"{\"config\": {\"terminology\": {\"cluster\": \"Group\", \"clusters\": \"Groups\", \"item\": \"Document\", \"items\": \"Documents\", \"link\": \"Similarity link\", \"links\": \"Similarity links\", \"link_strength\": \"Similarity strength\", \"total_link_strength\": \"Total similarity strengths\", \"title\": \"Title of the document\", \"abstract\": \"Abstract of the document\", \"authors\": \"Authors\"}, \"color_schemes\": {\"cluster_colors\": [{\"cluster\": 1, \"color\": \"#ff7f0e\"}, {\"cluster\": 2, \"color\": \"#d62728\"}]}, \"templates\": {\"item_description\": \"<div style='display:flex'><div style='padding-left:16px'><div class='description_heading'>{heading}</div><div class='description_title'><a class='description_url'href='{uri}'target='_blank'>{title}</a></div><div class='description_authors'style='margin:4px 0;font-weight:500px;color:#757575'>{authors}</div><div class='description_abstract'>{abstract}</div></div></div>\"}, \"styles\": {\"description_heading\": \"color: #757575; font-weight: 600;\"}, \"parameters\": {\"item_size_variation\": 0.7, \"largest_component\": true, \"attraction\": 1.0, \"repulsion\": -1.0, \"max_n_links\": 1000}}, \"network\": {\"items\": [{\"id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Finding optimal Learning rate schedules for Non-negative Matrix Factorization using Reinforcement Learning\", \"authors\": \"Shreyas Subramanian, Vignesh Ganapathiraman, Aly El Gamal\", \"label\": \"Finding optimal Learning rate schedules for Non-negative Matrix Factorization using Reinforcement Learning\", \"abstract\": \"Learning rate schedules are often picked out of experience or through trial and error, even though there are no real guarantees that the choice of sched- ule may lead to convergence across a wide range of tasks when training a complex Deep Learning network. In this paper we calculate a theoretical b...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=08814ac05c6bad4546e7a8146c6fff0b6d74b841\", \"img_url\": null, \"x\": -0.28005333027485385, \"y\": -0.6564196911539708, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation\", \"authors\": \"Ainesh Bakshi, Piotr Indyk, Praneeth Kacham, Sandeep Silwal, Samson Zhou\", \"label\": \"Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation\", \"abstract\": \"Kernel matrices, as well as weighted graphs represented by them, are ubiquitous objects in machine learning, statistics and other related fields. The main drawback of using kernel methods (learning and inference using kernel matrices) is efficiency -- given $n$ input points, most kernel-based algori...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=0c113f512672baa5caa0388b671bfeef4f8b7a95\", \"img_url\": null, \"x\": -0.03532769611742751, \"y\": -0.7644039697040688, \"cluster\": 1, \"weights\": {\"Influence\": 2.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2213114754098361, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8471489457971546, \"summary\": null}, {\"id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Almost Linear Constant-Factor Sketching for $\\\\ell_1$ and Logistic Regression\", \"authors\": \"Alexander Munteanu, Simon Omlor, David Woodruff\", \"label\": \"Almost Linear Constant-Factor Sketching for $\\\\ell_1$ and Logistic Regression\", \"abstract\": \"We improve upon previous oblivious sketching and turnstile streaming results for $\\\\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=0c34e3f02eb3e645183e05e122217afc5246a3d3\", \"img_url\": null, \"x\": -0.29048103439300926, \"y\": -0.8373883534884461, \"cluster\": 1, \"weights\": {\"Influence\": 5.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5163934426229508, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9050714505477065, \"summary\": null}, {\"id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach\", \"authors\": \"Heshan Devaka Fernando, Han Shen, Miao Liu, Subhajit Chaudhury, Keerthiram Murugesan, Tianyi Chen\", \"label\": \"Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach\", \"abstract\": \"Many machine learning problems today have multiple objective functions. They appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimiz...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=0c6075c6cd12e0d7f8a9e3ed034018761a50a632\", \"img_url\": null, \"x\": 0.019417762433159704, \"y\": -0.8639917739383378, \"cluster\": 1, \"weights\": {\"Influence\": 1.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18032786885245905, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8391041534706891, \"summary\": null}, {\"id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"SP2 : A Second Order Stochastic Polyak Method\", \"authors\": \"Shuang Li, William Joseph Swartworth, Martin Tak\\u00e1\\u010d, Deanna Needell, Robert M. Gower\", \"label\": \"SP2 : A Second Order Stochastic Polyak Method\", \"abstract\": \"Recently the SP (Stochastic Polyak step size) method has emerged as a competitive adaptive method for setting the step sizes of SGD.  SP can be interpreted as a method specialized to interpolated models, since it solves the interpolation equations. SP solves these equation by using local linearizati...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1746610555a537cb3593ad9a61cdbc4e666629d9\", \"img_url\": null, \"x\": -0.2190253426350083, \"y\": -0.8943822400442633, \"cluster\": 1, \"weights\": {\"Influence\": 5.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5286885245901639, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9074848882456463, \"summary\": null}, {\"id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"LOOPED TRANSFORMERS AS PROGRAMMABLE COMPUTERS\", \"authors\": \"Angeliki Giannou, Shashank Rajput, Jy-yong Sohn, Kangwook Lee, Jason D. Lee, Dimitris Papailiopoulos\", \"label\": \"LOOPED TRANSFORMERS AS PROGRAMMABLE COMPUTERS\", \"abstract\": \"We present a framework for using transformer networks as universal computers by programming them with specific weights and placing them in a loop. Our input sequence acts as a punchcard, consisting of instructions and memory for data read/writes. We demonstrate that a constant number of encoder laye...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb\", \"img_url\": null, \"x\": -0.10382655334722289, \"y\": -0.5247446793018523, \"cluster\": 1, \"weights\": {\"Influence\": 4.4, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4327868852459017, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8423956282904953, \"summary\": null}, {\"id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Improved Learning-augmented Algorithms for k-means and k-medians Clustering\", \"authors\": \"Thy Dinh Nguyen, Anamay Chaturvedi, Huy Nguyen\", \"label\": \"Improved Learning-augmented Algorithms for k-means and k-medians Clustering\", \"abstract\": \"We consider the problem of clustering in the learning-augmented setting. We are given a data set in $d$-dimensional Euclidean space, and a label for each data point given by a predictor indicating what subsets of points should be clustered together. This setting captures situations where we have acc...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1d725c899881e250efb01016809debea53c3e43a\", \"img_url\": null, \"x\": -0.28848153679115796, \"y\": -0.8963064087610016, \"cluster\": 1, \"weights\": {\"Influence\": 3.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.319672131147541, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.866456447380672, \"summary\": null}, {\"id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Adaptive Optimization in the $\\\\infty$-Width Limit\", \"authors\": \"Etai Littwin, Greg Yang\", \"label\": \"Adaptive Optimization in the $\\\\infty$-Width Limit\", \"abstract\": \"Recent works have developed detailed understanding of large neural networks' behaviors via their infinite-width limits, e.g., the neural tangent kernel (NTK) and the feature learning ($\\\\mu$) limits. These theories were developed for stochastic gradient descent. Yet, in practice, all large NN are tra...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184\", \"img_url\": null, \"x\": -0.10947405234287026, \"y\": -0.6877292471082369, \"cluster\": 1, \"weights\": {\"Influence\": 2.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.27049180327868855, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8568026965889133, \"summary\": null}, {\"id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Almost Sure Last Iterate Convergence of Sharpness-Aware Minimization\", \"authors\": \"Kyunghun Nam, Jinseok Chung, Namhoon Lee\", \"label\": \"Almost Sure Last Iterate Convergence of Sharpness-Aware Minimization\", \"abstract\": \"Sharpness-Aware Minimization (SAM) is an iterative optimization process to train neural networks, by which the training is guided to find flat minima, such that the solution found at convergence may generalize well. However, previous studies on the convergence of SAM have only shown the existence of...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=211991a3a9ac458b35866673765e188c6b7b2f5c\", \"img_url\": null, \"x\": -0.18100258086882043, \"y\": -0.9225980570837434, \"cluster\": 1, \"weights\": {\"Influence\": 3.499999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.34426229508196715, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8079772819197397, \"summary\": null}, {\"id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On Accelerated Perceptrons and Beyond\", \"authors\": \"Guanghui Wang, Rafael Hanashiro, Etash Kumar Guha, Jacob Abernethy\", \"label\": \"On Accelerated Perceptrons and Beyond\", \"abstract\": \"The classical Perceptron algorithm of Rosenblatt can be used to find a linear threshold function to correctly classify $n$ linearly separable data points, assuming the classes are separated by some margin $\\\\gamma > 0$. A foundational result is that Perceptron converges after  $\\\\Omega(1/\\\\gamma^{2})$ ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=21c550a9327392691fd9fd210c9ed68281c76d4b\", \"img_url\": null, \"x\": -0.06288627496437618, \"y\": -0.9655184778916917, \"cluster\": 1, \"weights\": {\"Influence\": 4.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4672131147540984, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.895417699755948, \"summary\": null}, {\"id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Why (and When) does Local SGD Generalize Better than SGD?\", \"authors\": \"Xinran Gu, Kaifeng Lyu, Longbo Huang, Sanjeev Arora\", \"label\": \"Why (and When) does Local SGD Generalize Better than SGD?\", \"abstract\": \"Local SGD is a communication-efficient variant of SGD for large-scale training, where multiple GPUs perform SGD independently and average the model parameters periodically. It has been recently observed that Local SGD can not only achieve the design goal of reducing the communication overhead but al...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2796c22fba65dd6950f2a6250834431cd78777e3\", \"img_url\": null, \"x\": -0.3959601738569602, \"y\": -0.8175415410757416, \"cluster\": 1, \"weights\": {\"Influence\": 4.166666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.40983606557377056, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8841549904988961, \"summary\": null}, {\"id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Information Plane Analysis for Dropout Neural Networks\", \"authors\": \"Linara Adilova, Bernhard C Geiger, Asja Fischer\", \"label\": \"Information Plane Analysis for Dropout Neural Networks\", \"abstract\": \"The information-theoretic framework promises to explain the predictive power of neural networks. In particular, the information plane analysis, which measures mutual information (MI) between input and representation as well as representation and output, should give rich insights into the training pr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2ca9edbba8b0efa31314fea9a1d8fbf9941ef592\", \"img_url\": null, \"x\": -0.10546172995447833, \"y\": -0.5566502284275271, \"cluster\": 1, \"weights\": {\"Influence\": 2.3333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2295081967213115, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8487579042624478, \"summary\": null}, {\"id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity\", \"authors\": \"Hongkang Li, Meng Wang, Sijia Liu, Pin-Yu Chen\", \"label\": \"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity\", \"abstract\": \"Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, the theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-r...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498\", \"img_url\": null, \"x\": -0.35488689963448705, \"y\": -0.44097537335005177, \"cluster\": 1, \"weights\": {\"Influence\": 8.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.8360655737704918, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9678208306941378, \"summary\": null}, {\"id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning\", \"authors\": \"Yuandong Tian\", \"label\": \"Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning\", \"abstract\": \"While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on on...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2ee383ebff429973fdd9d255c87ce7fad9d3e214\", \"img_url\": null, \"x\": -0.34073094882131777, \"y\": -0.5522165876392762, \"cluster\": 1, \"weights\": {\"Influence\": 8.499999999999998, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.8360655737704917, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9678208306941378, \"summary\": null}, {\"id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Neural Networks Efficiently Learn Low-Dimensional Representations with SGD\", \"authors\": \"Alireza Mousavi-Hosseini, Sejun Park, Manuela Girotti, Ioannis Mitliagkas, Murat A Erdogdu\", \"label\": \"Neural Networks Efficiently Learn Low-Dimensional Representations with SGD\", \"abstract\": \"We study the problem of training a two-layer neural network (NN) of arbitrary width using stochastic gradient descent (SGD) where the input $\\\\boldsymbol{x}\\\\in \\\\mathbb{R}^d$ is Gaussian and the target $y \\\\in \\\\mathbb{R}$ follows a multiple-index model, i.e., $y=g(\\\\langle\\\\boldsymbol{u_1},\\\\boldsymbol{x}...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=31ef10b0d82197012874d92618be35699065046d\", \"img_url\": null, \"x\": -0.18943047235541713, \"y\": -0.7977686092145352, \"cluster\": 1, \"weights\": {\"Influence\": 1.875, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18442622950819673, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8399086327033357, \"summary\": null}, {\"id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation\", \"authors\": \"Jun-Kun Wang, Andre Wibisono\", \"label\": \"Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation\", \"abstract\": \"We consider a setting that a model needs to adapt to a new domain under distribution shifts, given that only unlabeled test samples from the new domain are accessible at test time. A common idea in most of the related works is constructing pseudo-labels for the unlabeled test samples and applying gr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53\", \"img_url\": null, \"x\": -0.4545984812898901, \"y\": -0.6340862752967169, \"cluster\": 1, \"weights\": {\"Influence\": 7.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6885245901639344, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9388595783188618, \"summary\": null}, {\"id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time\", \"authors\": \"Jun-Kun Wang, Andre Wibisono\", \"label\": \"Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time\", \"abstract\": \"Hamiltonian Monte Carlo (HMC) is a popular method in sampling. While there are quite a few works of studying this method on various aspects, an interesting question is how to choose its integration time to achieve acceleration. In this work, we consider accelerating the process of sampling from a di...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f\", \"img_url\": null, \"x\": -0.26622232689669295, \"y\": -0.5985066310851876, \"cluster\": 1, \"weights\": {\"Influence\": 7.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6885245901639344, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9388595783188618, \"summary\": null}, {\"id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Distributed Extra-gradient with Optimal Complexity and Communication Guarantees\", \"authors\": \"Ali Ramezani-Kebrya, Kimon Antonakopoulos, Igor Krawczuk, Justin Deschenaux, Volkan Cevher\", \"label\": \"Distributed Extra-gradient with Optimal Complexity and Communication Guarantees\", \"abstract\": \"We consider monotone variational inequality (VI) problems in multi-GPU  settings where multiple processors/workers/clients have access to local stochastic dual vectors. This setting  includes a broad range of important problems from distributed convex minimization to min-max and games. Extra-gradien...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=40b3decaf6b173444b2a00ff6e950f3b976fc3e5\", \"img_url\": null, \"x\": -0.27512382510331906, \"y\": -0.9600055566473588, \"cluster\": 1, \"weights\": {\"Influence\": 2.3333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2295081967213115, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8487579042624478, \"summary\": null}, {\"id\": \"415d1e23935390eca56780afdd0c64cc5ea0397f_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Adaptive-saturated RNN: Remember more with less instability\", \"authors\": \"Khoi Minh Nguyen-Duy, Quang Pham, Binh T. Nguyen\", \"label\": \"Adaptive-saturated RNN: Remember more with less instability\", \"abstract\": \"Orthogonal parameterization has offered a compelling solution to the vanishing gradient problem (VGP) in recurrent neural networks (RNNs). Thanks to orthogonal parameters and non-saturated activation functions, gradients in such models are constrained to unit norms. On the other hand, although the t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=415d1e23935390eca56780afdd0c64cc5ea0397f\", \"img_url\": null, \"x\": -0.20800091551557512, \"y\": -0.642320917573078, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.19672131147540986, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7647721703516812, \"summary\": null}, {\"id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Towards Stochastic Gradient Variance Reduction by Solving a Filtering Problem\", \"authors\": \"Xingyi Yang\", \"label\": \"Towards Stochastic Gradient Variance Reduction by Solving a Filtering Problem\", \"abstract\": \"Deep neural networks (DNN) are typically optimized using stochastic gradient descent (SGD). However, the estimation of the gradient using stochastic samples tends to be noisy and unreliable, resulting in large gradient variance and bad convergence. In this paper, we propose Filter Gradient Decent (F...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=421133736c7b26adee4ced798b5ed8a4ce821c1e\", \"img_url\": null, \"x\": -0.17826147632766687, \"y\": -0.759084194052832, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Multi-Objective Online Learning\", \"authors\": \"Jiyan Jiang, Wenpeng Zhang, Shiji Zhou, Lihong Gu, Xiaodong Zeng, Wenwu Zhu\", \"label\": \"Multi-Objective Online Learning\", \"abstract\": \"This paper presents a systematic study of multi-objective online learning. We first formulate the framework of Multi-Objective Online Convex Optimization, which encompasses a novel multi-objective regret. This regret is built upon a sequence-wise extension of the commonly used discrepancy metric Par...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45\", \"img_url\": null, \"x\": 0.08133903533931232, \"y\": -0.8045180971892275, \"cluster\": 1, \"weights\": {\"Influence\": 3.1666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3114754098360656, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8648474889153789, \"summary\": null}, {\"id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property\", \"authors\": \"Yingzhen Yang, Ping Li\", \"label\": \"Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property\", \"abstract\": \"Nonconvex and nonsmooth optimization problems are important and challenging for statistics and machine learning. In this paper, we propose Projected Proximal Gradient Descent (PPGD) which solves a class of nonconvex and nonsmooth optimization problems, where the nonconvexity and nonsmoothness come f...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=43cb581da533a48b975471f4100f055cbfcd57ce\", \"img_url\": null, \"x\": -0.12785237867131533, \"y\": -0.9658756284260596, \"cluster\": 1, \"weights\": {\"Influence\": 4.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4672131147540984, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.895417699755948, \"summary\": null}, {\"id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning\", \"authors\": \"Alex Gu, Songtao Lu, Parikshit Ram, Tsui-Wei Weng\", \"label\": \"Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning\", \"abstract\": \"We consider a generic min-max multi-objective bilevel optimization problem with applications in robust machine learning such as representation learning and hyperparameter optimization. We design MORBiT, a novel single-loop gradient descent-ascent bilevel optimization algorithm, to solve the generic ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=45c00944e0ae7ef63f88c57eb3abd7337982cc5b\", \"img_url\": null, \"x\": -0.04214239202406137, \"y\": -0.8710751861464866, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.29508196721311475, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8616295719847926, \"summary\": null}, {\"id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets\", \"authors\": \"Edo Cohen-Karlik, Itamar Menuhin-Gruman, Raja Giryes, Nadav Cohen, Amir Globerson\", \"label\": \"Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets\", \"abstract\": \"Overparameterization in deep learning refers to settings where a trained Neural Network (NN) has representational capacity to fit the training data in many ways, some of which generalize well, while others do not. In the case of Recurrent Neural Networks (RNNs) there exists an additional layer of ov...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=460c76a8c7bda3cea365a11c53781e39a20afa4e\", \"img_url\": null, \"x\": -0.17565671188163232, \"y\": -0.6690447735996484, \"cluster\": 1, \"weights\": {\"Influence\": 4.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4672131147540984, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.895417699755948, \"summary\": null}, {\"id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Mini-batch $k$-means terminates within $O(d/\\\\epsilon)$ iterations\", \"authors\": \"Gregory Schwartzman\", \"label\": \"Mini-batch $k$-means terminates within $O(d/\\\\epsilon)$ iterations\", \"abstract\": \"We answer the question: \\\"Does \\\\emph{local} progress (on batches) imply \\\\emph{global} progress (on the entire dataset) for mini-batch $k$-means?\\\". Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below s...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=476beabca05f9acad45961fd4e7f014cb58c82ff\", \"img_url\": null, \"x\": -0.31557992839029664, \"y\": -0.9161142703937437, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams.\", \"authors\": \"Cuiyu Liu, Xiao Chuanfu, Mingshuo Ding, Chao Yang\", \"label\": \"Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams.\", \"abstract\": \"Low-rank approximation in data streams is a fundamental and significant task in computing science, machine learning and statistics. Multiple streaming algorithms have emerged over years and most of them are inspired by randomized algorithms, more specifically, sketching methods. However, many algori...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4781893f1f30259bef6724033986eb3a78c3621e\", \"img_url\": null, \"x\": -0.03209681350834696, \"y\": -0.801334280011497, \"cluster\": 1, \"weights\": {\"Influence\": 7.499999999999998, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7377049180327867, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9485133291106205, \"summary\": null}, {\"id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes\", \"authors\": \"Alexander Atanasov, Blake Bordelon, Sabarish Sainathan, Cengiz Pehlevan\", \"label\": \"The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes\", \"abstract\": \"For small training set sizes $P$, the generalization error of wide neural networks is well-approximated by the error of an infinite width neural network (NN), either in the kernel or mean-field/feature-learning regime. However, after a critical sample size $P^*$, we empirically find the finite-width...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4930f93a4ead2967a42e34cb6471bbe2407ed651\", \"img_url\": null, \"x\": -0.2132674134016896, \"y\": -0.6002444242284944, \"cluster\": 1, \"weights\": {\"Influence\": 1.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.12295081967213116, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8278414442136374, \"summary\": null}, {\"id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On the Convergence of AdaGrad(Norm) on $\\\\mathbb{R}^d$: Beyond Convexity, Non-Asymptotic Rate and Acceleration\", \"authors\": \"Zijian Liu, Ta Duy Nguyen, Alina Ene, Huy Nguyen\", \"label\": \"On the Convergence of AdaGrad(Norm) on $\\\\mathbb{R}^d$: Beyond Convexity, Non-Asymptotic Rate and Acceleration\", \"abstract\": \"Existing analysis of AdaGrad and other adaptive methods for smooth convex optimization is typically for functions with bounded domain diameter. In unconstrained problems, previous works guarantee an asymptotic convergence rate without an explicit constant factor that holds true for the entire functi...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4bfab236f516e2ad7efb4fa9457521968c08c9a7\", \"img_url\": null, \"x\": -0.17796273661403778, \"y\": -1.0092972551718673, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.49180327868852464, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9002445751518273, \"summary\": null}, {\"id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Federated Neural Bandits\", \"authors\": \"Zhongxiang Dai, Yao Shu, Arun Verma, Flint Xiaofeng Fan, Bryan Kian Hsiang Low, Patrick Jaillet\", \"label\": \"Federated Neural Bandits\", \"abstract\": \"Recent works on neural contextual bandits have achieved compelling performances due to their ability to leverage the strong representation power of neural networks (NNs) for reward prediction. Many applications of contextual bandits involve multiple agents who collaborate without sharing raw observa...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4c3155a7dc9c0785bde17e6b4fec26ae8f281e58\", \"img_url\": null, \"x\": 0.6932464327671702, \"y\": -0.6823506486258848, \"cluster\": 1, \"weights\": {\"Influence\": 1.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.13524590163934427, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.830254881911577, \"summary\": null}, {\"id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent\", \"authors\": \"Avrajit Ghosh, He Lyu, Xitong Zhang, Rongrong Wang\", \"label\": \"Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent\", \"abstract\": \"It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \\\\textit{Does the momentum parameter $\\\\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient desce...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2\", \"img_url\": null, \"x\": -0.3920211016584851, \"y\": -0.7678590037989543, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Faster federated optimization under second-order similarity\", \"authors\": \"Ahmed Khaled, Chi Jin\", \"label\": \"Faster federated optimization under second-order similarity\", \"abstract\": \"Federated learning (FL) is a subfield of machine learning where multiple clients try to collaboratively learn a model over a network under communication constraints. We consider finite-sum federated optimization under a second-order function similarity condition and strong convexity, and propose two...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=53433146de0db29171a65c53c4130f59cd247f0d\", \"img_url\": null, \"x\": -0.22317772276110076, \"y\": -0.9805805724579867, \"cluster\": 1, \"weights\": {\"Influence\": 5.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5163934426229508, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9050714505477065, \"summary\": null}, {\"id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions\", \"authors\": \"Arthur Jacot\", \"label\": \"Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions\", \"abstract\": \"We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a n...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=536db97acc7c6028eae840523031ad3f26a83908\", \"img_url\": null, \"x\": -0.03848162104098796, \"y\": -0.6375691665683966, \"cluster\": 1, \"weights\": {\"Influence\": 2.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426226, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"5390075b7f08fed5a2a1e2e855a8cc503b15958e_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Improving generalization by loss modification\", \"authors\": \"Michael Tetelman\", \"label\": \"Improving generalization by loss modification\", \"abstract\": \"What data points from available data set should be used for training? For all subsets of available data it will generally make different solutions. We show that a simple loss modification allows to find a single solution that represents data set properties and not particular selections of data point...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5390075b7f08fed5a2a1e2e855a8cc503b15958e\", \"img_url\": null, \"x\": -0.3119908455901264, \"y\": -0.3676816547695032, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning ReLU networks to high uniform accuracy is intractable\", \"authors\": \"Julius Berner, Philipp Grohs, Felix Voigtlaender\", \"label\": \"Learning ReLU networks to high uniform accuracy is intractable\", \"abstract\": \"Statistical learning theory provides bounds on the necessary number of training samples needed to reach a prescribed accuracy in a learning problem formulated over a given target class. This accuracy is typically measured in terms of a generalization error, that is, an expected value of a given loss...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=560694073022b93a92267e067baddd5490dd98db\", \"img_url\": null, \"x\": 0.04147526193052718, \"y\": -0.7146755899392163, \"cluster\": 1, \"weights\": {\"Influence\": 1.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18032786885245905, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8391041534706891, \"summary\": null}, {\"id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Sequential Attention for Feature Selection\", \"authors\": \"Taisuke Yasuda, Mohammadhossein Bateni, Lin Chen, Matthew Fahrbach, Gang Fu, Vahab Mirrokni\", \"label\": \"Sequential Attention for Feature Selection\", \"abstract\": \"Feature selection is the problem of selecting a subset of features for a machine learning model that maximizes model quality subject to a budget constraint. For neural networks, prior methods, including those based on $\\\\ell_1$ regularization, attention, and other techniques, typically select the ent...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=58ffdf8508266fa99dfcea315013ff52c1f815b1\", \"img_url\": null, \"x\": -0.2613653523355097, \"y\": -0.4486513932949194, \"cluster\": 1, \"weights\": {\"Influence\": 1.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18032786885245905, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8391041534706891, \"summary\": null}, {\"id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods\", \"authors\": \"Shunta Akiyama, Taiji Suzuki\", \"label\": \"Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods\", \"abstract\": \"While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. We investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=59bd8836e93870156ae5b56d425add5dd8286b9c\", \"img_url\": null, \"x\": -0.1863111589161098, \"y\": -0.7104198691645162, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.29508196721311475, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8616295719847926, \"summary\": null}, {\"id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Backpropagation through Combinatorial Algorithms: Identity with Projection Works\", \"authors\": \"Subham Sekhar Sahoo, Anselm Paulus, Marin Vlastelica, V\\u00edt Musil, Volodymyr Kuleshov, Georg Martius\", \"label\": \"Backpropagation through Combinatorial Algorithms: Identity with Projection Works\", \"abstract\": \"Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning. ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6\", \"img_url\": null, \"x\": 0.016385157899199237, \"y\": -0.5216398357350073, \"cluster\": 1, \"weights\": {\"Influence\": 1.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14754098360655737, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8326683196095167, \"summary\": null}, {\"id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation\", \"authors\": \"Thanh Nguyen-Tang, Raman Arora\", \"label\": \"VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation\", \"abstract\": \"We propose a novel algorithm for offline reinforcement learning called Value Iteration with Perturbed Rewards (VIPeR), which amalgamates the pessimism principle with random perturbations of the value function. Most current offline RL algorithms explicitly construct statistical confidence regions to ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5bf49762e18f4ef1d5fac9e05f16f1845fd06e31\", \"img_url\": null, \"x\": 0.7049458532408193, \"y\": -0.5826207764315586, \"cluster\": 1, \"weights\": {\"Influence\": 6.999999999999998, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6885245901639343, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9388595783188618, \"summary\": null}, {\"id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Solving Constrained Variational Inequalities via a First-order Interior Point-based Method\", \"authors\": \"Tong Yang, Michael Jordan, Tatjana Chavdarova\", \"label\": \"Solving Constrained Variational Inequalities via a First-order Interior Point-based Method\", \"abstract\": \"We develop an interior-point approach to solve constrained variational inequality (cVI) problems. Inspired by the efficacy of the alternating direction method of multipliers (ADMM) method in the single-objective context, we generalize ADMM to derive a first-order method for cVIs, that we refer to as...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5f2b126f7b685acd5b40570d2582a193159458dd\", \"img_url\": null, \"x\": -0.07555701610187436, \"y\": -0.9254780961493574, \"cluster\": 1, \"weights\": {\"Influence\": 10.166666666666666, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 1.0, \"summary\": null}, {\"id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Near-optimal Coresets for Robust Clustering\", \"authors\": \"Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou, Xuan Wu\", \"label\": \"Near-optimal Coresets for Robust Clustering\", \"abstract\": \"We consider robust clustering problems in $\\\\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means) with $m$ \\\\emph{outliers}, where the cost for a given center set $C \\\\subset \\\\mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6010d9b9d76b36207123f320865f84e6a1318b61\", \"img_url\": null, \"x\": -0.30290195441983814, \"y\": -0.8695779906481192, \"cluster\": 1, \"weights\": {\"Influence\": 1.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14754098360655737, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8326683196095167, \"summary\": null}, {\"id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Diffusion Models are Minimax Optimal Distribution Estimators\", \"authors\": \"Kazusato Oko, Shunta Akiyama, Taiji Suzuki\", \"label\": \"Diffusion Models are Minimax Optimal Distribution Estimators\", \"abstract\": \"We provide the first rigorous analysis on estimation error bounds of diffusion modeling for well-known function spaces. The highlight of this paper is that when the true density function belongs to the Besov space and the empirical score matching loss is properly minimized, the generated data distri...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=609600ec9a5871c02b8583cee5e7fb961d593fe6\", \"img_url\": null, \"x\": 0.02581787373976057, \"y\": -0.5889948448051495, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.29508196721311475, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.804133295274315, \"summary\": null}, {\"id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics\", \"authors\": \"Taiji Suzuki, Atsushi Nitanda, Denny Wu\", \"label\": \"Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics\", \"abstract\": \"The mean-field Langevin dynamics is characterized by a stochastic differential equation that arises from (noisy) gradient descent on an infinite-width two-layer neural network, which can be viewed as an interacting particle system. In this work, we establish a quantitative weak propagation of chaos ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6561ce95a78eda28a72bcf0b1c96215e18091ad0\", \"img_url\": null, \"x\": -0.06907523671997987, \"y\": -0.7067656315643793, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.29508196721311475, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8616295719847926, \"summary\": null}, {\"id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Implicit Regularization for Group Sparsity\", \"authors\": \"Jiangyuan Li, Thanh V Nguyen, Chinmay Hegde, Raymond K. W. Wong\", \"label\": \"Implicit Regularization for Group Sparsity\", \"abstract\": \"We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization, which we call a diagonally grouped linear neural network. We show the following intriguing property of our reparameterization: gradient descent over the squared regression loss...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=691ec4cd76ed021fb414e9ff33233d25d87d8bff\", \"img_url\": null, \"x\": -0.1670723680743269, \"y\": -0.6208113789843913, \"cluster\": 1, \"weights\": {\"Influence\": 2.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426232, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance\", \"authors\": \"Pankaj K Agarwal, Sharath Raghvendra, Pouyan Shirzadian, Rachita Sowle\", \"label\": \"A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance\", \"abstract\": \"We consider the problem of computing the $1$-Wasserstein distance $\\\\mathcal{W}(\\\\mu,\\\\nu)$ between two $d$-dimensional discrete distributions $\\\\mu$ and $\\\\nu$ whose support lie within the unit hypercube. There are several algorithms that estimate $\\\\mathcal{W}(\\\\mu,\\\\nu)$ within an additive error of $\\\\var...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6990d6ab5c9dc47673daacf4be4911e554fe97af\", \"img_url\": null, \"x\": -0.24522866120135783, \"y\": -0.8271210223600464, \"cluster\": 1, \"weights\": {\"Influence\": 1.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1721311475409836, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.837495195005396, \"summary\": null}, {\"id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Understanding Train-Validation Split in Meta-Learning with Neural Networks\", \"authors\": \"Xinzhe Zuo, Zixiang Chen, Huaxiu Yao, Yuan Cao, Quanquan Gu\", \"label\": \"Understanding Train-Validation Split in Meta-Learning with Neural Networks\", \"abstract\": \"The goal of meta-learning is to learn a good prior model from a collection of tasks such that the learned prior is able to adapt quickly to new tasks without accessing many data from the new tasks. A common practice in meta-learning is to perform a train-validation split on each task, where the trai...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57\", \"img_url\": null, \"x\": -0.08028038257084115, \"y\": -0.6634819380144045, \"cluster\": 1, \"weights\": {\"Influence\": 5.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5532786885245902, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9123117636415256, \"summary\": null}, {\"id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Robust Algorithms on Adaptive Inputs from Bounded Adversaries\", \"authors\": \"Yeshwanth Cherapanamjeri, Sandeep Silwal, David Woodruff, Fred Zhang, Qiuyi Zhang, Samson Zhou\", \"label\": \"Robust Algorithms on Adaptive Inputs from Bounded Adversaries\", \"abstract\": \"We study dynamic algorithms robust to adaptive input generated from sources with bounded capabilities, such as sparsity or limited interaction. For example, we consider robust linear algebraic algorithms when the updates to the input are sparse but given by an adversary with access to a query oracle...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=70885518c23471a5d65e401a3eee82d234e45abf\", \"img_url\": null, \"x\": -0.341317678493308, \"y\": -0.8471558006563612, \"cluster\": 1, \"weights\": {\"Influence\": 2.1666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21311475409836064, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8455399873318616, \"summary\": null}, {\"id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"heading\": \"ICLR, 09 Feb 2023\", \"title\": \"Multilevel Approach to Efficient Gradient Calculation in Stochastic Systems\", \"authors\": \"Joohwan Ko\", \"label\": \"Multilevel Approach to Efficient Gradient Calculation in Stochastic Systems\", \"abstract\": \"Gradient estimation in Stochastic Differential Equations is a critical challenge in fields that require dynamic modeling of stochastic systems. While there have been numerous studies on pathwise gradients, the calculation of expectations over different realizations of the Brownian process in SDEs is...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=74387200905db3e054a9013071f4a2a20127dc8f\", \"img_url\": null, \"x\": 0.19210028233826962, \"y\": -0.5113262399740349, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7488457180354954, \"summary\": null}, {\"id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Analytical solutions for a family of single layer neural network regression problems \", \"authors\": \"Siddharth Krishna Kumar\", \"label\": \"Analytical solutions for a family of single layer neural network regression problems \", \"abstract\": \"In this paper we show analytically that the optimal weights for a family of penalized single layer neural network regression problems wherein the response variable has all non-positive entries will always be $[0, 0, . . . , 0, 0]^T$...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8\", \"img_url\": null, \"x\": -0.15254786219828123, \"y\": -0.8404736667638414, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains\", \"authors\": \"Kefan Dong, Tengyu Ma\", \"label\": \"First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains\", \"abstract\": \"Real-world machine learning applications often involve deploying neural networks to domains that are not seen in the training time. Hence, we need to understand the extrapolation of \\\\textit{nonlinear} models---under what conditions on the distributions and function class, models can be guaranteed to...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=7c175f57042297e15a4014c3243c010fe5a91d43\", \"img_url\": null, \"x\": -0.31411789182916466, \"y\": -0.41466586099804054, \"cluster\": 1, \"weights\": {\"Influence\": 6.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5901639344262295, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9195520767353446, \"summary\": null}, {\"id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Strong inductive biases provably prevent harmless interpolation\", \"authors\": \"Michael Aerni, Marco Milanta, Konstantin Donhauser, Fanny Yang\", \"label\": \"Strong inductive biases provably prevent harmless interpolation\", \"abstract\": \"Classical wisdom suggests that estimators should avoid fitting noise to achieve good generalization. In contrast, modern overparameterized models can yield small test error despite interpolating noise \\u2014 a phenomenon often called \\\"benign overfitting\\\" or \\\"harmless interpolation\\\". This paper argues tha...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=80e24b14bb02af11590f105e1f3d1ca63aa2a46e\", \"img_url\": null, \"x\": -0.3283822901425244, \"y\": -0.6952620965364968, \"cluster\": 1, \"weights\": {\"Influence\": 2.999999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2950819672131147, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8616295719847926, \"summary\": null}, {\"id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"How Sharpness-Aware Minimization Minimizes Sharpness?\", \"authors\": \"Kaiyue Wen, Tengyu Ma, Zhiyuan Li\", \"label\": \"How Sharpness-Aware Minimization Minimizes Sharpness?\", \"abstract\": \"Sharpness-Aware Minimization (SAM) is a highly effective regularization technique for improving the generalization of deep neural networks for various settings. However, the underlying working of SAM remains elusive because of various intriguing approximations in the theoretical characterizations. S...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=88c536854961a03798ae492a6598ab070d7426e7\", \"img_url\": null, \"x\": -0.17506434052068898, \"y\": -0.8740429444648947, \"cluster\": 1, \"weights\": {\"Influence\": 8.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7868852459016394, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9581670799023791, \"summary\": null}, {\"id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Understanding Influence Functions and Datamodels via Harmonic Analysis\", \"authors\": \"Nikunj Saunshi, Arushi Gupta, Mark Braverman, Sanjeev Arora\", \"label\": \"Understanding Influence Functions and Datamodels via Harmonic Analysis\", \"abstract\": \"Influence functions estimate effect of individual data points on predictions of the model on test data and were adapted to deep learning in \\\\cite{koh2017understanding}. They have been used for detecting data poisoning, detecting helpful and harmful examples, influence of groups of datapoints, etc. R...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=89efb4aa4736421ceb48d23add92b3fbb5d1aa5d\", \"img_url\": null, \"x\": -0.5093287763553895, \"y\": -0.49213992226681585, \"cluster\": 1, \"weights\": {\"Influence\": 3.875, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3811475409836066, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8785236358703703, \"summary\": null}, {\"id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning\", \"authors\": \"Zeyuan Allen-Zhu, Yuanzhi Li\", \"label\": \"Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning\", \"abstract\": \"We formally study how \\\\emph{ensemble} of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using \\\\emph{knowledge distillation}. We consider the challenging case where the ensemble is simply an average of the outputs of a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f\", \"img_url\": null, \"x\": -0.4677952028549186, \"y\": -0.5233247604161761, \"cluster\": 1, \"weights\": {\"Influence\": 9.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.9098360655737705, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9823014568817758, \"summary\": null}, {\"id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Enhancing Meta Learning via Multi-Objective Soft Improvement Functions\", \"authors\": \"Runsheng Yu, Weiyu Chen, Xinrun Wang, James Kwok\", \"label\": \"Enhancing Meta Learning via Multi-Objective Soft Improvement Functions\", \"abstract\": \"Meta-learning tries to leverage information from similar learning tasks. In the commonly-used bilevel optimization formulation, the shared parameter is learned in the outer loop by minimizing the average loss over all tasks. However, the converged solution may be comprised in that it only focuses on...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=98f69cb8b49e6445ac9fecbc7b833416c937c682\", \"img_url\": null, \"x\": 0.09315151583471443, \"y\": -0.6797478319354588, \"cluster\": 1, \"weights\": {\"Influence\": 2.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426232, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"99ba665029e52a1b2066be025866c24222059889_0\", \"heading\": \"ICLR, 21 Feb 2023\", \"title\": \"Explaining Multiclass Classifiers with Categorical Values: A Case Study in Radiography\", \"authors\": \"Luca Franceschi, Cemre Zor, Muhammad Bilal Zafar, Gianluca Detommaso, Cedric Archambeau, Tamas Madl, Michele Donini, Matthias Seeger\", \"label\": \"Explaining Multiclass Classifiers with Categorical Values: A Case Study in Radiography\", \"abstract\": \"Explainability of machine learning methods is of fundamental importance in healthcare to calibrate trust. A large branch of explainable machine learning uses tools linked to the Shapley value, which have nonetheless been found difficult to interpret and potentially misleading. Taking multiclass clas...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=99ba665029e52a1b2066be025866c24222059889\", \"img_url\": null, \"x\": 0.11246344878180028, \"y\": -0.6467935167321893, \"cluster\": 1, \"weights\": {\"Influence\": 2.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2581967213114754, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7870756572201744, \"summary\": null}, {\"id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Accelerated Single-Call Methods for Constrained Min-Max Optimization\", \"authors\": \"Yang Cai, Weiqiang Zheng\", \"label\": \"Accelerated Single-Call Methods for Constrained Min-Max Optimization\", \"abstract\": \"We study first-order methods for constrained min-max optimization. Existing methods either require two gradient calls or two projections in each iteration, which may be costly in some applications. In this paper, we first show that a variant of the \\\\emph{Optimistic Gradient (OG)} method, a \\\\emph{sin...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7\", \"img_url\": null, \"x\": -0.09030879226494117, \"y\": -0.9826721338437927, \"cluster\": 1, \"weights\": {\"Influence\": 2.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426226, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"The SSL Interplay: Augmentations, Inductive Bias, and Generalization\", \"authors\": \"Vivien Cabannes, Bobak Kiani, Randall Balestriero, Yann LeCun, Alberto Bietti\", \"label\": \"The SSL Interplay: Augmentations, Inductive Bias, and Generalization\", \"abstract\": \"Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theo...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e\", \"img_url\": null, \"x\": -0.40745132776480086, \"y\": -0.5931678754890557, \"cluster\": 1, \"weights\": {\"Influence\": 5.1, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5016393442622951, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8615267947985855, \"summary\": null}, {\"id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning\", \"authors\": \"Peizhong Ju, Yingbin Liang, Ness Shroff\", \"label\": \"Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning\", \"abstract\": \"Meta-learning has arisen as a successful method for improving training performance by training over many similar tasks, especially with deep neural networks (DNNs). However, the theoretical understanding of when and why overparameterized models such as DNNs can generalize well in meta-learning is st...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9e7727ec223f4b90eeedadbe6925f5d80f281fc7\", \"img_url\": null, \"x\": -0.09848293603971957, \"y\": -0.7365840602806483, \"cluster\": 1, \"weights\": {\"Influence\": 2.3333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2295081967213115, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8487579042624478, \"summary\": null}, {\"id\": \"9ea82d4340917f03855d4230479d560d6386cec5_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"The Effects of Pretraining Task Diversity on In-Context Learning of Ridge Regression\", \"authors\": \"Allan Raventos, Mansheej Paul, Feng Chen, Surya Ganguli\", \"label\": \"The Effects of Pretraining Task Diversity on In-Context Learning of Ridge Regression\", \"abstract\": \"Pretrained transformers can do in-context learning (ICL), i.e. learn new tasks in the forward pass from a few examples provided in context. \\nBut can the model do ICL for completely new tasks or is this ability restricted to tasks similar to those seen during pretraining? \\nHow does the diversity of t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9ea82d4340917f03855d4230479d560d6386cec5\", \"img_url\": null, \"x\": -0.18364391228482174, \"y\": 0.14981033263135288, \"cluster\": 1, \"weights\": {\"Influence\": 3.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3606557377049181, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8223534538534485, \"summary\": null}, {\"id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"LEARNED LEARNING RATE SCHEDULES FOR DEEP NEURAL NETWORK TRAINING USING REINFORCEMENT LEARNING\", \"authors\": \"Shreyas Subramanian, Vignesh Ganapathiraman, Aly El Gamal\", \"label\": \"LEARNED LEARNING RATE SCHEDULES FOR DEEP NEURAL NETWORK TRAINING USING REINFORCEMENT LEARNING\", \"abstract\": \"Stochastic gradient descent (SGD) is a popular optimization algorithm for training deep neural networks (DNNs), but it requires careful selection of the learning rate schedule. In this paper, we present a novel strategy to generate learned schedules for SGD using reinforcement learning (RL). Our app...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9f021d6ba2ee9f90db9f57beffaf82a7944f7c48\", \"img_url\": null, \"x\": -0.29746632292531905, \"y\": -0.6357904041507192, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Solving stochastic weak Minty variational inequalities without increasing batch size\", \"authors\": \"Thomas Pethick, Olivier Fercoq, Puya Latafat, Panagiotis Patrinos, Volkan Cevher\", \"label\": \"Solving stochastic weak Minty variational inequalities without increasing batch size\", \"abstract\": \"This paper introduces a family of stochastic extragradient-type algorithms for a class of nonconvex-nonconcave problems characterized by the weak Minty variational inequality (MVI). Unlike existing results on extragradient methods in the monotone setting, employing diminishing stepsizes is no longer...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a0efb9f11f4f53e23054f6741abe8f31b61862ae\", \"img_url\": null, \"x\": -0.12377051893869498, \"y\": -1.0019482616499917, \"cluster\": 1, \"weights\": {\"Influence\": 3.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3073770491803279, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8640430096827323, \"summary\": null}, {\"id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Multi-objective optimization via equivariant deep hypervolume approximation\", \"authors\": \"Jim Boelrijk, Bernd Ensing, Patrick Forr\\u00e9\", \"label\": \"Multi-objective optimization via equivariant deep hypervolume approximation\", \"abstract\": \"Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is use...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a1d26e653910490a9acbc590431de1d12f12049f\", \"img_url\": null, \"x\": 0.2854865073462521, \"y\": -0.5014074428276122, \"cluster\": 1, \"weights\": {\"Influence\": 2.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426226, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks\", \"authors\": \"Daniel Kunin, Atsushi Yamamura, Chao Ma, Surya Ganguli\", \"label\": \"The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks\", \"abstract\": \"In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with homogen...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a24af3846e706489a5fc3a5a363217250f179f54\", \"img_url\": null, \"x\": -0.1311544891131889, \"y\": -0.7804275557044661, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.49180327868852464, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9002445751518273, \"summary\": null}, {\"id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"\\u200b\\u200bWhat learning algorithm is in-context learning? Investigations with linear models\", \"authors\": \"Ekin Aky\\u00fcrek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou\", \"label\": \"\\u200b\\u200bWhat learning algorithm is in-context learning? Investigations with linear models\", \"abstract\": \"Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples $(x, f(x))$ presented in the input without further parameter updates. We investigate the hypothesis that transformer-based in-c...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a707eb33e0d88a559bc543148ac5f01651f03cf9\", \"img_url\": null, \"x\": -0.1391334257279567, \"y\": -0.1112474424677812, \"cluster\": 1, \"weights\": {\"Influence\": 6.4, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6295081967213115, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9272750773687515, \"summary\": null}, {\"id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Memorization Capacity of Neural Networks with Conditional Computation\", \"authors\": \"Erdem Koyuncu\", \"label\": \"Memorization Capacity of Neural Networks with Conditional Computation\", \"abstract\": \"Many empirical studies have demonstrated the performance benefits of conditional computation in neural networks, including reduced inference time and power consumption. We study the fundamental limits of neural conditional computation from the perspective of memorization capacity. For Rectified Line...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a7c28f8861965143923f6f3ec84cb4fc7d002905\", \"img_url\": null, \"x\": -0.0636494917712625, \"y\": -0.5718687735125748, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"A Kernel Perspective of Skip Connections in Convolutional Networks\", \"authors\": \"Daniel Barzilai, Amnon Geifman, Meirav Galun, Ronen Basri\", \"label\": \"A Kernel Perspective of Skip Connections in Convolutional Networks\", \"abstract\": \"Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural\\u00a0architectures for image processing. Here we study their\\u00a0properties through\\u00a0their Gaussian Process and Neural Tangent kernels. We derive explicit\\u00a0formulas for these kernels, analyze their spectra, and ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ae67f0cc885bd798eb6805ab26c191087f371eae\", \"img_url\": null, \"x\": -0.35851518730521037, \"y\": -0.6632656362391498, \"cluster\": 1, \"weights\": {\"Influence\": 4.166666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.40983606557377056, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8841549904988961, \"summary\": null}, {\"id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation\", \"authors\": \"Junjie Yang, Xuxi Chen, Tianlong Chen, Zhangyang Wang, Yingbin Liang\", \"label\": \"M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation\", \"abstract\": \" Learning to Optimize (L2O) has drawn increasing attention as it often remarkably accelerates the optimization procedure of complex tasks by \\\"overfitting\\\" specific task type, leading to enhanced performance compared to analytical optimizers. Generally, L2O develops a parameterized optimization metho...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=af2a26e0e430576d6bd2075f4a33421a151384b8\", \"img_url\": null, \"x\": -0.21482622126185003, \"y\": -0.5507639232840604, \"cluster\": 1, \"weights\": {\"Influence\": 3.5999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3540983606557377, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.873214072934903, \"summary\": null}, {\"id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On the Trade-Off between Actionable Explanations and the Right to be Forgotten\", \"authors\": \"Martin Pawelczyk, Tobias Leemann, Asia Biega, Gjergji Kasneci\", \"label\": \"On the Trade-Off between Actionable Explanations and the Right to be Forgotten\", \"abstract\": \"As machine learning (ML) models are increasingly being deployed in high-stakes applications, policymakers have suggested tighter data protection regulations (e.g., GDPR, CCPA). One key principle is the \\u201cright to be forgotten\\u201d which gives users the right to have their data deleted. Another key princi...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=afc5a91d071fe2bde41ec46adb67d91bf61ec394\", \"img_url\": null, \"x\": -0.26537841007204505, \"y\": -0.37291602071312896, \"cluster\": 1, \"weights\": {\"Influence\": 1.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14754098360655737, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8326683196095167, \"summary\": null}, {\"id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment\", \"authors\": \"Chuanhao Li, Huazheng Wang, Mengdi Wang, Hongning Wang\", \"label\": \"Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment\", \"abstract\": \"Despite the recent advances in communication-efficient distributed bandit learning, most existing solutions are restricted to parametric models, e.g., linear bandits and generalized linear bandits (GLB). In comparison, kernel bandits, which search for non-parametric functions in a reproducing kernel...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b03f4454d2adbc866a8baf54595f93b262970658\", \"img_url\": null, \"x\": 0.0020507949602973736, \"y\": -0.9580938376254079, \"cluster\": 1, \"weights\": {\"Influence\": 3.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3770491803278688, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8777191566377237, \"summary\": null}, {\"id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Provably Auditing Ordinary Least Squares in Low Dimensions\", \"authors\": \"Ankur Moitra, Dhruv Rohatgi\", \"label\": \"Provably Auditing Ordinary Least Squares in Low Dimensions\", \"abstract\": \"Auditing the stability of a machine learning model to small changes in the training procedure is critical for engendering trust in practical applications. For example, a model should not be overly sensitive to removing a small fraction of its training data. However, algorithmically validating this p...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b0834fa559de36a9b6f1b8dd903c8a0f747f0845\", \"img_url\": null, \"x\": -0.3024160140093912, \"y\": -0.46456723693915203, \"cluster\": 1, \"weights\": {\"Influence\": 4.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4180327868852459, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8857639489641893, \"summary\": null}, {\"id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning Sparse Group Models Through Boolean Relaxation\", \"authors\": \"Yijie Wang, Yuan Zhou, Xiaoqing Huang, Kun Huang, Jie Zhang, Jianzhu Ma\", \"label\": \"Learning Sparse Group Models Through Boolean Relaxation\", \"abstract\": \"We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b397e8acf582c06bc3f86fc27f82f0c40bc3df9d\", \"img_url\": null, \"x\": -0.20282597861259072, \"y\": -0.4600226369785749, \"cluster\": 1, \"weights\": {\"Influence\": 2.6, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2557377049180328, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8539065713513857, \"summary\": null}, {\"id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives\", \"authors\": \"Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu\", \"label\": \"Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives\", \"abstract\": \"Motivated by various practical applications, we propose a novel and general formulation of targeted multi-objective hyperparameter optimization. Our formulation allows a clear specification of an automatable optimization goal using lexicographic preference over multiple objectives. We then propose a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b401419f27545f0b245e329faab1e8f4bf77a4e3\", \"img_url\": null, \"x\": 0.020265280884328316, \"y\": -0.788552393703786, \"cluster\": 1, \"weights\": {\"Influence\": 1.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1721311475409836, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.837495195005396, \"summary\": null}, {\"id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates\", \"authors\": \"Laurent Condat, Peter Richt\\u00e1rik\", \"label\": \"RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates\", \"abstract\": \"Proximal splitting algorithms are well suited to solving large-scale nonsmooth optimization problems, in particular those arising in machine learning. We propose a new primal\\u2013dual algorithm, in which the dual update is randomized; equivalently, the proximity operator of one of the function in the pr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=bad9c9f00577ad8ead06b93daf27f25cadadbe94\", \"img_url\": null, \"x\": -0.1783318612954344, \"y\": -0.9732293697729364, \"cluster\": 1, \"weights\": {\"Influence\": 7.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7131147540983607, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9436864537147411, \"summary\": null}, {\"id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"How gradient estimator variance and bias impact learning in neural networks\", \"authors\": \"Arna Ghosh, Yuhan Helena Liu, Guillaume Lajoie, Konrad Kording, Blake Aaron Richards\", \"label\": \"How gradient estimator variance and bias impact learning in neural networks\", \"abstract\": \"There is growing interest in understanding how real brains may approximate gradients and how gradients can be used to train neuromorphic chips. However, neither real brains nor neuromorphic chips can perfectly follow the loss gradient, so parameter updates would necessarily use gradient estimators t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=bd0af88287744affc0f23c775926c37cdd141900\", \"img_url\": null, \"x\": -0.1727419411038517, \"y\": -0.550865294552276, \"cluster\": 1, \"weights\": {\"Influence\": 1.4, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1377049180327869, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.830737569451165, \"summary\": null}, {\"id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence\", \"authors\": \"Margalit Glasgow, Colin Wei, Mary Wootters, Tengyu Ma\", \"label\": \"Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence\", \"abstract\": \"A major challenge in modern machine learning is theoretically understanding the generalization properties of overparameterized models. Many existing tools rely on uniform convergence  (UC), a property that, when it holds, guarantees that the test loss will be close to the training loss, uniformly ov...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c11939248e114e8276c15257a7a0c8164b2d450b\", \"img_url\": null, \"x\": -0.22071980097000618, \"y\": -0.7340011138035722, \"cluster\": 1, \"weights\": {\"Influence\": 5.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5409836065573771, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9098983259435859, \"summary\": null}, {\"id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Depth Separation with Multilayer Mean-Field Networks\", \"authors\": \"Yunwei Ren, Mo Zhou, Rong Ge\", \"label\": \"Depth Separation with Multilayer Mean-Field Networks\", \"abstract\": \"Depth separation\\u2014why a deeper network is more powerful than a shallow one\\u2014has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not appro...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c17e141b2697b3a4ee7b3786cca8ee92da09f549\", \"img_url\": null, \"x\": 0.011833916707463794, \"y\": -0.6413998756247444, \"cluster\": 1, \"weights\": {\"Influence\": 6.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5901639344262295, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9195520767353446, \"summary\": null}, {\"id\": \"c1a1e71154cf835b4196f7a6d6bfe5189750514a_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"The Responsibility Problem in Neural Networks with Unordered Targets\", \"authors\": \"Ben Hayes, Charalampos Saitis, Gy\\u00f6rgy Fazekas\", \"label\": \"The Responsibility Problem in Neural Networks with Unordered Targets\", \"abstract\": \"We discuss the discontinuities that arise when mapping unordered objects to neural network outputs of fixed permutation, referred to as the responsibility problem. Prior work has proved the existence of the issue by identifying a single discontinuity. Here, we show that discontinuities under such mo...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c1a1e71154cf835b4196f7a6d6bfe5189750514a\", \"img_url\": null, \"x\": -0.10704343805343246, \"y\": -0.8566721326604012, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7359687626396422, \"summary\": null}, {\"id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes\", \"authors\": \"Christian Alexander Haase, Christoph Hertrich, Georg Loho\", \"label\": \"Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes\", \"abstract\": \"We prove that the set of functions representable by ReLU neural networks with integer weights strictly increases with the network depth while allowing arbitrary width. More precisely, we show that $\\\\lceil\\\\log_2(n)\\\\rceil$ hidden layers are indeed necessary to compute the maximum of $n$ numbers, match...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c\", \"img_url\": null, \"x\": -0.009436914899422812, \"y\": -0.6831324391585903, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Sampling-based inference for large linear models, with application to linearised Laplace\", \"authors\": \"Javier Antoran, Shreyas Padhy, Riccardo Barbano, Eric Nalisnick, David Janz, Jos\\u00e9 Miguel Hern\\u00e1ndez-Lobato\", \"label\": \"Sampling-based inference for large linear models, with application to linearised Laplace\", \"abstract\": \"Large-scale linear models are ubiquitous throughout machine learning, with contemporary application as surrogate models for neural network uncertainty quantification; that is, the linearised Laplace method. Alas, the computational cost associated with Bayesian linear models constrains this method's ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c3b9310b8da36064f818daa6c0f4332bd3a30364\", \"img_url\": null, \"x\": -0.24778743850789275, \"y\": -0.4986141941690609, \"cluster\": 1, \"weights\": {\"Influence\": 3.1, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3049180327868853, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8635603221431444, \"summary\": null}, {\"id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Feature selection and low test error in shallow low-rotation ReLU networks\", \"authors\": \"Matus Telgarsky\", \"label\": \"Feature selection and low test error in shallow low-rotation ReLU networks\", \"abstract\": \"This work establishes low test error of gradient flow (GF) and stochastic gradient descent (SGD) on two-layer ReLU networks with standard initialization scale, in three regimes where key sets of weights rotate little (either naturally due to GF and SGD, or due to an artificial constraint), and makin...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ccd93ef604166d2d3688d1d963ea10a12affca84\", \"img_url\": null, \"x\": -0.2329598578801837, \"y\": -0.7721777494480019, \"cluster\": 1, \"weights\": {\"Influence\": 4.999999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4918032786885245, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9002445751518272, \"summary\": null}, {\"id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization\", \"authors\": \"Difan Zou, Yuan Cao, Yuanzhi Li, Quanquan Gu\", \"label\": \"Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization\", \"abstract\": \"Adaptive gradient methods such as Adam have gained increasing popularity in deep learning optimization. However, it has been observed in many deep learning applications such as image classification, Adam can converge to a different solution with a worse test error compared to (stochastic) gradient d...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cf40d9ace9751fd0a0c336f302c3be037cd460ae\", \"img_url\": null, \"x\": -0.36755313114027865, \"y\": -0.723200735415342, \"cluster\": 1, \"weights\": {\"Influence\": 7.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7131147540983607, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9436864537147411, \"summary\": null}, {\"id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"heading\": \"ICLR, 09 Feb 2023\", \"title\": \"Noise Injection as a Probe of Deep Learning Dynamics\", \"authors\": \"Noam Itzhak Levi, Itay Mimouni Bloch, Marat Freytsis, Tomer Volansky\", \"label\": \"Noise Injection as a Probe of Deep Learning Dynamics\", \"abstract\": \"We propose a new method to probe the learning mechanism of Deep Neural Networks (DNN) by perturbing the system using Noise Injection Nodes (NINs). These nodes inject uncorrelated noise via additional optimizable weights to existing feed-forward network architectures, without changing the optimizatio...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d046923d6036c80fdb5b95bc4920f6c5c995f22d\", \"img_url\": null, \"x\": -0.10105818810775426, \"y\": -0.5985163441015163, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7488457180354954, \"summary\": null}, {\"id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Symmetries, Flat Minima, and the Conserved Quantities of Gradient Flow\", \"authors\": \"Bo Zhao, Iordan Ganev, Robin Walters, Rose Yu, Nima Dehmamy\", \"label\": \"Symmetries, Flat Minima, and the Conserved Quantities of Gradient Flow\", \"abstract\": \"Empirical studies of the loss landscape of deep networks have revealed that many local minima are connected through low-loss valleys. Yet, little is known about the theoretical origin of such valleys. We present a general framework for finding continuous symmetries in the parameter space, which carv...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d18f2c27c0b6911b60ba471de84cdd0bcfc310bb\", \"img_url\": null, \"x\": -0.030416444291934373, \"y\": -0.6011844294646178, \"cluster\": 1, \"weights\": {\"Influence\": 2.875, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2827868852459017, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.859216134286853, \"summary\": null}, {\"id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Noise Is Not the Main Factor Behind the Gap Between Sgd and Adam on Transformers, But Sign Descent Might Be\", \"authors\": \"Frederik Kunstner, Jacques Chen, Jonathan Wilder Lavington, Mark Schmidt\", \"label\": \"Noise Is Not the Main Factor Behind the Gap Between Sgd and Adam on Transformers, But Sign Descent Might Be\", \"abstract\": \"The success of the Adam optimizer on a wide array of architectures has made it the default in settings where stochastic gradient descent (SGD) performs poorly. However, our theoretical understanding of this discrepancy is lagging, preventing the development of significant improvements on either algo...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d2edd2a991aca60d19867e723097621b249244ee\", \"img_url\": null, \"x\": -0.4385443170919518, \"y\": -0.7576942658638622, \"cluster\": 1, \"weights\": {\"Influence\": 6.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.639344262295082, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9292058275271031, \"summary\": null}, {\"id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks\", \"authors\": \"Mor Shpigel Nacson, Rotem Mulayoff, Greg Ongie, Tomer Michaeli, Daniel Soudry\", \"label\": \"The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks\", \"abstract\": \"We study the type of solutions to which stochastic gradient descent converges when used to train a single hidden-layer multivariate ReLU network with the quadratic loss. Our results are based on a dynamical stability analysis. In the univariate case, it was shown that linearly stable minima correspo...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d80d6f765dc8e5b73d4367685193aac019d84d32\", \"img_url\": null, \"x\": -0.13948122307615807, \"y\": -0.7371426465556333, \"cluster\": 1, \"weights\": {\"Influence\": 3.5999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3540983606557377, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.873214072934903, \"summary\": null}, {\"id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On The Relative Error of Random Fourier Features for Preserving Kernel Distance\", \"authors\": \"Kuan Cheng, Shaofeng H.-C. Jiang, Luojian Wei, Zhide Wei\", \"label\": \"On The Relative Error of Random Fourier Features for Preserving Kernel Distance\", \"abstract\": \"The method of random Fourier features (RFF), proposed in a seminal paper by Rahimi and Recht (NIPS'07), is a powerful technique to find approximate low-dimensional representations of points in (high-dimensional) kernel space, for shift-invariant kernels. While RFF has been analyzed under various not...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=da210e0565fa431b7d4b3a51da183ad6fc004bda\", \"img_url\": null, \"x\": -0.2548868499489281, \"y\": -0.8651985757751388, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm\", \"authors\": \"Toygun Basaklar, Suat Gumussoy, Umit Ogras\", \"label\": \"PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm\", \"abstract\": \"Multi-objective reinforcement learning (MORL) approaches have emerged to tackle many real-world problems with multiple conflicting objectives by maximizing a joint objective function weighted by a preference vector. These approaches find fixed customized policies corresponding to preference vectors ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6\", \"img_url\": null, \"x\": 0.7494950117016986, \"y\": -0.36174583235005564, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD\", \"authors\": \"Konstantinos Nikolakakis, Farzin Haddadpour, Amin Karbasi, Dionysios Kalogerias\", \"label\": \"Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD\", \"abstract\": \"We provide sharp path-dependent generalization and excess risk guarantees for the full-batch Gradient Descent (GD) algorithm on smooth losses (possibly non-Lipschitz, possibly nonconvex). At the heart of our analysis is an upper bound on the generalization error, which implies that average output st...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=de8f1bb911b27ce33656601d4ce080958115a5cc\", \"img_url\": null, \"x\": -0.3476884270728711, \"y\": -0.8898398930766487, \"cluster\": 1, \"weights\": {\"Influence\": 2.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2336065573770492, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8495623834950943, \"summary\": null}, {\"id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Computing all Optimal Partial Transports\", \"authors\": \"Abhijeet Phatak, Sharath Raghvendra, CHITTARANJAN TRIPATHY, Kaiyi Zhang\", \"label\": \"Computing all Optimal Partial Transports\", \"abstract\": \"We consider the classical version of the optimal partial transport problem. Let $\\\\mu$ (with a mass of $U$) and $\\\\nu$ (with a mass of $S$) be two discrete mass distributions with $S \\\\le U$ and let $n$ be the total number of points in the supports of $\\\\mu$ and $\\\\nu$. For a parameter $\\\\alpha \\\\in [0,S]$...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e1452d7eae10c11e6117d07c3aef56f1869d90d2\", \"img_url\": null, \"x\": -0.2730975061957807, \"y\": -0.7985490337625561, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport\", \"authors\": \"Lingkai Kong, Yuqing Wang, Molei Tao\", \"label\": \"Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport\", \"abstract\": \"The problem of optimization on Stiefel manifold, i.e., minimizing functions of (not necessarily square) matrices that satisfy orthogonality constraints, has been extensively studied. Yet, a new approach is proposed based on, for the first time, an interplay between thoughtfully designed continuous a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e23f64d5d1094e86bdf8f5306c09a3e2563d0853\", \"img_url\": null, \"x\": -0.23460374834577125, \"y\": -0.6684056121959684, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"e93479be9ce2293697f01793118f1c5f8fb490cc_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"On a Relation Between the Rate-Distortion Function and Optimal Transport\", \"authors\": \"Eric Lei, Hamed Hassani, Shirin Saeedi Bidokhti\", \"label\": \"On a Relation Between the Rate-Distortion Function and Optimal Transport\", \"abstract\": \"We discuss a relationship between rate-distortion and optimal transport (OT) theory, even though they seem to be unrelated at first glance. In particular, we show that a function defined via an extremal entropic OT distance is equivalent to the rate-distortion function. We numerically verify this re...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e93479be9ce2293697f01793118f1c5f8fb490cc\", \"img_url\": null, \"x\": -0.27804659338890586, \"y\": -0.7409549563110231, \"cluster\": 1, \"weights\": {\"Influence\": 1.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14754098360655737, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7503704664956616, \"summary\": null}, {\"id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation\", \"authors\": \"Yao Shu, Zhongxiang Dai, Weicong Sng, Arun Verma, Patrick Jaillet, Bryan Kian Hsiang Low\", \"label\": \"Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation\", \"abstract\": \"Zeroth-order (ZO) optimization, in which the derivative is unavailable, has recently succeeded in many important machine learning applications. Existing algorithms rely on finite difference (FD) methods for derivative estimation and gradient descent (GD)-based approaches for optimization. However, t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e9570215e36febb507fa434f592249cd070bf2ba\", \"img_url\": null, \"x\": -0.08160397005638331, \"y\": -0.8127227568857253, \"cluster\": 1, \"weights\": {\"Influence\": 1.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.13524590163934427, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.830254881911577, \"summary\": null}, {\"id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution\", \"authors\": \"Sungyoon Lee, Cheongjae Jang\", \"label\": \"A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution\", \"abstract\": \"For full-batch gradient descent (GD), it has been empirically shown that the sharpness, the top eigenvalue of the Hessian, increases and then hovers above $2/\\\\text{(learning rate)}$, and this is called ``the edge of stability'' phenomenon. However, it is unclear why the sharpness is somewhat larger ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e9b61d34a1e826e82d189e183b32eb288a5094cc\", \"img_url\": null, \"x\": -0.4424100805401987, \"y\": -0.7124253815092169, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"heading\": \"ICLR, 16 Mar 2023\", \"title\": \"Training Data Eigenvector Dynamics in the EigenPro 3 Implementation of the Neural Tangent Kernel and Recursive Feature Machines\", \"authors\": \"Cyril Gorlla\", \"label\": \"Training Data Eigenvector Dynamics in the EigenPro 3 Implementation of the Neural Tangent Kernel and Recursive Feature Machines\", \"abstract\": \"There has been much recent work on kernel methods as a viable alternative to deep neural networks (DNNs). The advent of the $\\\\textit{Neural Tangent Kernel}$ (NTK) has brought on renewed interest in these methods and their application to typical deep learning tasks. Recently, kernels have been shown ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ea811f56d75a673b642b37a9a6615a325e4d2ae8\", \"img_url\": null, \"x\": -0.35644068290284353, \"y\": -0.5942201569485126, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7258796017681175, \"summary\": null}, {\"id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Fundamental limits on the robustness of image classifiers\", \"authors\": \"Zheng Dai, David Gifford\", \"label\": \"Fundamental limits on the robustness of image classifiers\", \"abstract\": \"We prove that image classifiers are fundamentally sensitive to small perturbations in their inputs. Specifically, we show that given some image space of $n$-by-$n$ images, all but a tiny fraction of images in any image class induced over that space can be moved outside that class by adding some pert...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ed87bd7618eaad0b1a6f86623881c9589526728f\", \"img_url\": null, \"x\": -0.3270358893165929, \"y\": -0.7921997173523042, \"cluster\": 1, \"weights\": {\"Influence\": 1.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14754098360655735, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8326683196095167, \"summary\": null}, {\"id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Error Analysis of Fitted $Q$-iteration with ReLU-activated Deep Neural Networks\", \"authors\": \"Lican Kang, Yuan Luo, Han Yuan, Chang Zhu\", \"label\": \"Error Analysis of Fitted $Q$-iteration with ReLU-activated Deep Neural Networks\", \"abstract\": \"Deep reinforcement learning (RL) has grown rapidly with the development of backbone feedforward neural networks (FNNs). However, there remains a theoretical gap when researchers conduct error analysis of the FNNs-based RL process. In this work, we provide an error analysis for deep-fitted $Q$-iterat...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f0c7296d18c7ae97faae0a2575ef11bc007931cf\", \"img_url\": null, \"x\": 0.06278228943906462, \"y\": -0.6267441686127168, \"cluster\": 1, \"weights\": {\"Influence\": 2.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2213114754098361, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.771973022279691, \"summary\": null}, {\"id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning in temporally structured environments\", \"authors\": \"Matt Jones, Tyler R. Scott, Mengye Ren, Gamaleldin Fathy Elsayed, Katherine Hermann, David Mayo, Michael Curtis Mozer\", \"label\": \"Learning in temporally structured environments\", \"abstract\": \"Natural environments have temporal structure at multiple timescales. This property is reflected in biological learning and memory but typically not in machine learning systems. We advance a multiscale learning method in which each weight in a neural network is decomposed as a sum of subweights with ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f17611b97e72578ed47f180970702083209ef076\", \"img_url\": null, \"x\": -0.03617392279864015, \"y\": -0.5214421647758253, \"cluster\": 1, \"weights\": {\"Influence\": 2.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2213114754098361, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8471489457971546, \"summary\": null}, {\"id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On Achieving Optimal Adversarial Test Error\", \"authors\": \"Justin D. Li, Matus Telgarsky\", \"label\": \"On Achieving Optimal Adversarial Test Error\", \"abstract\": \"We first elucidate various fundamental properties of optimal adversarial predictors: the structure of optimal adversarial convex predictors in terms of optimal adversarial zero-one predictors, bounds relating the adversarial convex loss to the adversarial zero-one loss, and the fact that continuous ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f32623810587308a48b6d618224dfff5d8728ac5\", \"img_url\": null, \"x\": -0.5012883268910133, \"y\": -0.666000109655506, \"cluster\": 1, \"weights\": {\"Influence\": 2.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24590163934426232, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.851975821193034, \"summary\": null}, {\"id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Asynchronous Distributed Bilevel Optimization\", \"authors\": \"Yang Jiao, Kai Yang, Tiancheng Wu, Dongjin Song, Chengtao Jian\", \"label\": \"Asynchronous Distributed Bilevel Optimization\", \"abstract\": \"Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches r...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f3646495b063d6dfc79c414af5beb73ed88c9c06\", \"img_url\": null, \"x\": -0.11819334906464767, \"y\": -0.9176163924237023, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.19672131147540986, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8423220704012754, \"summary\": null}, {\"id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Fast Nonlinear Vector Quantile Regression\", \"authors\": \"Aviv A. Rosenberg, Sanketh Vedula, Yaniv Romano, Alexander Bronstein\", \"label\": \"Fast Nonlinear Vector Quantile Regression\", \"abstract\": \"$$\\n\\\\newcommand{\\\\rvar}[1]{\\\\mathrm {#1}}\\n\\\\newcommand{\\\\rvec}[1]{\\\\boldsymbol{\\\\mathrm{#1}}}\\n$$\\nQuantile regression (QR) is a powerful tool for estimating one or more conditional quantiles of a target variable $\\\\rvar{Y}$ given explanatory features $\\\\rvec{X}$.\\nA limitation of QR is that it is only defined ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f994e729a3a7b42e2546585fa5bf28d22058bf96\", \"img_url\": null, \"x\": -0.2628052608109634, \"y\": -0.7126952132220695, \"cluster\": 1, \"weights\": {\"Influence\": 3.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.33196721311475413, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8688698850786116, \"summary\": null}, {\"id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Fisher-Legendre (FishLeg) optimization of deep neural networks\", \"authors\": \"Jezabel R Garcia, Federica Freddi, Stathi Fotiadis, Maolin Li, Sattar Vakili, Alberto Bernacchia, Guillaume Hennequin\", \"label\": \"Fisher-Legendre (FishLeg) optimization of deep neural networks\", \"abstract\": \"Incorporating second-order gradient information (curvature) into optimization can dramatically reduce the number of iterations required to train machine learning models. In natural gradient descent, such information comes from the Fisher information matrix which yields a number of desirable properti...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fa4222cf35875a4d6e810d7573542822251ea95c\", \"img_url\": null, \"x\": -0.15332567606378056, \"y\": -0.5859100035246927, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09836065573770493, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8230145688177581, \"summary\": null}, {\"id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study\", \"authors\": \"Yiwen Kou, Zixiang Chen, Yuan Cao, Quanquan Gu\", \"label\": \"How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study\", \"abstract\": \"Semi-supervised learning is a popular machine learning paradigm that utilizes a large amount of unlabeled data as well as a small amount of labeled data to facilitate learning tasks. While semi-supervised learning has achieved great success in training neural networks, its theoretical understanding ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4\", \"img_url\": null, \"x\": -0.44391656494450094, \"y\": -0.5626878465673603, \"cluster\": 1, \"weights\": {\"Influence\": 5.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5737704918032787, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9163341598047583, \"summary\": null}, {\"id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data \", \"authors\": \"Spencer Frei, Gal Vardi, Peter Bartlett, Nathan Srebro, Wei Hu\", \"label\": \"Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data \", \"abstract\": \"The implicit biases of gradient-based optimization algorithms are conjectured to be a major factor in the success of modern deep learning.  In this work, we investigate the implicit bias of gradient flow and gradient descent in two-layer fully-connected neural networks with leaky ReLU activations wh...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fafd70b2b9d956095a7bb5b27052fed9b5284db3\", \"img_url\": null, \"x\": -0.14714210048925322, \"y\": -0.6997264585303389, \"cluster\": 1, \"weights\": {\"Influence\": 7.800000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7672131147540985, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9543055795856757, \"summary\": null}], \"links\": [{\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"strength\": 0.23662360000000005}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.24690986666666667}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"strength\": 0.21098775333333336}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"strength\": 0.8411232666666667}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.21865823333333334}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.2176089}, {\"source_id\": \"08814ac05c6bad4546e7a8146c6fff0b6d74b841_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.21015102333333335}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"strength\": 0.3102317}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"strength\": 0.25300860000000003}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"strength\": 0.6086696333333335}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.6812855}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.6164509200000001}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.9158934000000001}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"strength\": 0.29969833333333334}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.2998326333333333}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.8892645333333333}, {\"source_id\": \"0c113f512672baa5caa0388b671bfeef4f8b7a95_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.24797713333333335}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"strength\": 0.6442501800000001}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"strength\": 0.29996765000000003}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"strength\": 0.2592646333333334}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.30861143333333335}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"strength\": 0.2201764666666667}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.31592898}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.21804710000000002}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"strength\": 0.6183584833333333}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.6755016666666667}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.5578234200000001}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.2896937333333333}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.8469435000000001}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.6415390833333334}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"strength\": 0.30182663333333337}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.2915685}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.2856691333333333}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.6358999000000001}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.7146373333333333}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.8622364166666667}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2827988166666667}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.24384583333333334}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.2938743833333334}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.3334074}, {\"source_id\": \"0c34e3f02eb3e645183e05e122217afc5246a3d3_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.27751020000000004}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"strength\": 0.7038675833333334}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"strength\": 0.29027366666666665}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.7309491333333333}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.28452303333333334}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.6711587}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.2977077666666667}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.6132535800000001}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.2748141333333333}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.2959753666666667}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"strength\": 1.0486212}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.2668736}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.7168813833333334}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"strength\": 0.6285870366666667}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.5717154}, {\"source_id\": \"0c6075c6cd12e0d7f8a9e3ed034018761a50a632_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.31219263333333336}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"strength\": 0.22364626666666668}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.23876906666666667}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"strength\": 0.23853696666666666}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"strength\": 0.24754116666666667}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"strength\": 0.22461333333333336}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.2347427}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.21240141666666668}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2365279}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.23194670000000003}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.24390803333333336}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2350064666666667}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.3197801666666667}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.25210451666666667}, {\"source_id\": \"1746610555a537cb3593ad9a61cdbc4e666629d9_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.2624125666666667}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"strength\": 0.28047025000000003}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"strength\": 0.5834295666666667}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"strength\": 0.7401059200000001}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"strength\": 0.2957828533333333}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.31592253333333337}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.26661073333333335}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"strength\": 0.3083215666666667}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.6045892}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2777466}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.7023264666666668}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"strength\": 0.32573340000000006}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.3002484}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.30251733333333336}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.30435856666666666}, {\"source_id\": \"1d06f4b8c38e85fde96f753c3161dfcc39b5d5cb_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.2798839333333334}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.29512363333333336}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.6336029000000001}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.31257713333333337}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.2730228333333334}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.939252}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.28984183333333335}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.2739757666666667}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.2708805}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.8384776333333332}, {\"source_id\": \"1d725c899881e250efb01016809debea53c3e43a_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.5517719866666666}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"strength\": 0.22933654666666667}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"strength\": 0.3038432}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.37052592}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"strength\": 0.23431175333333334}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"strength\": 0.23694900000000002}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"strength\": 0.7984234533333334}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.6238124333333332}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.6621832133333334}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.2972091333333334}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2963675666666667}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.2889183}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.27080753333333335}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.23175393333333333}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.7215652833333334}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.3266335666666667}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.6256097333333335}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.28000806666666667}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.2993188333333333}, {\"source_id\": \"1f25b3d33f6441b9c1e99d0e8a31371b9d6c4184_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.2885920333333334}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"strength\": 0.2422822666666667}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.2755667333333333}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.26793653333333334}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.23050856666666666}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.2180093}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.23317166666666667}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.6673465166666668}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.21818593333333336}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.28095603333333335}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"strength\": 0.23326772}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.2683979}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.25044523333333335}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.2568121}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.2599383}, {\"source_id\": \"211991a3a9ac458b35866673765e188c6b7b2f5c_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.2419939}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.29020636666666666}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"strength\": 0.31366990000000006}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"strength\": 0.32947393333333336}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"strength\": 0.27632070000000003}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.2792731466666667}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.3185416}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.28816373333333334}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.2583821333333334}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.26128255333333333}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.7912217333333333}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.2526487666666667}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.31159688333333335}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.26564233333333337}, {\"source_id\": \"21c550a9327392691fd9fd210c9ed68281c76d4b_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.24629585333333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"strength\": 0.32337898333333337}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.7641062833333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.32282856666666665}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.26879135000000004}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.4187362666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.6624015833333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"strength\": 0.27267855333333335}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.6539619333333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"strength\": 0.3104522333333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.3296985666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.8355400666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"strength\": 0.3371427666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.6402988333333334}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.2830754866666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.29263900000000004}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.6826229666666668}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3592002866666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.7873874666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.28898628333333337}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.3292668}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2750525666666667}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.32992088333333336}, {\"source_id\": \"2796c22fba65dd6950f2a6250834431cd78777e3_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.8461433666666667}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"strength\": 0.28886678}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.2927522533333334}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"strength\": 0.3300762166666667}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.2979482666666667}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.31823781333333334}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.2965931}, {\"source_id\": \"2ca9edbba8b0efa31314fea9a1d8fbf9941ef592_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.28191035000000003}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"strength\": 0.3029075}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.39744903333333337}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.26436006666666667}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"strength\": 0.2760503666666667}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"strength\": 0.29651878333333337}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.7330710833333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.36067716666666666}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.2984291333333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"strength\": 0.32758458333333335}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.36221331333333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.34231113333333335}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.3189093533333333}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.31079043333333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.6991270466666668}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.7016432666666668}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2825962666666667}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2962245333333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3337427333333334}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2809688666666667}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.24367592000000005}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.30853035}, {\"source_id\": \"2df915e2bb7d12ea7f56ea94d0ec74ca4b60e498_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3342701}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"strength\": 0.38572965000000003}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.2974167666666667}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.29253380000000007}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"strength\": 0.27139434666666673}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.20308895000000002}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.3741183666666667}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"strength\": 0.2943495666666667}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.2991844}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.6509128533333334}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.35428955000000006}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.7289394333333334}, {\"source_id\": \"2ee383ebff429973fdd9d255c87ce7fad9d3e214_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.34301526666666665}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"strength\": 0.2755534666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"strength\": 0.28228966666666666}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"strength\": 0.2735137666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"strength\": 0.30375473333333336}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.2963744}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"strength\": 0.8180631333333335}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"strength\": 0.29211190000000004}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.38950386666666664}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"strength\": 0.2814262666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"strength\": 0.3301986666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 1.0296974666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.8295028}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.28250943333333334}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.7801821666666666}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.2899929666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.31636630000000004}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.38139081333333336}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"strength\": 0.20769516000000002}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.6866964133333333}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.31017115333333334}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.3111625}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.29291135}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.21436615}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.31787403333333336}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.38555523333333336}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"strength\": 0.3553984666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.27191923333333334}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.28403360000000005}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.42056198}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.3087515333333334}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 1.0419054}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.8507905}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2963895666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.3673021666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.8158700666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.34282348666666673}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.3565107466666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.37510432}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.2612314866666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.2472327}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.2937789666666667}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.3601767}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.295787}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.36654823333333336}, {\"source_id\": \"31ef10b0d82197012874d92618be35699065046d_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.7951528999999999}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"strength\": 0.32626538666666666}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.2378474666666667}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2859166666666667}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.5791230866666667}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.26513786666666667}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.23898816666666667}, {\"source_id\": \"36c51386a38b996e7eeaa7b6c7e7c8fbbd6c1a53_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3262064666666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.24777298000000003}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.2564013}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.27842483333333334}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.2474843866666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"strength\": 0.5137368}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.5803085166666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.2932354666666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.2474777466666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.2831753666666667}, {\"source_id\": \"3cdecc1dbf1de1147c41ae8805f7e79eedf48e3f_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.5489654}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"strength\": 0.3139724466666667}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"strength\": 0.25343913333333334}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.2077620666666667}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.6276030666666668}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.5976788333333334}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.37788210000000005}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.39509313333333335}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.27159710000000004}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.5972920166666666}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3149409}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.3459689}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.21867828333333336}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.3293082666666667}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.2673376333333333}, {\"source_id\": \"40b3decaf6b173444b2a00ff6e950f3b976fc3e5_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.26258146666666665}, {\"source_id\": \"415d1e23935390eca56780afdd0c64cc5ea0397f_0\", \"target_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"strength\": 0.2291635}, {\"source_id\": \"415d1e23935390eca56780afdd0c64cc5ea0397f_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.24162134666666665}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"strength\": 0.24692066666666668}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"strength\": 0.52923175}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.28045603333333335}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.25128855333333333}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.23583320000000002}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.23621756666666666}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.25403111666666667}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.2716254666666667}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.5885823666666667}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.23830900000000002}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.33243523333333336}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.28513730000000004}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.5467488466666667}, {\"source_id\": \"421133736c7b26adee4ced798b5ed8a4ce821c1e_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.23545736666666667}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"strength\": 0.23639523333333334}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.6986949333333334}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"strength\": 0.5632066200000001}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.27371648}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"strength\": 0.6494971666666667}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"99ba665029e52a1b2066be025866c24222059889_0\", \"strength\": 0.18085016666666667}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.2860982}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"strength\": 0.3099111166666667}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.30819865}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.23722073333333332}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.33052233333333336}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.6251987333333333}, {\"source_id\": \"424c5f5bf76d931d5edc2b6e5df9f7b1a57b5c45_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.5910332166666667}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"strength\": 0.31281428}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.2419094}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.6574334666666667}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.560554}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.6032606833333334}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.23497146666666668}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.22854523333333335}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.22348493333333333}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.2387601666666667}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.23617653333333333}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.24512319999999999}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.5037557}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.22060680000000002}, {\"source_id\": \"43cb581da533a48b975471f4100f055cbfcd57ce_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.2550914}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.20829455000000002}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"strength\": 0.26170705}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"strength\": 0.2935195666666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.6265749666666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.6634711333333334}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.3587478333333334}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.32971323333333336}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.3067873133333333}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"strength\": 0.8962281000000001}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.37034703333333335}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.30148426666666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.28183983333333334}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"strength\": 0.309398}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.6459034666666668}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.2500963333333333}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.6022595666666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.2668757}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3522751866666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.3168962}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.33269960000000004}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2837752}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.2869535833333333}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.7834909666666667}, {\"source_id\": \"45c00944e0ae7ef63f88c57eb3abd7337982cc5b_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.33144155}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"strength\": 0.21587890000000004}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"strength\": 0.9309259999999999}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.6001317333333334}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.286184}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.2947364666666667}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.32183901333333337}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"strength\": 0.6575397666666667}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.2833639333333334}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.30413723333333337}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.4189711}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.31437960000000004}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.31141655}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.29092466666666666}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.5804179133333334}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.28783861666666666}, {\"source_id\": \"460c76a8c7bda3cea365a11c53781e39a20afa4e_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.6235569666666667}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.21371678666666669}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"strength\": 0.5703016000000001}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"strength\": 0.21087904666666668}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.2108395}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.26914520000000003}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.21085140000000002}, {\"source_id\": \"476beabca05f9acad45961fd4e7f014cb58c82ff_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.21589475}, {\"source_id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.24130203333333333}, {\"source_id\": \"4781893f1f30259bef6724033986eb3a78c3621e_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.2229808666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"strength\": 0.3545014666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.3927737}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.2874910666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.7022472666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.6837233333333335}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"strength\": 0.36017621333333333}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.2683681666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.26217608}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.2528789}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.68623975}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.27550008000000004}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.39086773333333336}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.7872999}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.38392396666666667}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.36157970000000006}, {\"source_id\": \"4930f93a4ead2967a42e34cb6471bbe2407ed651_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.6964914}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.3040416666666667}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.2622223}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.27369845}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.2707967}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.2912630666666667}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.7649553666666666}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.5261815333333334}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.5395151666666667}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.2737192}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.5465366333333335}, {\"source_id\": \"4bfab236f516e2ad7efb4fa9457521968c08c9a7_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.2754997}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.2944546333333333}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.33390785333333334}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.28091133333333335}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.3082996333333334}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.6876602}, {\"source_id\": \"4c3155a7dc9c0785bde17e6b4fec26ae8f281e58_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.6272142666666667}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"strength\": 0.30839553333333336}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.37579840000000003}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.32058573333333334}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"strength\": 0.2149446866666667}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.65389567}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.7431272633333335}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3610475}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.8266479666666666}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.8813376333333334}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.7384148866666667}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.7162020666666666}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.6789384533333334}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.9587680000000001}, {\"source_id\": \"4ecd0cbaaa4f882bb71db0546e0bced8ab67a8b2_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.38671618}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"strength\": 0.24366986666666668}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.21206019}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.35790196666666674}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.28542063333333334}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.2855743666666667}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.237926}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.755325}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.73909508}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.2770364}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.6028461333333334}, {\"source_id\": \"53433146de0db29171a65c53c4130f59cd247f0d_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.6143263}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"strength\": 0.27163948000000004}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.32193008333333334}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2807118666666667}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"strength\": 0.2607737466666667}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.2636367333333334}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.3124830333333334}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.27713478}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.23412295000000002}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2629421666666667}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.61303683}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.2848952}, {\"source_id\": \"536db97acc7c6028eae840523031ad3f26a83908_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.6358483500000001}, {\"source_id\": \"5390075b7f08fed5a2a1e2e855a8cc503b15958e_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.17497716666666668}, {\"source_id\": \"5390075b7f08fed5a2a1e2e855a8cc503b15958e_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.17160979}, {\"source_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.2710533133333334}, {\"source_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.29371546666666665}, {\"source_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"target_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"strength\": 0.25740763333333333}, {\"source_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.3332976}, {\"source_id\": \"560694073022b93a92267e067baddd5490dd98db_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.2549617666666667}, {\"source_id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"target_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"strength\": 0.2540695666666667}, {\"source_id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.5608016}, {\"source_id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.2758012666666667}, {\"source_id\": \"58ffdf8508266fa99dfcea315013ff52c1f815b1_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2541549333333334}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"strength\": 0.31797400000000003}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"strength\": 0.2852840666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.6659998333333333}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"strength\": 0.3135855666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.32974630000000005}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.3141923666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"strength\": 0.33048678000000004}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.33766266666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.7220510333333334}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.6272877000000001}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.2941944666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.2443462}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.6752181000000002}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.34910192}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.35414353333333337}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.2556679333333333}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.6113362500000001}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3220486333333334}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.8032103666666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2829148866666667}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.59330925}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.7919528866666666}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.3665233333333333}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.29818106666666666}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.2612462}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.27594450000000004}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3454566333333334}, {\"source_id\": \"59bd8836e93870156ae5b56d425add5dd8286b9c_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.7118482}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.2685456666666667}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"strength\": 0.590679}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.2711329333333333}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.26182363333333336}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.33399316666666673}, {\"source_id\": \"5b561ebefad668bdfe8a3f6d944eb95ec2bfddd6_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.2887302133333333}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"strength\": 0.6962711666666668}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.28771036666666666}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.7600573333333334}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.3169766666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.30977123333333334}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.28668162}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.27052561333333336}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"strength\": 0.30964590000000003}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.3344867}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.3043605666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.3367933666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.26618843333333336}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.22224710000000003}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.29959078333333333}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.30448586666666666}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.22672668333333335}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.28859804666666666}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.40092}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.40646985333333335}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.4232345666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.3776357666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.27000816666666666}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.2699892}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.2889720333333333}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.3166857666666667}, {\"source_id\": \"5bf49762e18f4ef1d5fac9e05f16f1845fd06e31_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.3401239533333334}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"strength\": 0.2943606}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.29684738000000005}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.20760601}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.26950250000000003}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"strength\": 0.8331598333333333}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.5503790333333334}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2721727}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.21827675000000002}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.2842333}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.28617440000000005}, {\"source_id\": \"5f2b126f7b685acd5b40570d2582a193159458dd_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.5960050333333333}, {\"source_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.2828561666666667}, {\"source_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.5916034000000001}, {\"source_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.2877274}, {\"source_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.7859584333333334}, {\"source_id\": \"6010d9b9d76b36207123f320865f84e6a1318b61_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.2402726}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.3022574333333333}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.20209791666666668}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.2934204}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.26925233333333337}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.23438021333333336}, {\"source_id\": \"609600ec9a5871c02b8583cee5e7fb961d593fe6_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.32670583333333336}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"strength\": 0.31619223333333335}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"strength\": 0.6925254666666667}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"strength\": 0.21109239000000002}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"strength\": 0.24735463333333335}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"strength\": 0.30013140000000005}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.34902263333333333}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.29716413333333336}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.3155659666666667}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.32473240000000003}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.29779496666666666}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.2303929}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.7520406000000001}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.31145533333333336}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.28225718333333333}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.28288796666666666}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.30017308666666664}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.33346943333333334}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.2661819666666667}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.28556358333333337}, {\"source_id\": \"6561ce95a78eda28a72bcf0b1c96215e18091ad0_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.7400796333333334}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.2901476}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.3269354}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.25273318}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.2792285333333333}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.30693033333333336}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.7041410333333333}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.300084}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2899072533333334}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.28959843333333335}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.2877409333333334}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.27670008333333335}, {\"source_id\": \"691ec4cd76ed021fb414e9ff33233d25d87d8bff_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.32799815000000004}, {\"source_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"target_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"strength\": 0.29177223333333335}, {\"source_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.6594702333333333}, {\"source_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 1.0378355333333333}, {\"source_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.29268323333333335}, {\"source_id\": \"6990d6ab5c9dc47673daacf4be4911e554fe97af_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.2798811666666667}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.6886748333333335}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"strength\": 0.36831780000000003}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.6996235000000001}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.7756870166666667}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.2455632}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.33072225}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.2946926}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"strength\": 0.2919545333333333}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.9429347333333333}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.29811808333333334}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.34795153333333334}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.3740467666666667}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.3619122}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.8132210333333334}, {\"source_id\": \"6a3b1b48c5c2b9fd65c0262e0c3b22665674ac57_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.34261645}, {\"source_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.5926233866666667}, {\"source_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.7203485000000001}, {\"source_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.5991203333333335}, {\"source_id\": \"70885518c23471a5d65e401a3eee82d234e45abf_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.2513942333333334}, {\"source_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.20423567333333334}, {\"source_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.20972959000000002}, {\"source_id\": \"74387200905db3e054a9013071f4a2a20127dc8f_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.24151946666666665}, {\"source_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"target_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"strength\": 0.2073560066666667}, {\"source_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"target_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"strength\": 0.21462821999999998}, {\"source_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.28167338000000003}, {\"source_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.22567126666666668}, {\"source_id\": \"74fdbac0bcf2ea47f1ed52610053fbbaf8e0b0b8_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.21879963333333333}, {\"source_id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.6218663333333334}, {\"source_id\": \"7c175f57042297e15a4014c3243c010fe5a91d43_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.3046073}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.7302581666666668}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.2910488666666667}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.3353662866666667}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.64990893}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.32299923333333336}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.33560059999999997}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.3403502}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.3171679333333334}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.33831923333333336}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3355640166666667}, {\"source_id\": \"80e24b14bb02af11590f105e1f3d1ca63aa2a46e_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.6615599666666667}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.3107167666666667}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.3199708333333333}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.3202041666666667}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"c1a1e71154cf835b4196f7a6d6bfe5189750514a_0\", \"strength\": 0.2012075666666667}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.32094902000000003}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.37967371666666666}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.30956676666666666}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.3295308666666667}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.24866523333333335}, {\"source_id\": \"88c536854961a03798ae492a6598ab070d7426e7_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.7242374}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"strength\": 0.2584116}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.3019124}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.2663279}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"strength\": 0.2689549}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.2689269}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.32124663333333336}, {\"source_id\": \"89efb4aa4736421ceb48d23add92b3fbb5d1aa5d_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.27720493333333335}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.28714851333333336}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.7569412666666667}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.3276713666666667}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.33533605}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.2655520666666667}, {\"source_id\": \"91ecb4f7f14a35a8e5f2ea0192932b6a90932c2f_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3666392666666667}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"99ba665029e52a1b2066be025866c24222059889_0\", \"strength\": 0.18173093333333334}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"strength\": 0.32023875}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"strength\": 0.6908408166666666}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"strength\": 0.30252013333333333}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.216766}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.7112912333333333}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.6211024866666667}, {\"source_id\": \"98f69cb8b49e6445ac9fecbc7b833416c937c682_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.33084981333333335}, {\"source_id\": \"99ba665029e52a1b2066be025866c24222059889_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.19611573333333335}, {\"source_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"target_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"strength\": 0.6667694}, {\"source_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.2669228866666667}, {\"source_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.24832443333333337}, {\"source_id\": \"9ac3a7be0ec3a5588546f33b3a9825d8a1a229b7_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.2970303666666667}, {\"source_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.32193663333333333}, {\"source_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.2634535666666667}, {\"source_id\": \"9e1d1e8bfac6e6dfe8d35b0cd18b3860e003ef1e_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.7183568}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"9ea82d4340917f03855d4230479d560d6386cec5_0\", \"strength\": 0.230168}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"strength\": 0.3468598666666667}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.65579615}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.31835783333333334}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.6554297866666667}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3322487333333334}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.6272869333333333}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.26344271333333336}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.2959537}, {\"source_id\": \"9e7727ec223f4b90eeedadbe6925f5d80f281fc7_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.2995552666666667}, {\"source_id\": \"9ea82d4340917f03855d4230479d560d6386cec5_0\", \"target_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"strength\": 0.7172193666666666}, {\"source_id\": \"9ea82d4340917f03855d4230479d560d6386cec5_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.23605560000000003}, {\"source_id\": \"9ea82d4340917f03855d4230479d560d6386cec5_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.24876116666666667}, {\"source_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"target_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"strength\": 0.2643724333333333}, {\"source_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.59937925}, {\"source_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.28762173333333335}, {\"source_id\": \"9f021d6ba2ee9f90db9f57beffaf82a7944f7c48_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.33308011333333337}, {\"source_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"target_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"strength\": 0.5943051}, {\"source_id\": \"a0efb9f11f4f53e23054f6741abe8f31b61862ae_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.20073604666666667}, {\"source_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"target_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"strength\": 0.5688674}, {\"source_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.5608772333333334}, {\"source_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.8055742333333333}, {\"source_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.306361}, {\"source_id\": \"a1d26e653910490a9acbc590431de1d12f12049f_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.2547479}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"strength\": 0.6656532333333334}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"strength\": 0.2688109333333334}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.24998763333333335}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"strength\": 0.3393459666666667}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.31870893333333333}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.33083063333333335}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"c1a1e71154cf835b4196f7a6d6bfe5189750514a_0\", \"strength\": 0.2181709}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.23137223333333334}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.7182396666666666}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.31207643333333335}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2933656666666667}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.6908275666666668}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.7869199}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.3063206666666667}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.31816088333333337}, {\"source_id\": \"a24af3846e706489a5fc3a5a363217250f179f54_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.7817304833333334}, {\"source_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.34460151666666666}, {\"source_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.30242423333333335}, {\"source_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.3151921833333333}, {\"source_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.28172121666666666}, {\"source_id\": \"a707eb33e0d88a559bc543148ac5f01651f03cf9_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.31594663333333334}, {\"source_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"target_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"strength\": 0.30538186666666667}, {\"source_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"target_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"strength\": 0.3081359666666667}, {\"source_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3327162166666667}, {\"source_id\": \"a7c28f8861965143923f6f3ec84cb4fc7d002905_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.33675993333333337}, {\"source_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.29515683333333337}, {\"source_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2988761666666667}, {\"source_id\": \"ae67f0cc885bd798eb6805ab26c191087f371eae_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.2815603133333333}, {\"source_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.28435328}, {\"source_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.31933848000000004}, {\"source_id\": \"af2a26e0e430576d6bd2075f4a33421a151384b8_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.5819494533333334}, {\"source_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"target_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"strength\": 0.31171183333333335}, {\"source_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.5364218633333333}, {\"source_id\": \"afc5a91d071fe2bde41ec46adb67d91bf61ec394_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.2620945666666667}, {\"source_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"target_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"strength\": 0.2689128333333334}, {\"source_id\": \"b03f4454d2adbc866a8baf54595f93b262970658_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.5226790000000001}, {\"source_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"target_id\": \"b397e8acf582c06bc3f86fc27f82f0c40bc3df9d_0\", \"strength\": 0.556915}, {\"source_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.30850316666666666}, {\"source_id\": \"b0834fa559de36a9b6f1b8dd903c8a0f747f0845_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.2856784}, {\"source_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"target_id\": \"dd6bcd859d2927b978b50f2f6a83b7c7483cd2a6_0\", \"strength\": 0.3616657}, {\"source_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.21962931333333335}, {\"source_id\": \"b401419f27545f0b245e329faab1e8f4bf77a4e3_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.24546410000000002}, {\"source_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"target_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"strength\": 0.2621656666666667}, {\"source_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.2703332666666667}, {\"source_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2662282}, {\"source_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.30018253333333333}, {\"source_id\": \"bad9c9f00577ad8ead06b93daf27f25cadadbe94_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.27313074666666665}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.7038389333333335}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.38698200000000005}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.37283648333333336}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.40839773333333335}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.33828748000000003}, {\"source_id\": \"bd0af88287744affc0f23c775926c37cdd141900_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.36099803333333336}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.36013116666666667}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"strength\": 0.2827363333333333}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3526463}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.3147821}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.33473058}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.3160578}, {\"source_id\": \"c11939248e114e8276c15257a7a0c8164b2d450b_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.38164258333333334}, {\"source_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"target_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"strength\": 0.3175256}, {\"source_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.3395534333333333}, {\"source_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.7824013000000001}, {\"source_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.5367667}, {\"source_id\": \"c17e141b2697b3a4ee7b3786cca8ee92da09f549_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.2981128333333334}, {\"source_id\": \"c1a1e71154cf835b4196f7a6d6bfe5189750514a_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.21594390000000002}, {\"source_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.2584344}, {\"source_id\": \"c2e5ba8c5d960dd70f4501fd0d55785fcc86fc1c_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.24174526666666668}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.35861540000000003}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3766814666666667}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.3160505166666667}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.3235422}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.6923434333333334}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.29123356666666667}, {\"source_id\": \"c3b9310b8da36064f818daa6c0f4332bd3a30364_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.7120187666666666}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"strength\": 0.7492690799999999}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.6245317833333334}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3749327333333334}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.2838877866666667}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.7747396666666667}, {\"source_id\": \"ccd93ef604166d2d3688d1d963ea10a12affca84_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.8020294000000001}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"strength\": 0.3523894666666667}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.3400261166666667}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.4005300133333333}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.3059042666666667}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.7973749333333333}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"ea811f56d75a673b642b37a9a6615a325e4d2ae8_0\", \"strength\": 0.2924114466666667}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.23883660000000004}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.40440940000000003}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 1.0222603666666668}, {\"source_id\": \"cf40d9ace9751fd0a0c336f302c3be037cd460ae_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.8295382666666667}, {\"source_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"target_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"strength\": 0.29086650000000003}, {\"source_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.33405303333333336}, {\"source_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.2984357666666667}, {\"source_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"target_id\": \"f17611b97e72578ed47f180970702083209ef076_0\", \"strength\": 0.5921441000000001}, {\"source_id\": \"d046923d6036c80fdb5b95bc4920f6c5c995f22d_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.3029740333333334}, {\"source_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"target_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"strength\": 0.37736773333333334}, {\"source_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.28047668333333337}, {\"source_id\": \"d18f2c27c0b6911b60ba471de84cdd0bcfc310bb_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.7043704666666667}, {\"source_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"target_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"strength\": 0.30626508}, {\"source_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"target_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"strength\": 0.27425588}, {\"source_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.8776046666666668}, {\"source_id\": \"d2edd2a991aca60d19867e723097621b249244ee_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.3134326666666667}, {\"source_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.6797203500000001}, {\"source_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"target_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"strength\": 0.2449334466666667}, {\"source_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.2949548333333334}, {\"source_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"target_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"strength\": 0.6601696333333334}, {\"source_id\": \"d80d6f765dc8e5b73d4367685193aac019d84d32_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.8049058333333334}, {\"source_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"target_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"strength\": 0.2179699}, {\"source_id\": \"da210e0565fa431b7d4b3a51da183ad6fc004bda_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.26025576666666667}, {\"source_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.28862592000000004}, {\"source_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.3446477333333333}, {\"source_id\": \"de8f1bb911b27ce33656601d4ce080958115a5cc_0\", \"target_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"strength\": 0.35093450000000004}, {\"source_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"target_id\": \"e93479be9ce2293697f01793118f1c5f8fb490cc_0\", \"strength\": 0.2876889}, {\"source_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"target_id\": \"ed87bd7618eaad0b1a6f86623881c9589526728f_0\", \"strength\": 0.4807128666666667}, {\"source_id\": \"e1452d7eae10c11e6117d07c3aef56f1869d90d2_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.24651753333333334}, {\"source_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"target_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"strength\": 0.28532280000000004}, {\"source_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.6301216166666668}, {\"source_id\": \"e23f64d5d1094e86bdf8f5306c09a3e2563d0853_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.2833370333333333}, {\"source_id\": \"e93479be9ce2293697f01793118f1c5f8fb490cc_0\", \"target_id\": \"f994e729a3a7b42e2546585fa5bf28d22058bf96_0\", \"strength\": 0.33880066666666664}, {\"source_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"target_id\": \"e9b61d34a1e826e82d189e183b32eb288a5094cc_0\", \"strength\": 0.33940295000000004}, {\"source_id\": \"e9570215e36febb507fa434f592249cd070bf2ba_0\", \"target_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"strength\": 0.33889606666666666}, {\"source_id\": \"f0c7296d18c7ae97faae0a2575ef11bc007931cf_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.24718286666666667}, {\"source_id\": \"f32623810587308a48b6d618224dfff5d8728ac5_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.30900688333333337}, {\"source_id\": \"f3646495b063d6dfc79c414af5beb73ed88c9c06_0\", \"target_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"strength\": 0.25424623333333335}, {\"source_id\": \"fa4222cf35875a4d6e810d7573542822251ea95c_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.3305290466666667}, {\"source_id\": \"fae8e38d6c1b0a4959d416e7a853af6fde3dc1b4_0\", \"target_id\": \"fafd70b2b9d956095a7bb5b27052fed9b5284db3_0\", \"strength\": 0.35932383333333334}], \"clusters\": [{\"cluster\": 1, \"label\": \"Optimization Techniques for ML Models\", \"summary\": null}, {\"cluster\": 2, \"label\": \"Representative documents of cluster\", \"summary\": null}], \"blog_title\": null, \"blog_intro\": null, \"blog_conclusion\": null}}"