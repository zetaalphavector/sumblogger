"{\"config\": {\"terminology\": {\"cluster\": \"Group\", \"clusters\": \"Groups\", \"item\": \"Document\", \"items\": \"Documents\", \"link\": \"Similarity link\", \"links\": \"Similarity links\", \"link_strength\": \"Similarity strength\", \"total_link_strength\": \"Total similarity strengths\", \"title\": \"Title of the document\", \"abstract\": \"Abstract of the document\", \"authors\": \"Authors\"}, \"color_schemes\": {\"cluster_colors\": [{\"cluster\": 1, \"color\": \"#bcbd22\"}, {\"cluster\": 2, \"color\": \"#d62728\"}]}, \"templates\": {\"item_description\": \"<div style='display:flex'><div style='padding-left:16px'><div class='description_heading'>{heading}</div><div class='description_title'><a class='description_url'href='{uri}'target='_blank'>{title}</a></div><div class='description_authors'style='margin:4px 0;font-weight:500px;color:#757575'>{authors}</div><div class='description_abstract'>{abstract}</div></div></div>\"}, \"styles\": {\"description_heading\": \"color: #757575; font-weight: 600;\"}, \"parameters\": {\"item_size_variation\": 0.7, \"largest_component\": true, \"attraction\": 1.0, \"repulsion\": -1.0, \"max_n_links\": 1000}}, \"network\": {\"items\": [{\"id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small\", \"authors\": \"Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt\", \"label\": \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small\", \"abstract\": \"Research in mechanistic interpretability seeks to explain behaviors of ML models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=00713671e1532afff26458bba10c815db540fc82\", \"img_url\": null, \"x\": -0.20082833848576398, \"y\": 0.5249192358655492, \"cluster\": 1, \"weights\": {\"Influence\": 2.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.20238095238095244, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8434330179130254, \"summary\": null}, {\"id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"A Mixture-of-Expert Approach to RL-based Dialogue Management\", \"authors\": \"Yinlam Chow, Azamat Tulepbergenov, Ofir Nachum, Dhawal Gupta, Moonkyung Ryu, Mohammad Ghavamzadeh, Craig Boutilier\", \"label\": \"A Mixture-of-Expert Approach to RL-based Dialogue Management\", \"abstract\": \"Despite recent advancements in language models (LMs), their application to dialogue management (DM) problems and ability to carry on rich conversations remain a challenge. We use reinforcement learning (RL) to develop a dialogue agent that avoids being short-sighted (outputting generic utterances) a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=00bdc1335e7fcaa04948b9fb95d5d8e837bf7144\", \"img_url\": null, \"x\": 0.28129141448288053, \"y\": 0.7755227792447417, \"cluster\": 1, \"weights\": {\"Influence\": 4.916666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3511904761904763, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8726432757650728, \"summary\": null}, {\"id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Model Extraction Attacks on DitsilBERT\", \"authors\": \"Amro Salman, Ayman Saeed, Khalid Elmadani, Sharief Babiker\", \"label\": \"Model Extraction Attacks on DitsilBERT\", \"abstract\": \"$$This paper investigates model extraction attacks, where an adversary can train a substitute model by collecting data through query access to a victim model and steal its functionality. We use DistilBERT as the victim model due to its smaller size and faster processing speed. The results demonstrat...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=066f9450f5c711985540d95de2dd685434906817\", \"img_url\": null, \"x\": -0.5162655747283552, \"y\": 0.8044680618624251, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Visually-Augmented Language Modeling\", \"authors\": \"Weizhi Wang, Li Dong, Hao Cheng, Haoyu Song, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, Furu Wei\", \"label\": \"Visually-Augmented Language Modeling\", \"abstract\": \"Human language is grounded on multimodal knowledge including visual knowledge like colors, sizes, and shapes. However, current large-scale pre-trained language models rely on the text-only self-supervised training with massive text data, which precludes them from utilizing relevant visual informatio...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=08c23d7e9010a556e408032f2be868b4b137cde1\", \"img_url\": null, \"x\": -0.23835789285089562, \"y\": 0.8103720037448249, \"cluster\": 1, \"weights\": {\"Influence\": 7.857142857142858, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5612244897959185, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9138714682762485, \"summary\": null}, {\"id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization\", \"authors\": \"ZeFeng Cai, Chongyang Tao, Tao Shen, Can Xu, Xiubo Geng, Xin Alex Lin, Liang He, Daxin Jiang\", \"label\": \"HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization\", \"abstract\": \"Recently, large-scale text retrieval has made impressive progress, facilitating both information retrieval and downstream knowledge-intensive tasks (e.g., open-domain QA and dialogue). With a moderate amount of data, a neural text retriever can outperform traditional methods such as BM25 by a large ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=0bf6bde50c746c14dc05e96bcce53de82514ab58\", \"img_url\": null, \"x\": -0.20020847943971468, \"y\": 0.9340783062172857, \"cluster\": 1, \"weights\": {\"Influence\": 2.5714285714285716, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18367346938775517, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8397608712116251, \"summary\": null}, {\"id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Chain Of Thought Prompting Under Streaming Batch: A Case Study\", \"authors\": \"Yuxin Tang\", \"label\": \"Chain Of Thought Prompting Under Streaming Batch: A Case Study\", \"abstract\": \"Recently, Large Language Models (LLMs) have demonstrated remarkable capa-\\nbilities. Chain-of-Thought (CoT) has been proposed as a way of assisting LLMs\\nin performing complex reasoning. However, developing effective prompts can be\\na challenging and labor-intensive task. Many studies come out of some ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=103acce1154b891ef581ef3e5210a8987e38f231\", \"img_url\": null, \"x\": 0.016948056581672064, \"y\": 1.2765041538380621, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Ask Me Anything: A simple strategy for prompting language models\", \"authors\": \"Simran Arora, Avanika Narayan, Mayee F Chen, Laurel Orr, Neel Guha, Kush Bhatia, Ines Chami, Christopher Re\", \"label\": \"Ask Me Anything: A simple strategy for prompting language models\", \"abstract\": \"Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predict...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=11651173866b06c8bbd6be77978e7d140c8c5ac4\", \"img_url\": null, \"x\": -0.134521201290133, \"y\": 1.241156574786128, \"cluster\": 1, \"weights\": {\"Influence\": 2.0625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1473214285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8326252225077678, \"summary\": null}, {\"id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference\", \"authors\": \"Benfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, Qiaoqiao She, Yongdong Zhang\", \"label\": \"$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference\", \"abstract\": \"In-Context Learning (ICL), which formulates target tasks as prompt completion conditioned on in-context demonstrations, has become the prevailing utilization of LLMs. In this paper, we first disclose an actual predicament for this typical usage that it can not scale up with training data due to cont...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1220ce96c6db4edf48899387a173730c6868e323\", \"img_url\": null, \"x\": -0.26727714712986933, \"y\": 1.1606242120770374, \"cluster\": 1, \"weights\": {\"Influence\": 4.3, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3071428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8639970394408668, \"summary\": null}, {\"id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Large Language Models are Human-Level Prompt Engineers\", \"authors\": \"Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba\", \"label\": \"Large Language Models are Human-Level Prompt Engineers\", \"abstract\": \"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted b...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=143cfb098bdebc195b95d87a19978ba4001d1fa8\", \"img_url\": null, \"x\": -0.013846320078599478, \"y\": 1.1427965690079573, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8738116860791547, \"summary\": null}, {\"id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Generating Sequences by Learning to Self-Correct\", \"authors\": \"Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, Yejin Choi\", \"label\": \"Generating Sequences by Learning to Self-Correct\", \"abstract\": \"Sequence generation applications require satisfying semantic constraints, such as ensuring that programs are correct, using certain keywords, or avoiding undesirable content. Language models, whether fine-tuned or prompted with few-shot demonstrations, frequently violate these constraints, and lack ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=154b30e600a62c531fed410d51f41d34a5d13ef6\", \"img_url\": null, \"x\": -0.17066228065767688, \"y\": 1.0456440648026044, \"cluster\": 1, \"weights\": {\"Influence\": 4.166666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2976190476190477, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8621275829383357, \"summary\": null}, {\"id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Linearly Mapping from Image to Text Space\", \"authors\": \"Jack Merullo, Louis Castricato, Carsten Eickhoff, Ellie Pavlick\", \"label\": \"Linearly Mapping from Image to Text Space\", \"abstract\": \"The extent to which text-only language models (LMs)  learn to represent the physical, non-linguistic world is an open question. Prior work has shown that pretrained LMs can be taught to ``understand'' visual inputs when the models' parameters are updated on image captioning tasks. We test a stronger...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=158c3e9b9937ad25aa9ef65b42d655cafe9754b5\", \"img_url\": null, \"x\": -0.1197756267257241, \"y\": 0.8085815280507838, \"cluster\": 1, \"weights\": {\"Influence\": 2.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.20238095238095244, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8434330179130254, \"summary\": null}, {\"id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"SLTUNET: A Simple Unified Model for Sign Language Translation\", \"authors\": \"Biao Zhang, Mathias M\\u00fcller, Rico Sennrich\", \"label\": \"SLTUNET: A Simple Unified Model for Sign Language Translation\", \"abstract\": \"Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation sha...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=162d51317b72d69f5e99da4a6cc53cbd7f9b5e86\", \"img_url\": null, \"x\": -0.2786096927480854, \"y\": 0.9378164048511101, \"cluster\": 1, \"weights\": {\"Influence\": 5.166666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3690476190476192, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8761485067073186, \"summary\": null}, {\"id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"WikiWhy: Answering and Explaining Cause-and-Effect Questions\", \"authors\": \"Matthew Ho, Aditya Sharma, Justin Chang, Michael Saxon, Sharon Levy, Yujie Lu, William Yang Wang\", \"label\": \"WikiWhy: Answering and Explaining Cause-and-Effect Questions\", \"abstract\": \"As large language models (LLMs) grow larger and more sophisticated, assessing their \\\"reasoning\\\" capabilities in natural language grows more challenging. Recent question answering (QA) benchmarks that attempt to assess reasoning are often limited by a narrow scope of covered situations and subject ma...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=199a854fceaf26a4a1deae9b0c12c71276f5da00\", \"img_url\": null, \"x\": -0.06845136645873531, \"y\": 1.1284232994113972, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1428571428571429, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8317489147722064, \"summary\": null}, {\"id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees\", \"authors\": \"Swarnadeep Saha, Shiyue Zhang, Peter Hase, Mohit Bansal\", \"label\": \"Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees\", \"abstract\": \"Current abstractive summarization models either suffer from a lack of clear interpretability or provide incomplete rationales by only highlighting parts of the source document. To this end, we propose the Summarization Program (SP), an interpretable modular framework consisting of an (ordered) list ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1c4ca3277c2f4b3aab7b9c44937a91391cdf807b\", \"img_url\": null, \"x\": -0.05456202179717704, \"y\": 0.983327964681688, \"cluster\": 1, \"weights\": {\"Influence\": 4.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2946428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8615433777812949, \"summary\": null}, {\"id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"TypeT5: Seq2seq Type Inference using Static Analysis\", \"authors\": \"Jiayi Wei, Greg Durrett, Isil Dillig\", \"label\": \"TypeT5: Seq2seq Type Inference using Static Analysis\", \"abstract\": \"There has been growing interest in automatically predicting missing type annotations in programs written in Python and JavaScript. While prior methods have achieved impressive accuracy when predicting the most common types, they often perform poorly on rare or complex types. In this paper, we presen...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1d26730c325a12eead65d64552a91658cce12baf\", \"img_url\": null, \"x\": -0.08952582663160519, \"y\": 1.0229284239404497, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21428571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8457698385411891, \"summary\": null}, {\"id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph\", \"authors\": \"Jinhao Jiang, Kun Zhou, Xin Zhao, Ji-Rong Wen\", \"label\": \"UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph\", \"abstract\": \"Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG).\\nTo cope with the vast search space, existing work usually adopts a two-stage a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1e5cd6b33c003196129a1f247932ffbb7896feb5\", \"img_url\": null, \"x\": -0.12109710850215051, \"y\": 0.9061140223283458, \"cluster\": 1, \"weights\": {\"Influence\": 4.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3452380952380953, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.871474865450991, \"summary\": null}, {\"id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-Linear Functions\", \"authors\": \"Neo Wei Ming, Zhehui Wang, Cheng Liu, Rick Siow Mong Goh, Tao Luo\", \"label\": \"MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-Linear Functions\", \"abstract\": \"Due to their superior results, Transformer-based models such as BERT have become de facto standards in many Natural Language Processing (NLP) applications. However, the intensive use of complex non-linear functions within the Transformer architecture impairs its computing efficiency and complicates ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=1ed1617d66761681a93bdbe7b1f53aef7d21091f\", \"img_url\": null, \"x\": -0.6026056963868244, \"y\": 0.6428762585068916, \"cluster\": 1, \"weights\": {\"Influence\": 3.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2321428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8492750694834349, \"summary\": null}, {\"id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation\", \"authors\": \"Ziqi Wang, Yuexin Wu, Frederick Liu, Daogao Liu, Le Hou, Hongkun Yu, Jing Li, Heng Ji\", \"label\": \"Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation\", \"abstract\": \"Knowledge distillation is one of the primary methods of transferring knowledge from large to small models. However, it requires massive task-specific data, which may not be plausible in many real-world applications. Data augmentation methods such as representation interpolation, token replacement, o...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e\", \"img_url\": null, \"x\": -0.631396430698834, \"y\": 0.693371962556931, \"cluster\": 1, \"weights\": {\"Influence\": 2.642857142857143, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18877551020408168, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8407623657665525, \"summary\": null}, {\"id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"ChatGPT for Therapy? Opportunities and Barriers for ChatGPT in Speech-Language Therapy\", \"authors\": \"Yao Du, Felix Juefei-Xu\", \"label\": \"ChatGPT for Therapy? Opportunities and Barriers for ChatGPT in Speech-Language Therapy\", \"abstract\": \"Speech-language pathologists (SLPs) are health professionals who work with children and adults with various communication disorders that result in communication breakdowns in areas such as speech, language, hearing, and voice. The rise of voice assistants and chatbots brings new opportunities for cl...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=253ec8cde3e27fdba1c9ad3012d1fc3e9603b231\", \"img_url\": null, \"x\": 0.15065200048768568, \"y\": 0.9603836622341445, \"cluster\": 1, \"weights\": {\"Influence\": 4.999999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.35714285714285715, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8117491567391735, \"summary\": null}, {\"id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization\", \"authors\": \"Seonghyeon Ye, Joel Jang, Doyoung Kim, Yongrae Jo, Minjoon Seo\", \"label\": \"Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization\", \"abstract\": \"During zero-shot inference with language models (LMs), using hard prompts alone may not be able to fully describe the target task. In this paper, we explore how the retrieval of soft prompts obtained through prompt tuning can assist hard prompts in zero-shot task generalization. Specifically, we tra...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2a4e4028b8c23d3e71b07833c38d21059964d08a\", \"img_url\": null, \"x\": -0.27921564460964216, \"y\": 1.2614362264384067, \"cluster\": 1, \"weights\": {\"Influence\": 3.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2321428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7866451966380932, \"summary\": null}, {\"id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Task Ambiguity in Humans and Language Models\", \"authors\": \"Alex Tamkin, Kunal Handa, Avash Shrestha, Noah Goodman\", \"label\": \"Task Ambiguity in Humans and Language Models\", \"abstract\": \"Language models have recently achieved strong performance across a wide range of NLP benchmarks. However, real world tasks are often poorly specified, and agents must deduce the intended behavior from a combination of context, instructions, and examples. We investigate how both humans and models beh...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3\", \"img_url\": null, \"x\": 0.010245891177754186, \"y\": 1.0831600308859932, \"cluster\": 1, \"weights\": {\"Influence\": 2.6666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.19047619047619052, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8410961972848616, \"summary\": null}, {\"id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Pseudo-label Training and Model Inertia in Neural Machine Translation\", \"authors\": \"Benjamin Hsu, Anna Currey, Xing Niu, Maria Nadejde, Georgiana Dinu\", \"label\": \"Pseudo-label Training and Model Inertia in Neural Machine Translation\", \"abstract\": \"Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across re-trainin...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2d572c3562f66ea11f12de57a5ed1f961a6e4b68\", \"img_url\": null, \"x\": -0.2622310194967749, \"y\": 0.903042848066136, \"cluster\": 1, \"weights\": {\"Influence\": 2.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.18750000000000006, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8405119921278206, \"summary\": null}, {\"id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"UL2: Unifying Language Learning Paradigms\", \"authors\": \"Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Steven Zheng, Denny Zhou, Neil Houlsby, Donald Metzler\", \"label\": \"UL2: Unifying Language Learning Paradigms\", \"abstract\": \"Existing pre-trained models are generally geared towards a particular class of problems. To date, there seems to be still no consensus on what the right architecture and pre-training setup should be. This paper presents a unified framework for pre-training models that are universally effective acros...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=2db7fac67c690d80d8b68567e6032edd31a04661\", \"img_url\": null, \"x\": -0.28434812678283705, \"y\": 1.0639795162107548, \"cluster\": 1, \"weights\": {\"Influence\": 2.4166666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.17261904761904764, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8375909663426159, \"summary\": null}, {\"id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning\", \"authors\": \"Chenkai Ma\", \"label\": \"Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning\", \"abstract\": \"Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning benchmarks...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=30464dcfbcc9361f9567cb6180a024fde3f9f7c0\", \"img_url\": null, \"x\": -0.20270291037263818, \"y\": 1.3129089186638174, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Characterizing intrinsic compositionality in transformers with Tree Projections\", \"authors\": \"Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher D Manning\", \"label\": \"Characterizing intrinsic compositionality in transformers with Tree Projections\", \"abstract\": \"When trained on language data, do transformers learn some arbitrary computation that utilizes the full capacity of the architecture or do they learn a simpler, tree-like computation, hypothesized to underlie compositional meaning systems like human languages? There is an apparent tension between com...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=312dd8836aeed42afc7cd56ba3f844401b4a7aac\", \"img_url\": null, \"x\": -0.03278327985045441, \"y\": 0.6823115269437003, \"cluster\": 1, \"weights\": {\"Influence\": 11.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7946428571428573, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9596898441641744, \"summary\": null}, {\"id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Binding Language Models in Symbolic Languages\", \"authors\": \"Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, Tao Yu\", \"label\": \"Binding Language Models in Symbolic Languages\", \"abstract\": \"Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of la...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=3339fc69d56af1c26a861cd289435c3b70a12b9a\", \"img_url\": null, \"x\": -0.10702875282252598, \"y\": 1.1030481077163583, \"cluster\": 1, \"weights\": {\"Influence\": 8.555555555555555, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6111111111111113, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9236638594799824, \"summary\": null}, {\"id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Compositionality with Variation Reliably Emerges in Neural Networks\", \"authors\": \"Henry Conklin, Kenny Smith\", \"label\": \"Compositionality with Variation Reliably Emerges in Neural Networks\", \"abstract\": \"Human languages enable robust generalization, letting us leverage our prior experience to communicate about novel meanings. This is partly due to language being compositional, where the meaning of a whole expression is a function of its parts. Natural languages also exhibit extensive variation, enco...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=347646a7f503e63e832fbd65317a9bb94b16a591\", \"img_url\": null, \"x\": -0.07902422544829896, \"y\": 0.5050470655424572, \"cluster\": 1, \"weights\": {\"Influence\": 1.9999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14285714285714285, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8317489147722064, \"summary\": null}, {\"id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement\", \"authors\": \"Hongwei Han, Mengyu Zhou, Shi Han, Xiu Li, Dongmei Zhang\", \"label\": \"CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement\", \"abstract\": \"There are sequence generation tasks where the best order to generate the target sequence is not left-to-right. For example, an answer to the Sudoku game, a structured code like s-expression, and even a logical natural language answer where the analysis may be generated after the decision. We define ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=34cc48cbd844dbafbe35faeb82129d13e66095bf\", \"img_url\": null, \"x\": -0.12272379419896931, \"y\": 0.9508699623337159, \"cluster\": 1, \"weights\": {\"Influence\": 1.3333333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09523809523809526, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8224016322595512, \"summary\": null}, {\"id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Uni-Match: A Semantic Unified Model for Query-Product Retrieval\", \"authors\": \"Zhenyang Zhu, Rui-Jie Zhu, Yunrui Ge, Qihang Zhao\", \"label\": \"Uni-Match: A Semantic Unified Model for Query-Product Retrieval\", \"abstract\": \"For most practical search systems, the cascaded matching-prerank-rank architecture is designed. In the prerank stage, the dual-tower structure is widely used to maintain efficiency. However, due to the lack of interaction between query and document, this architecture could only take into account eff...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=3bac3a260f475e4af46396b434902c7a31a79d49\", \"img_url\": null, \"x\": -0.20606095825527287, \"y\": 0.8859988447816888, \"cluster\": 1, \"weights\": {\"Influence\": 3.999999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2857142857142857, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7908323963768593, \"summary\": null}, {\"id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Zero-Shot Classification Reveals Potential Positive Sentiment Bias in African Languages Translations\", \"authors\": \"Saurav Keshari Aryal, Hrishav Sapkota, Howard Prioleau\", \"label\": \"Zero-Shot Classification Reveals Potential Positive Sentiment Bias in African Languages Translations\", \"abstract\": \"Natural Language Processing research into African languages has been limited, with over 2000 languages still needing to be studied. We employ the AfriSenti-SemEval dataset, a recently released resource that provides annotated tweets across 13 African languages, for sentiment analysis to address this...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=40aa20d82f89b9d916bafcae6e7345462e2d8d35\", \"img_url\": null, \"x\": -0.2957172166659535, \"y\": 0.6274150157154759, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought\", \"authors\": \"Abulhair Saparov, He He\", \"label\": \"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought\", \"abstract\": \"Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is u...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=416279f655ea1098f0d9994426ae7fea3e89535c\", \"img_url\": null, \"x\": -0.016488884378512845, \"y\": 1.2538586272936945, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8177279910032236, \"summary\": null}, {\"id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Training language models to summarize narratives improves brain alignment\", \"authors\": \"Khai Loong Aw, Mariya Toneva\", \"label\": \"Training language models to summarize narratives improves brain alignment\", \"abstract\": \"Building systems that achieve a deeper understanding of language is one of the central goals of natural language processing (NLP). Towards this goal, recent works have begun to train language models on narrative datasets which require extracting the most critical information by integrating across lo...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4383881f88fa683debadcf3027460fff1f2858a8\", \"img_url\": null, \"x\": -0.23705616925832415, \"y\": 0.7185570246638558, \"cluster\": 1, \"weights\": {\"Influence\": 1.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.10714285714285714, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.824738452887715, \"summary\": null}, {\"id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"heading\": \"ICLR, 15 Feb 2023\", \"title\": \"Sentence Embedding Encoders are Easy to Steal but Hard to Defend\", \"authors\": \"Haonan Duan\", \"label\": \"Sentence Embedding Encoders are Easy to Steal but Hard to Defend\", \"abstract\": \"Self-supervised learning (SSL) has become the predominant approach to training on large amounts of data when no labels are available. Since the corresponding model architectures are usually large, the training process is, in itself, costly, and training relies on dedicated expensive hardware. As a c...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4615365bba1bda4cd045b864a6cc186a6fe4e4fb\", \"img_url\": null, \"x\": -0.550456149126579, \"y\": 0.7676031209113076, \"cluster\": 1, \"weights\": {\"Influence\": 4.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.30357142857142866, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8030759633099827, \"summary\": null}, {\"id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Progressive Prompts: Continual Learning for Language Models\", \"authors\": \"Anastasia Razdaibiedina, Yuning Mao, Rui Hou, Madian Khabsa, Mike Lewis, Amjad Almahairi\", \"label\": \"Progressive Prompts: Continual Learning for Language Models\", \"abstract\": \"We introduce Progressive Prompts \\u2013 a simple and efficient approach for continual learning in language models. Our method allows forward transfer and resists catastrophic forgetting, without relying on data replay or a large number of task-specific parameters. Progressive Prompts learns a new soft pr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=49408caf6974b9f88c0ff22bdc7bb0f031b44012\", \"img_url\": null, \"x\": -0.5211654592792672, \"y\": 0.9277022221872274, \"cluster\": 1, \"weights\": {\"Influence\": 3.4, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2428571428571429, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8513782080487823, \"summary\": null}, {\"id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"The Independent Compositional Subspace Hypothesis for the Structure of CLIP's Last Layer\", \"authors\": \"Max Wolff, Wieland Brendel, Stuart Wolff\", \"label\": \"The Independent Compositional Subspace Hypothesis for the Structure of CLIP's Last Layer\", \"abstract\": \"In this paper, we propose a hypothesis which posits that CLIP disentangles compositional visual attributes into orthogonal, independent subspaces which CLIP uses to build compositional representations of images. Our hypothesis suggests that CLIP learns compositional techniques that are similar to hu...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4b064bf120f526e0a47df49f891a0e09958f8b40\", \"img_url\": null, \"x\": -0.11062713795382396, \"y\": 0.7408196754569186, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21428571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7816834570250255, \"summary\": null}, {\"id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"heading\": \"ICLR, 15 Feb 2023\", \"title\": \"Robustifying Language Models with Test-Time Adaptation\", \"authors\": \"Noah Thomas McDermott, Junfeng Yang, Chengzhi Mao\", \"label\": \"Robustifying Language Models with Test-Time Adaptation\", \"abstract\": \"Large-scale language models achieved state-of-the-art performance over a number of language tasks. However, they fail on adversarial language examples, which are sentences optimized to fool the language models but with similar semantic meanings for humans. While prior work focuses on making the lang...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=4f1eb4a8421681a49858b0590dafe1469e94ec7f\", \"img_url\": null, \"x\": -1.033797870668143, \"y\": 0.07862363463024273, \"cluster\": 1, \"weights\": {\"Influence\": 3.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2321428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7828786262135706, \"summary\": null}, {\"id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Language Models can do Zero-Shot Visual Referring Expression Comprehension\", \"authors\": \"Xiuchao Sui, Shaohua Li, Hong Yang, Hongyuan Zhu, Yan Wu\", \"label\": \"Language Models can do Zero-Shot Visual Referring Expression Comprehension\", \"abstract\": \"The use of visual referring expressions is an important aspect of human-robot interactions.  Comprehending referring expressions (ReC) like ``the brown cookie near the cup'' requires to understand both self-referential expressions, ``brown cookie\\\", and relational referential expressions, ``near the ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=56071e7fc5122991ecd78ce573ac00cf3e5067ef\", \"img_url\": null, \"x\": 0.08282413671744782, \"y\": 0.9497457934610944, \"cluster\": 1, \"weights\": {\"Influence\": 2.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.15178571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7516134706975206, \"summary\": null}, {\"id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"MACHINE TRANSLATION BASELINES FOR ARABIC - SWAHILI\", \"authors\": \"Asim Awad Osman, Ahmed Emadeldin Almahady, Muhammed Saeed, Hiba Hassan Sayed\", \"label\": \"MACHINE TRANSLATION BASELINES FOR ARABIC - SWAHILI\", \"abstract\": \"Building neural machine translation (NMT) systems for low-resource languages poses several challenges, mainly due to the lack of parallel data. In this research, we propose a baseline NMT system for translating between Arabic and Swahili. Despite being spoken by nearly 300 million individuals worldw...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=569dbc3270ede6061aa6eec6c9b43bc2a646c43d\", \"img_url\": null, \"x\": -0.3533519370279872, \"y\": 0.91871651182779, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers\", \"authors\": \"Chen Liang, Haoming Jiang, Zheng Li, Xianfeng Tang, Bing Yin, Tuo Zhao\", \"label\": \"HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers\", \"abstract\": \"Knowledge distillation has been shown to be a powerful model compression approach to facilitate the deployment of pre-trained language models in practice. This paper focuses on task-agnostic distillation. It produces a compact pre-trained model that can be easily fine-tuned on various tasks with sma...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=56baf9e289f10825bce61e0cc10783b2abb58bde\", \"img_url\": null, \"x\": -0.6657888184499758, \"y\": 0.6432226057183414, \"cluster\": 1, \"weights\": {\"Influence\": 3.1666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.22619047619047625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.848106659169353, \"summary\": null}, {\"id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Learning Language Representations with Logical Inductive Bias\", \"authors\": \"Jianshu Chen\", \"label\": \"Learning Language Representations with Logical Inductive Bias\", \"abstract\": \"Transformer architectures have achieved great success in solving natural language tasks, which learn strong language representations from large-scale unlabeled texts. In this paper, we seek to go further beyond and explore a new logical inductive bias for better language representation learning. Log...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5973f5bc9a87c1e9f3e95e70f30b6497b95a673a\", \"img_url\": null, \"x\": -0.2203641649946844, \"y\": 0.6717621053997935, \"cluster\": 1, \"weights\": {\"Influence\": 6.499999999999998, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4642857142857143, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.894843071732629, \"summary\": null}, {\"id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"INTEGRATING INFORMATION FROM NATURAL LANGUAGE PARSE TREE TO CODE GENERATION\", \"authors\": \"Hung D Phan, Ali Jannesari\", \"label\": \"INTEGRATING INFORMATION FROM NATURAL LANGUAGE PARSE TREE TO CODE GENERATION\", \"abstract\": \"While more and more research works have considered Natural Language artifacts as the inputs of software engineering research, such as code generation, information about their  graph/tree representations needs to be carefully considered. In this work, we propose an approach for integrating informatio...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5aa073b34e5455c3161e8e73b80b58eabae3a9ac\", \"img_url\": null, \"x\": -0.15214166260292294, \"y\": 0.9863304497602614, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Language Models Can Teach Themselves to Program Better\", \"authors\": \"Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai\", \"label\": \"Language Models Can Teach Themselves to Program Better\", \"abstract\": \"Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=5e6744097d023772f4e066a66f8496bcfc06e15d\", \"img_url\": null, \"x\": -0.14574475937406448, \"y\": 1.1207728836549002, \"cluster\": 1, \"weights\": {\"Influence\": 2.1666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1547619047619048, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8340857354003701, \"summary\": null}, {\"id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval\", \"authors\": \"Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang\", \"label\": \"LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval\", \"abstract\": \"In large-scale retrieval, the lexicon-weighting paradigm, learning weighted sparse representations in vocabulary space, has shown promising results with high quality and low latency. Despite it deeply exploiting the lexicon-representing capability of pre-trained language models, a crucial gap remain...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6a9dd394987411ced6f4d53c6e4c71887d5c52ea\", \"img_url\": null, \"x\": -0.2442309978494974, \"y\": 0.857000763621808, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21428571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8457698385411891, \"summary\": null}, {\"id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"GLM-130B: An Open Bilingual Pre-trained Model\", \"authors\": \"Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, Jie Tang\", \"label\": \"GLM-130B: An Open Bilingual Pre-trained Model\", \"abstract\": \"We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we fac...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=6ffbbe187cbcc22c7b7f1254a0396459a35e7d43\", \"img_url\": null, \"x\": -0.23184125360723679, \"y\": 1.0234877716563706, \"cluster\": 1, \"weights\": {\"Influence\": 3.142857142857143, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2244897959183674, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8477728276510439, \"summary\": null}, {\"id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"heading\": \"ICLR, 15 Feb 2023\", \"title\": \"KNIFE: Distilling Meta-Reasoning Knowledge with Free-Text Rationales\", \"authors\": \"Zhiyuan Zeng\", \"label\": \"KNIFE: Distilling Meta-Reasoning Knowledge with Free-Text Rationales\", \"abstract\": \"Recent works have explored using free-text rationales (FTRs)---i.e., natural language explanations of a task output---to teach language models (LMs) how to solve NLP tasks. In these works, the LM is often finetuned or prompted to jointly generate the FTR and task output. However, this approach eithe...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=738a5dc4ffd40969e1eebee88c95fb48e9013ccf\", \"img_url\": null, \"x\": -0.21534328709756326, \"y\": 1.2483061132377158, \"cluster\": 1, \"weights\": {\"Influence\": 2.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.19642857142857148, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7727799576653646, \"summary\": null}, {\"id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Logical Message Passing Networks with One-hop Inference on Atomic Formulas\", \"authors\": \"Zihao Wang, Yangqiu Song, Ginny Wong, Simon See\", \"label\": \"Logical Message Passing Networks with One-hop Inference on Atomic Formulas\", \"abstract\": \"Complex Query Answering (CQA) over Knowledge Graphs (KGs) has attracted a lot of attention to potentially support many applications. Given that KGs are usually incomplete, neural models are proposed to answer the logical queries by parameterizing set operators with complex neural networks. However, ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=76914ab5905f7896de9ea76722ee01e78f0f40ef\", \"img_url\": null, \"x\": 0.3304529901276877, \"y\": 0.5195683094206587, \"cluster\": 1, \"weights\": {\"Influence\": 4.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2857142857142858, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8597907623101719, \"summary\": null}, {\"id\": \"794d9d72a13ea406df0901e9d7459463efa086f3_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Is CLIP Fooled by Optical Illusions?\", \"authors\": \"Jerry Ngo, Swami Sankaranarayanan, Phillip Isola\", \"label\": \"Is CLIP Fooled by Optical Illusions?\", \"abstract\": \"Recent large machine learning models such as CLIP have shown impressive generalization performance for various perception tasks. In this work, we explore to what extent they model the human cognitive process. We focus our attention on how these models perceive optical illusions. We present a simple ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=794d9d72a13ea406df0901e9d7459463efa086f3\", \"img_url\": null, \"x\": -0.12585677391113648, \"y\": 0.7464322504731351, \"cluster\": 1, \"weights\": {\"Influence\": 6.166666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.44047619047619063, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8361520438285399, \"summary\": null}, {\"id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Model Extraction Attacks on Arabic BERT-Based APIs\", \"authors\": \"Hassan Abbelkarim, Mohammed Eltahir, Khalid Elmadani, Anas Showk\", \"label\": \"Model Extraction Attacks on Arabic BERT-Based APIs\", \"abstract\": \"In this paper, we study the feasibility of performing Model Extraction attacks on Arabic BERT-based APIs. In our experiments, we try to perform these attacks under different scenarios and observe the accuracy of the extracted model against the victim model. We then propose a method for protecting ag...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=7b874f6ed208bd4d96c8067585e1baada269ed99\", \"img_url\": null, \"x\": -0.50201386435741, \"y\": 0.8191383848140473, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Recitation-Augmented Language Models\", \"authors\": \"Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, Denny Zhou\", \"label\": \"Recitation-Augmented Language Models\", \"abstract\": \"We propose a new paradigm to help Large Language Models (LLMs) generate more accurate factual knowledge without retrieving from an external corpus, called RECITation-augmented gEneration (RECITE). Different from retrieval-augmented language models that retrieve relevant documents before generating t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=7b98935360946bb508faa85c8a3a1af1da8bb596\", \"img_url\": null, \"x\": -0.07558914700683349, \"y\": 1.1760168147292407, \"cluster\": 1, \"weights\": {\"Influence\": 3.9000000000000004, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2785714285714287, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8583886699332737, \"summary\": null}, {\"id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code\", \"authors\": \"Nadezhda Chirkova, Sergey Troshin\", \"label\": \"CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code\", \"abstract\": \"Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of su...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=7ebd240a5100239de5f1143348bb6a02e57b4a3e\", \"img_url\": null, \"x\": -0.18733055094630172, \"y\": 0.9888259428659545, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8177279910032236, \"summary\": null}, {\"id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training\", \"authors\": \"Wei Li, Linchao Zhu, Longyin Wen, Yi Yang\", \"label\": \"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training\", \"abstract\": \"Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong zero-shot transfer capability in many discriminative tasks, e.g., image classification. Their adaptation to zero-shot image-conditioned text generation tasks has drawn increasing interest. Prior arts approach to zero-shot cap...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=800604d777a5e522dd1b1fd27bfdba1457e06121\", \"img_url\": null, \"x\": -0.06992799780646661, \"y\": 0.7872928355500499, \"cluster\": 1, \"weights\": {\"Influence\": 5.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4107142857142858, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8843273789058919, \"summary\": null}, {\"id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Complexity-Based Prompting for Multi-step Reasoning\", \"authors\": \"Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, Tushar Khot\", \"label\": \"Complexity-Based Prompting for Multi-step Reasoning\", \"abstract\": \"We study the task of prompting large-scale language models to perform multi-step reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reaso...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8040d9faa4476c89d1d8530fc3629609f670c413\", \"img_url\": null, \"x\": -0.0285737916039688, \"y\": 1.2977467101823033, \"cluster\": 1, \"weights\": {\"Influence\": 5.6, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4000000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8822242403405445, \"summary\": null}, {\"id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Can Text Encoders be Deceived by Length Attack?\", \"authors\": \"Chenghao Xiao, Zihuiwen Ye, G Thomas Hudson, Zhongtian Sun, Phil Blunsom, Noura Al Moubayed\", \"label\": \"Can Text Encoders be Deceived by Length Attack?\", \"abstract\": \"Albeit \\\\textit{de facto} to use in training dense retrieval models, we observe that contrastive learning is prone to length overfitting, making it vulnerable to adversarial length attacks. We examine the behaviour of this phenomenon and propose an editing method to mitigate this problem. We find tha...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=814afdbddae5a09ae806fd668ee77e35184255f8\", \"img_url\": null, \"x\": -0.38922226319377506, \"y\": 0.8360792839717802, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8117491567391735, \"summary\": null}, {\"id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Computational Language Acquisition with Theory of Mind\", \"authors\": \"Andy Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\", \"label\": \"Computational Language Acquisition with Theory of Mind\", \"abstract\": \"Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8172f5bcb615707ec5055beab47b4dd30e52d27b\", \"img_url\": null, \"x\": -0.04760623713304602, \"y\": 0.8309006053673456, \"cluster\": 1, \"weights\": {\"Influence\": 6.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4732142857142858, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8965956872037518, \"summary\": null}, {\"id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention\", \"authors\": \"Shijie Geng, Jianbo Yuan, Yu Tian, Yuxiao Chen, Yongfeng Zhang\", \"label\": \"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention\", \"abstract\": \"The success of large-scale contrastive vision-language pretraining (CLIP) has benefited both visual recognition and multimodal content understanding. The concise design brings CLIP the advantage in inference efficiency against other vision-language models with heavier cross-attention fusion layers, ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8415bcaf2b7284f0e357000e48ffb5fee6dd38b5\", \"img_url\": null, \"x\": -0.163840770042722, \"y\": 0.7281195659383378, \"cluster\": 1, \"weights\": {\"Influence\": 2.3, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1642857142857143, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8359551919029012, \"summary\": null}, {\"id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers\", \"authors\": \"Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, Furu Wei\", \"label\": \"Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers\", \"abstract\": \"Large pretrained language models have shown surprising in-context learning (ICL) ability. With a few demonstration input-label pairs, they can predict labels for unseen inputs without parameter updates. Despite the great success in performance, its working mechanism still remains an open question. I...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=842a83bd2d69d11016fcfe6c04050f8285afebcb\", \"img_url\": null, \"x\": -0.24204550200121477, \"y\": 1.1332383908318129, \"cluster\": 1, \"weights\": {\"Influence\": 4.916666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3511904761904763, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8197234607252105, \"summary\": null}, {\"id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Mind's Eye: Grounded Language Model Reasoning through Simulation\", \"authors\": \"Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, Andrew M. Dai\", \"label\": \"Mind's Eye: Grounded Language Model Reasoning through Simulation\", \"abstract\": \"Successful and effective communication between humans and AI relies on a shared experience of the world. By training solely on written text, current language models (LMs) miss the grounded experience of humans in the real-world---their failure to relate language to the physical world causes knowledg...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8700f035892152b56dc9fc03c132cfa2deb7f85f\", \"img_url\": null, \"x\": -0.1783752316400789, \"y\": 1.220306740352773, \"cluster\": 1, \"weights\": {\"Influence\": 3.375, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.24107142857142863, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8510276849545577, \"summary\": null}, {\"id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Bidirectional Language Models Are Also Few-shot Learners\", \"authors\": \"Ajay Patel, Bryan Li, Mohammad Sadegh Rasooli, Noah Constant, Colin Raffel, Chris Callison-Burch\", \"label\": \"Bidirectional Language Models Are Also Few-shot Learners\", \"abstract\": \"Large language models such as GPT-3 (Brown et al., 2020) can perform arbitrary tasks without undergoing fine-tuning after being prompted with only a few labeled examples. An arbitrary task can be reformulated as a natural language prompt, and a language model can be asked to generate the completion,...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=89a27fe3e20a404707a6e722e7ac75e5a41c936d\", \"img_url\": null, \"x\": -0.23768360656570728, \"y\": 1.0763915923771945, \"cluster\": 1, \"weights\": {\"Influence\": 4.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3452380952380953, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.871474865450991, \"summary\": null}, {\"id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs\", \"authors\": \"George Pu, Anirudh Jain, Jihan Yin, Russell Kaplan\", \"label\": \"Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs\", \"abstract\": \"As foundation models continue to exponentially scale in size, efficient methods of adaptation become increasingly critical. Parameter-efficient fine-tuning (PEFT), a recent class of techniques which require only modifying a small percentage of the model parameters, is currently the most popular meth...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8d60ddb46505a6c7cf1218d521823cb0c5c4cd66\", \"img_url\": null, \"x\": -0.3763581919951984, \"y\": 1.0526077285325206, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7419895401204848, \"summary\": null}, {\"id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Exploring Demonstration Ensembling for In-context Learning\", \"authors\": \"Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang\", \"label\": \"Exploring Demonstration Ensembling for In-context Learning\", \"abstract\": \"In-context learning (ICL) operates by showing language models (LMs) examples of input-output pairs for desired tasks, i.e., demonstrations. The standard approach for ICL is to prompt the LM with concatenated demonstrations followed by the test input. This approach suffers from some issues. First, co...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8e3711b88bf51197682b0faf1dda62e1e6496eb6\", \"img_url\": null, \"x\": -0.22703606845125812, \"y\": 1.1738793739912676, \"cluster\": 1, \"weights\": {\"Influence\": 7.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.5446428571428573, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8734756398667762, \"summary\": null}, {\"id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"DiffusER: Diffusion via Edit-based Reconstruction\", \"authors\": \"Machel Reid, Vincent Josua Hellendoorn, Graham Neubig\", \"label\": \"DiffusER: Diffusion via Edit-based Reconstruction\", \"abstract\": \"In text generation, models that generate text from scratch one token at a time are currently the dominant paradigm. Despite being performant, these models lack the ability to revise existing text, which limits their usability in many practical scenarios. We look to address this, with DiffusER (Diffu...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=8f1a724b5f7673c5cea51e10729a17139409b141\", \"img_url\": null, \"x\": -0.041411191366719356, \"y\": 0.9086910023373238, \"cluster\": 1, \"weights\": {\"Influence\": 5.333333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.38095238095238104, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8784853273354823, \"summary\": null}, {\"id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Words are all you need? Language as an approximation for human similarity judgments\", \"authors\": \"Raja Marjieh, Pol Van Rijn, Ilia Sucholutsky, Theodore Sumers, Harin Lee, Thomas L. Griffiths, Nori Jacoby\", \"label\": \"Words are all you need? Language as an approximation for human similarity judgments\", \"abstract\": \"Human similarity judgments are a powerful supervision signal for machine learning applications based on techniques such as contrastive learning, information retrieval, and model alignment, but classical methods for collecting human similarity judgments are too expensive to be used at scale. Recent m...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=910ef8ca812f569efa081784e20837687fa5412f\", \"img_url\": null, \"x\": -0.2694503028625009, \"y\": 0.5740298334616625, \"cluster\": 1, \"weights\": {\"Influence\": 3.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.25000000000000006, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8527803004256805, \"summary\": null}, {\"id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"TopEx: Topic-based Explanations for Model Comparison\", \"authors\": \"Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar\", \"label\": \"TopEx: Topic-based Explanations for Model Comparison\", \"abstract\": \"Meaningfully comparing language models is challenging with current explanation methods. Current explanations are overwhelming for humans due to large vocabularies or incomparable across models. We present TopEx, an explanation method that enables a level playing field for comparing language models v...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9191ed837c5f5e96fce1b9ab1a856e54ad27cf48\", \"img_url\": null, \"x\": -0.24199122438177392, \"y\": 0.6190951502543781, \"cluster\": 1, \"weights\": {\"Influence\": 5.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3750000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.816978346829752, \"summary\": null}, {\"id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation\", \"authors\": \"Yuqiao Wen, Yongchang Hao, Yanshuai Cao, Lili Mou\", \"label\": \"An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation\", \"abstract\": \"Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and acce...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=937cb172bd8fb345dd500451e9090a1d1c742a9f\", \"img_url\": null, \"x\": -0.0026146011535555748, \"y\": 0.8898172045191199, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8738116860791547, \"summary\": null}, {\"id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"LogicDP: Creating Labels for Graph Data via Inductive Logic Programming\", \"authors\": \"Yuan Yang, Faramarz Fekri, James Clayton Kerce, Ali Payani\", \"label\": \"LogicDP: Creating Labels for Graph Data via Inductive Logic Programming\", \"abstract\": \"Graph data, such as scene graphs and knowledge graphs, see wide use in AI systems. In real-world and large applications graph data are usually incomplete, motivating graph reasoning models for missing-fact or missing-relationship inference. While these models can achieve state-of-the-art performance...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55\", \"img_url\": null, \"x\": 0.2950823108167351, \"y\": 0.5217301144302876, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8177279910032236, \"summary\": null}, {\"id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Continual Pre-training of Language Models\", \"authors\": \"Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, Bing Liu\", \"label\": \"Continual Pre-training of Language Models\", \"abstract\": \"Language models (LMs) have been instrumental for the rapid advance of natural language processing. This paper studies continual pre-training of LMs, in particular, continual domain-adaptive pre-training (or continual DAP-training). Existing research has shown that further pre-training an LM using a ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=95b15e6145029721347f9996f2773d1b77d6bb66\", \"img_url\": null, \"x\": -0.2863181303489647, \"y\": 0.7020319582770451, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8738116860791547, \"summary\": null}, {\"id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models\", \"authors\": \"Xiaoman Pan, Wenlin Yao, Hongming Zhang, Dian Yu, Dong Yu, Jianshu Chen\", \"label\": \"Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models\", \"abstract\": \"Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=96125b9cbf068a1f19afb3437a569c6718491419\", \"img_url\": null, \"x\": -0.3166165272706902, \"y\": 1.1314113212079404, \"cluster\": 1, \"weights\": {\"Influence\": 5.416666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.38690476190476203, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8796537376495643, \"summary\": null}, {\"id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters\", \"authors\": \"Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, Huan Sun\", \"label\": \"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters\", \"abstract\": \"Chain-of-Thought (CoT) prompting, which encourages language models (LMs) to generate intermediate rationales for the final answer through in-context demonstrations, dramatically improves large LMs' ability to solve reasoning tasks. Despite its success, there is little understanding on what makes CoT...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=975b10e85ce2b8ad21d06c14449fe36492531eb6\", \"img_url\": null, \"x\": 0.016927284184623626, \"y\": 1.2436066118116933, \"cluster\": 1, \"weights\": {\"Influence\": 5.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3750000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8263391135426339, \"summary\": null}, {\"id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Systematic Rectification of Language Models via Dead-end Analysis\", \"authors\": \"Meng Cao, Mehdi Fatemi, Jackie CK Cheung, Samira Shabanian\", \"label\": \"Systematic Rectification of Language Models via Dead-end Analysis\", \"abstract\": \"With adversarial or otherwise normal prompts, existing large language models (LLM) can be pushed to generate toxic discourses. One way to reduce the risk of LLMs generating undesired discourses is to alter the training of the LLM. This can be very restrictive due to demanding computation requirement...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=978b9bb55b55d26ab62267a885cb369761805000\", \"img_url\": null, \"x\": 0.05058392421323517, \"y\": 0.8955037875011514, \"cluster\": 1, \"weights\": {\"Influence\": 1.875, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.13392857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8299962993010835, \"summary\": null}, {\"id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Leveraging Large Language Models for Multiple Choice Question Answering\", \"authors\": \"Joshua Robinson, David Wingate\", \"label\": \"Leveraging Large Language Models for Multiple Choice Question Answering\", \"abstract\": \"While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9a6e1b270d07b878a00eb571c87ce87cd859c93c\", \"img_url\": null, \"x\": -0.13004507212919608, \"y\": 1.3112897459599628, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1428571428571429, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8317489147722064, \"summary\": null}, {\"id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining\", \"authors\": \"Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant\", \"label\": \"UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining\", \"abstract\": \"Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we pr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9c29e03740cac092695afb43a5a70cf895bbb43a\", \"img_url\": null, \"x\": -0.34838397333744076, \"y\": 0.9558500516925984, \"cluster\": 1, \"weights\": {\"Influence\": 3.142857142857143, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2244897959183674, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8477728276510439, \"summary\": null}, {\"id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"heading\": \"ICLR, 16 Feb 2023\", \"title\": \"Instruction-Finetuned Foundation Models for Multimodal Web Navigation\", \"authors\": \"Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, Izzeddin Gur\", \"label\": \"Instruction-Finetuned Foundation Models for Multimodal Web Navigation\", \"abstract\": \"We propose an instruction-aligned multimodal agent for autonomous web navigation -- i.e., sequential decision making tasks employing a computer interface. Our approach is based on supervised finetuning of vision and language foundation models on a large corpus of web data consisting of webpage scree...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1\", \"img_url\": null, \"x\": 0.22284638301628046, \"y\": 0.9385445305899512, \"cluster\": 1, \"weights\": {\"Influence\": 4.583333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.32738095238095244, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8093323351869866, \"summary\": null}, {\"id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic\", \"authors\": \"Zijun Wu, Zi Xuan Zhang, Atharva Naik, Zhijian Mei, Mauajama Firdaus, Lili Mou\", \"label\": \"Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic\", \"abstract\": \"Natural language inference (NLI) aims to determine the logical relationship between two sentences, such as Entailment, Contradiction, and Neutral. In recent years, deep learning models have become a prevailing approach to NLI, but they lack interpretability and explainability. In this work, we addre...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1\", \"img_url\": null, \"x\": -0.0951451412052082, \"y\": 0.8724530825836803, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1428571428571429, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8317489147722064, \"summary\": null}, {\"id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Knowledge Distillation of BERT Language Model on the Arabic Language\", \"authors\": \"Hager Adil Ibrahim, Abrar Elidrisi, Mohamed Saeed\", \"label\": \"Knowledge Distillation of BERT Language Model on the Arabic Language\", \"abstract\": \"The absence of good Arabic language models led to significant setbacks in the Arabic language related tasks and lag with respect to robustness and accuracy. While a pre-trained version of BERT on Arabic language is available, a smaller distilled version could be proven to be highly scalable. In this...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9f025823831bf6a7883f12641ae4ab3fbe3120d7\", \"img_url\": null, \"x\": -0.4823071700641127, \"y\": 0.8248785872681726, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"The Geometry of Multilingual Language Models: A Fairness Lens\", \"authors\": \"Cheril Shah, Yashashree Chandak, Manan Suri\", \"label\": \"The Geometry of Multilingual Language Models: A Fairness Lens\", \"abstract\": \"Understanding the representations of different languages in multilingual language models is essential for comprehending their cross-lingual properties, predicting their performance on downstream tasks, and identifying any biases across languages. In our study, we analyze the geometry of three multil...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d\", \"img_url\": null, \"x\": -0.3955449719207445, \"y\": 0.9159176076761294, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"EFFECT OF TRAINING FRAGMENT LENGTH ON THE PERFORMANCE OF TRANSFORMERS IN TEXT COMPLEXITY CLASSIFICATION\", \"authors\": \"Rafik Hachana, Vladimir V. Ivanov\", \"label\": \"EFFECT OF TRAINING FRAGMENT LENGTH ON THE PERFORMANCE OF TRANSFORMERS IN TEXT COMPLEXITY CLASSIFICATION\", \"abstract\": \"With the myriad practical applications of text complexity classification, it is important to optimize the training text fragment size for performance. We experiment with fine-tuning pre-trained BERT models to classify the complexity of Russian school text using different fragment sizes for training....\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a15aa7f865c5a7ff51361bf3e04812165432fab5\", \"img_url\": null, \"x\": -0.44249718005194594, \"y\": 0.7808248770800627, \"cluster\": 1, \"weights\": {\"Influence\": 1.9999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.14285714285714285, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7489988756522312, \"summary\": null}, {\"id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning\", \"authors\": \"Sheng Zhang, Hao Cheng, Jianfeng Gao, Hoifung Poon\", \"label\": \"Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning\", \"abstract\": \"We present a bi-encoder framework for named entity recognition (NER), which applies contrastive learning to map candidate text spans and entity types into the same vector representation space. Prior work predominantly approaches NER as sequence labeling or span classification. We instead frame NER a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a78d1be317d81da5a4020349ba536e9181e1037a\", \"img_url\": null, \"x\": -0.33140995858726735, \"y\": 0.8293174064775243, \"cluster\": 1, \"weights\": {\"Influence\": 9.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6517857142857144, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9316479966262088, \"summary\": null}, {\"id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Copy is All You Need\", \"authors\": \"Tian Lan, Deng Cai, Yan Wang, Heyan Huang, Xian-Ling Mao\", \"label\": \"Copy is All You Need\", \"abstract\": \"The dominant text generation models compose the output by sequentially selecting words from a fixed vocabulary. In this paper, we formulate text generation as progressively copying text segments (e.g., words or phrases) from an existing text collection. We compute the contextualized representations ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a81bdd7b9216e082bde00e72490394930ab652a8\", \"img_url\": null, \"x\": -0.16966822878964527, \"y\": 0.8687999632452205, \"cluster\": 1, \"weights\": {\"Influence\": 4.9, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3500000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8724095937022565, \"summary\": null}, {\"id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Large Language Models Perform Diagnostic Reasoning\", \"authors\": \"Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen\", \"label\": \"Large Language Models Perform Diagnostic Reasoning\", \"abstract\": \"We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models traine...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a8b93e4304e78f871888067da2b86627e6d9d79d\", \"img_url\": null, \"x\": 0.03999793604039663, \"y\": 1.1720325783352037, \"cluster\": 1, \"weights\": {\"Influence\": 5.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4047619047619049, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8256936636473828, \"summary\": null}, {\"id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Train Monolingual, Infer Bilingual\", \"authors\": \"Alaeddin Sel\\u00e7uk G\\u00fcrel, Ayd\\u0131n Gerek\", \"label\": \"Train Monolingual, Infer Bilingual\", \"abstract\": \"Cross-lingual transfer learning has been studied at depth. While many methods\\nhave been developed for pretraining or fine-tuning on monolingual, multilingual\\nand parallel corpora with the purpose of predicting on a low-resource monolingual\\ntest set; in this paper we investigate the feasibility of tr...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=a9c04f1bd391a18bc1a275e91a0d4a73e570aec0\", \"img_url\": null, \"x\": -0.398812992790958, \"y\": 0.8845542076790472, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Language Models Inversely Scale on Piecewise Function Evaluation with Biased Examples\", \"authors\": \"Bradley CA Brown, Jordan Juravsky, Atif Mahmud, Wais Shahbaz, Ryan Saul Ehrlich\", \"label\": \"Language Models Inversely Scale on Piecewise Function Evaluation with Biased Examples\", \"abstract\": \"We investigate whether pretrained language models (LMs) can be misled by providing them with factually correct, but unrepresentative/biased examples, in the context of integer-to-integer piecewise functions. Given the definition of a piecewise function and several examples of the function\\u2019s evaluati...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=aa7c8e8d0e77d06be04cecb954275a993bfc0616\", \"img_url\": null, \"x\": -0.18770453400642523, \"y\": 1.150921234661605, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Text2Face: A Multi-Modal 3D Face Model\", \"authors\": \"Will Rowan, Patrik Huber, Nick Pears, Andrew Keeling\", \"label\": \"Text2Face: A Multi-Modal 3D Face Model\", \"abstract\": \"We present the first 3D morphable modelling approach, whereby 3D face shape can be directly and completely defined using a textual prompt. Building on work in multi-modal learning, we extend the FLAME head model to a common image-and-text latent space. This allows for direct 3D Morphable Model (3DMM...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ac9245791ee906fa4171932daaf6597a52c0fa98\", \"img_url\": null, \"x\": 0.16298410763984938, \"y\": 0.8436071609765728, \"cluster\": 1, \"weights\": {\"Influence\": 1.8333333333333335, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.130952380952381, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7455127489251789, \"summary\": null}, {\"id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"MetaXLR - Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit\", \"authors\": \"Liat Bezalel, Eyal Orgad\", \"label\": \"MetaXLR - Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit\", \"abstract\": \"Transfer learning for extremely low-resource languages is a challenging task as there is no large-scale monolingual corpora for pre-training or sufficient annotated data for fine-tuning. We follow the work of (Xia et al., 2021) which suggests using meta learning for transfer learning from a single s...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ace20966de455608877702bdba6ddfcf3d4c5248\", \"img_url\": null, \"x\": -0.3203871339179552, \"y\": 0.8928181341099815, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations\", \"authors\": \"Xinxi Lyu, Sewon Min, Iz Beltagy, Luke Zettlemoyer, Hannaneh Hajishirzi\", \"label\": \"Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations\", \"abstract\": \"Language models (LMs) perform a new task at test time either through zero-shot inference or few-shot in-context learning, i.e., conditioning on the k-shot training data (so-called demonstrations). Prior work suggests that in-context learning mainly activates the intrinsic ability of the LM. We argue...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ae051745891477c4d524fadadded72dc67e244e4\", \"img_url\": null, \"x\": -0.2527228213765697, \"y\": 1.2087152462839088, \"cluster\": 1, \"weights\": {\"Influence\": 9.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6607142857142859, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9057269473517157, \"summary\": null}, {\"id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection\", \"authors\": \"Mohammad Aflah Khan, Diksha Sethi, Neemesh Yadav, Raghav Sahni\", \"label\": \"Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection\", \"abstract\": \"Health experts assert that hope plays a crucial role in enhancing individuals' physical and mental well-being, facilitating their recovery, and promoting restoration. Hope speech refers to ``YouTube comments/posts that offer support, reassurance, suggestions, inspiration, and insight.\\\". The detectio...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b1093942944eb13269b1e4b7dbd71b931206ac32\", \"img_url\": null, \"x\": -0.3832260863561266, \"y\": 0.7786986245594146, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"QAID: Question Answering Inspired Few-shot Intent Detection\", \"authors\": \"Asaf Yehudai, Matan Vetzler, Yosi Mass, Koren Lazar, Doron Cohen, Boaz Carmeli\", \"label\": \"QAID: Question Answering Inspired Few-shot Intent Detection\", \"abstract\": \"Intent detection with semantically similar fine-grained intents is a challenging task. To address it, we reformulate intent detection as a question-answering retrieval task by treating utterances and intent names as questions and answers. To that end, we utilize a question-answering retrieval archit...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b18d2118bbae2664f100d7f2764db171c3e7ddbe\", \"img_url\": null, \"x\": -0.2915003224648094, \"y\": 0.8476433203916999, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8177279910032236, \"summary\": null}, {\"id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Bootstrapping Parallel Anchors for Relative Representations\", \"authors\": \"Irene Cannistraci, Luca Moschella, Valentino Maiorca, Marco Fumero, Antonio Norelli, Emanuele Rodol\\u00e0\", \"label\": \"Bootstrapping Parallel Anchors for Relative Representations\", \"abstract\": \"The use of relative representations for latent embeddings has shown potential in enabling latent space communication and zero-shot model stitching across a wide range of applications. Nevertheless, relative representations rely on a certain amount of parallel anchors to be given as input, which can ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b381e35373a8a5f711b8c30561f0955434490182\", \"img_url\": null, \"x\": -0.38878260752941884, \"y\": 0.6374808068251264, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21428571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7699156360145454, \"summary\": null}, {\"id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Compositional Task Representations for Large Language Models\", \"authors\": \"NAN SHAO, Zefan Cai, Hanwei xu, Chonghua Liao, Yanan Zheng, Zhilin Yang\", \"label\": \"Compositional Task Representations for Large Language Models\", \"abstract\": \"Large language models have shown a remarkable cross-task generalization ability. Most prior work assumed that prompts effectively extract knowledge from language models to facilitate generalization to new tasks. This perspective led to numerous studies on improving prompts. In contrast, we introduce...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b79aa79713c798b31118df4df4e474e744adf3b9\", \"img_url\": null, \"x\": -0.319897918971619, \"y\": 1.1870256347930186, \"cluster\": 1, \"weights\": {\"Influence\": 4.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.33928571428571436, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8703064551369091, \"summary\": null}, {\"id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints\", \"authors\": \"Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua Ainslie, Yi Tay, Mostafa Dehghani, Neil Houlsby\", \"label\": \"Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints\", \"abstract\": \"Training large, deep neural networks to convergence can be prohibitively expensive. As a result, often only a small selection of popular, dense models are reused across different contexts and tasks. Increasingly, sparsely activated models, which seek to decouple model size from computation costs, ar...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b82544e7b6f3d7f929005770613bc1d429ba6b26\", \"img_url\": null, \"x\": -0.4460368273193626, \"y\": 0.6700611526411716, \"cluster\": 1, \"weights\": {\"Influence\": 1.625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1160714285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8264910683588378, \"summary\": null}, {\"id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Editing models with task arithmetic\", \"authors\": \"Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Ludwig Schmidt, Hannaneh Hajishirzi, Ali Farhadi\", \"label\": \"Editing models with task arithmetic\", \"abstract\": \"Changing how pre-trained models behave---e.g., improving their performance on a downstream task or mitigating biases learned during pre-training---is a common practice when developing machine learning systems. In this work, we propose a new paradigm for steering the behavior of neural networks, cent...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b89d1b51f29771b7df36c5aa06d788ef19142453\", \"img_url\": null, \"x\": -0.4412707505331836, \"y\": 0.610207106988474, \"cluster\": 1, \"weights\": {\"Influence\": 6.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.47619047619047633, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8971798923607928, \"summary\": null}, {\"id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Speech Emotion Recognition Goes Textual: Using Modality Conversion to Unlock Emotion Recognition from Audio\", \"authors\": \"Zeinab Sadat Taghavi, Ali Satvaty\", \"label\": \"Speech Emotion Recognition Goes Textual: Using Modality Conversion to Unlock Emotion Recognition from Audio\", \"abstract\": \"Emotion recognition from the speech is a challenging task. In this paper, we propose a modality conversion approach to improve emotion recognition performance on the MELD dataset by converting speech to text and leveraging text-based features. We propose a model called Modality-Conversion which auto...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=b9adac8b86a46ce53d30f935c93d94efe8240723\", \"img_url\": null, \"x\": -0.34318426167238636, \"y\": 0.7012788071781665, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"ReAct: Synergizing Reasoning and Acting in Language Models\", \"authors\": \"Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, Yuan Cao\", \"label\": \"ReAct: Synergizing Reasoning and Acting in Language Models\", \"abstract\": \"While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=bc3f48deb9335657a0435bf09275fe89d55b5beb\", \"img_url\": null, \"x\": 0.04400198118176531, \"y\": 1.2117122367487163, \"cluster\": 1, \"weights\": {\"Influence\": 4.333333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3095238095238096, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8644644035664996, \"summary\": null}, {\"id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models\", \"authors\": \"Guande He, Jianfei Chen, Jun Zhu\", \"label\": \"Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models\", \"abstract\": \"Large pre-trained language models (PLMs) have demonstrated strong performance on natural language understanding (NLU) tasks through fine-tuning. However, fine-tuned models still suffer from overconfident predictions, especially in out-of-domain settings. In this paper, we tackle the problem of calib...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=bcc767207b1287eb294e9a467c460545751f87f6\", \"img_url\": null, \"x\": -0.4356802535104131, \"y\": 0.726195361073068, \"cluster\": 1, \"weights\": {\"Influence\": 9.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6964285714285716, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9404110739818231, \"summary\": null}, {\"id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Understanding HTML with Large Language Models\", \"authors\": \"Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin V Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, Aleksandra Faust\", \"label\": \"Understanding HTML with Large Language Models\", \"abstract\": \"Large language models (LLMs) have shown exceptional performance on a variety of natural language tasks. Yet, their capabilities for HTML understanding -- i.e., parsing the raw HTML of a webpage, with applications to automation of web-based tasks, crawling, and browser-assisted retrieval -- have not ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=bd92f5a11981955438485317e8838ce905ae9fb4\", \"img_url\": null, \"x\": 0.0010984233570244762, \"y\": 0.9875990371383668, \"cluster\": 1, \"weights\": {\"Influence\": 2.9285714285714284, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2091836734693878, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7802658171355776, \"summary\": null}, {\"id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Out-of-context Meta-learning in Large Language Models\", \"authors\": \"Dmitrii Krasheninnikov, Egor Krasheninnikov, David Krueger\", \"label\": \"Out-of-context Meta-learning in Large Language Models\", \"abstract\": \"Brown (2020) famously introduced the phenomenon of in-context meta-learning in large language models (LLMs). Our work establishes the existence of a phenomenon we call out-of-context meta-learning via carefully designed synthetic experiments with large language models. We argue that out-of-context m...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c3233f783e071d58d17669ed4b17040c83622fbc\", \"img_url\": null, \"x\": -0.09972446484309391, \"y\": 1.213535111277683, \"cluster\": 1, \"weights\": {\"Influence\": 2.75, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.19642857142857148, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.776721717411958, \"summary\": null}, {\"id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Automatic Chain of Thought Prompting in Large Language Models\", \"authors\": \"Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola\", \"label\": \"Automatic Chain of Thought Prompting in Large Language Models\", \"abstract\": \"Large Language Models (LLMs) can carry out complex reasoning tasks by generating intermediate reasoning steps. These steps are triggered by what is called chain-of-thought (CoT) prompting, which comes in two flavors: one leverages a simple prompt like \\\"Let\\u2019s think step by step\\\" to facilitate step-by...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c35345142c29c10dd877b90f067671ad2dc9081c\", \"img_url\": null, \"x\": -0.06056236970642551, \"y\": 1.273820799447812, \"cluster\": 1, \"weights\": {\"Influence\": 6.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4642857142857144, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.894843071732629, \"summary\": null}, {\"id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Is a Caption Worth a Thousand Images? A Study on Representation Learning\", \"authors\": \"Shibani Santurkar, Yann Dubois, Rohan Taori, Percy Liang, Tatsunori Hashimoto\", \"label\": \"Is a Caption Worth a Thousand Images? A Study on Representation Learning\", \"abstract\": \"The development of CLIP [Radford et al., 2021] has sparked a debate on whether adding language supervision can yield vision models with more transferable representations than traditional image-only methods. Our work studies this question through a carefully controlled comparison of two approaches, i...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2\", \"img_url\": null, \"x\": -0.16305930275856373, \"y\": 0.6865751926741734, \"cluster\": 1, \"weights\": {\"Influence\": 5.7, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.40714285714285725, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8836263327174427, \"summary\": null}, {\"id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Pivot Pre-finetuning for Low Resource MT: A Case Study in Kikamba\", \"authors\": \"Stephen Ngumbi Kiilu, Machel Reid\", \"label\": \"Pivot Pre-finetuning for Low Resource MT: A Case Study in Kikamba\", \"abstract\": \"Current approaches to performant machine translation often require large amounts of data (Koehn et al., 2022). However for a majority of 7000+ languages in the world, these languages often have a relative lack of digitized/organized text available, and are considered low-resource. In practical terms...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c5c408ff21f5280879d55665f2fc11a13b53fa95\", \"img_url\": null, \"x\": -0.3221214293730492, \"y\": 0.9386628964128378, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for Classification of Common Mental Illnesses on Social Media Posts\", \"authors\": \"Pratinav Seth, Mihir Agarwal\", \"label\": \"Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for Classification of Common Mental Illnesses on Social Media Posts\", \"abstract\": \"Given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c81c3af55037853a58cb4d1020c7e1ed37e702e0\", \"img_url\": null, \"x\": -0.4961245450641758, \"y\": 0.6308997713282829, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales\", \"authors\": \"PeiFeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, Xiang Ren\", \"label\": \"PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales\", \"abstract\": \"Neural language models (LMs) have achieved impressive results on various language-based reasoning tasks by utilizing latent knowledge encoded in their own pretrained parameters. To make this reasoning process more explicit, recent works retrieve a rationalizing LM's internal knowledge by training or...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=c9bcbab395245c32bcfb60369320486a3d89ef98\", \"img_url\": null, \"x\": -0.17086279110317892, \"y\": 1.2753940488702673, \"cluster\": 1, \"weights\": {\"Influence\": 3.1, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2214285714285715, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8471719309180874, \"summary\": null}, {\"id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Decomposed Prompting: A Modular Approach for Solving Complex Tasks\", \"authors\": \"Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, Ashish Sabharwal\", \"label\": \"Decomposed Prompting: A Modular Approach for Solving Complex Tasks\", \"abstract\": \"Few-shot prompting is a surprisingly powerful way to use Large Language Models (LLMs) to solve various tasks. However, this approach struggles as the task complexity increases or when the individual reasoning steps of the task themselves are hard to learn, especially when embedded in more complex ta...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cafcd1ec66445ef30a74de00ab878462088c0e5b\", \"img_url\": null, \"x\": -0.039687391247876645, \"y\": 1.2249853161610704, \"cluster\": 1, \"weights\": {\"Influence\": 4.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.30357142857142866, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8632959932524177, \"summary\": null}, {\"id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Neural Compositional Rule Learning for Knowledge Graph Reasoning\", \"authors\": \"Kewei Cheng, Nesreen Ahmed, Yizhou Sun\", \"label\": \"Neural Compositional Rule Learning for Knowledge Graph Reasoning\", \"abstract\": \"Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn logic...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cb874b3ac26b4b643bd11d102ad4a64f13b494dd\", \"img_url\": null, \"x\": 0.28734149396503816, \"y\": 0.5537338562064752, \"cluster\": 1, \"weights\": {\"Influence\": 4.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3452380952380953, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.871474865450991, \"summary\": null}, {\"id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation\", \"authors\": \"Lorenz Kuhn, Yarin Gal, Sebastian Farquhar\", \"label\": \"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation\", \"abstract\": \"We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of \\\"semantic equivalenc...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cba38b30b10b856818a1b2c96e147c90b526500e\", \"img_url\": null, \"x\": -0.025811803111103947, \"y\": 1.0429736728272063, \"cluster\": 1, \"weights\": {\"Influence\": 4.333333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3095238095238096, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8644644035664996, \"summary\": null}, {\"id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"DocPrompting: Generating Code by Retrieving the Docs\", \"authors\": \"Shuyan Zhou, Uri Alon, Frank F. Xu, Zhengbao Jiang, Graham Neubig\", \"label\": \"DocPrompting: Generating Code by Retrieving the Docs\", \"abstract\": \"Publicly available source-code libraries are continuously growing and changing. This makes it impossible for models of code\\nto keep current with all available APIs by simply training these models on existing code repositories. Thus, existing models inherently cannot generalize to using unseen functi...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cd07e6460b349dbaae2d346eea1f5c1ce90e9347\", \"img_url\": null, \"x\": -0.13301317150909892, \"y\": 1.0589874557735786, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8738116860791547, \"summary\": null}, {\"id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Compound Tokens: Channel Fusion for Vision-Language Representation Learning\", \"authors\": \"Maxwell Mbabilla Aladago, AJ Piergiovanni\", \"label\": \"Compound Tokens: Channel Fusion for Vision-Language Representation Learning\", \"abstract\": \"We present an effective method for fusing visual-and-language representations for several question answering tasks including visual question answering and visual entailment.\\nIn contrast to prior works that concatenate unimodal representations or use only cross-attention, we compose multimodal repres...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=cde088dabad3c7da68d013f4869713cd792ba962\", \"img_url\": null, \"x\": -0.15879058473531996, \"y\": 0.7887895769798363, \"cluster\": 1, \"weights\": {\"Influence\": 3.499999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7803740161957023, \"summary\": null}, {\"id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Transformer Performance on Kinyarwanda Tweets using Trainer Framework\", \"authors\": \"Roger Byakunda\", \"label\": \"Transformer Performance on Kinyarwanda Tweets using Trainer Framework\", \"abstract\": \"Abstract:\\nNatural language processing (NLP) has become an essential part of many industries, and sentiment analysis is one of its significant applications. In this paper, we evaluate the performance of different transformer models on Kinyarwanda tweets using the Trainer framework. We used the Kinyar...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d01647148dc09c77c31fbf9c08f181710ef2e94a\", \"img_url\": null, \"x\": -0.41727272678272737, \"y\": 0.7977154747809937, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization\", \"authors\": \"Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kiant\\u00e9 Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, Yejin Choi\", \"label\": \"Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization\", \"abstract\": \"We tackle the problem of aligning pre-trained large language models (LMs) with human preferences. If we view text generation as a sequential decision-making problem, reinforcement learning (RL) appears to be a natural conceptual framework. However, using RL for LM-based generation faces empirical ch...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d05cd121f1b7d8dbc66d65141de6284818425b34\", \"img_url\": null, \"x\": 0.0651971365576, \"y\": 0.8509829430764504, \"cluster\": 1, \"weights\": {\"Influence\": 4.5625, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3258928571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8676775319302248, \"summary\": null}, {\"id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis\", \"authors\": \"Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong\", \"label\": \"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis\", \"abstract\": \"Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resourc...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d0e39e56013f39042797c59aa4fabe8ddfc44c14\", \"img_url\": null, \"x\": -0.13973551965636097, \"y\": 1.0184298209859204, \"cluster\": 1, \"weights\": {\"Influence\": 6.125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4375000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8895852253192604, \"summary\": null}, {\"id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Evaluating Impact of Emoticons and Pre-processing on Sentiment Classification of Translated African Tweets\", \"authors\": \"Saurav Keshari Aryal, Gaurav Adhikari\", \"label\": \"Evaluating Impact of Emoticons and Pre-processing on Sentiment Classification of Translated African Tweets\", \"abstract\": \"This paper examines the impact of emoticons and pre-processing on sentiment classification for English translations of 11 African languages. Using AfriSenti-SemEval datasets, Roberta and Twitter-Roberta models are fine-tuned, and standard classification metrics are used to assess performance. The st...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d37954de196d2a847c8c987dc562f58649e88c9f\", \"img_url\": null, \"x\": -0.32730115060392695, \"y\": 0.6545255582267955, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Neuromodulation Gated Transformer\", \"authors\": \"Kobe Knowles, Joshua Bensemann, Diana Benavides Prado, Vithya Yogarajan, Michael Witbrock, Gillian Dobbie, Yang Chen\", \"label\": \"Neuromodulation Gated Transformer\", \"abstract\": \"We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation s...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d4fdae33a9ad8746cdcfb319930e0e73f4bdab99\", \"img_url\": null, \"x\": -0.47256390783620544, \"y\": 0.9369830509873343, \"cluster\": 1, \"weights\": {\"Influence\": 1.3333333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.09523809523809526, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7350543687440219, \"summary\": null}, {\"id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"SUDANESE ARABIC DIALECT ENCODING USING XLM-RoBERTa LANGUAGE MODEL: Zol-ROBERTA\", \"authors\": \"Duaa Badradein Alshareif, Taiseer Abdulateef Fadlalla, Muhammed Yahya Saeed, Hiba Hassan S. M. Ali\", \"label\": \"SUDANESE ARABIC DIALECT ENCODING USING XLM-RoBERTa LANGUAGE MODEL: Zol-ROBERTA\", \"abstract\": \"XLM-RoBERTa  has proven to be very efficient at Natural Language Understanding (NLU), as it allows to achieve state-of-the-art results in most NLU tasks. In this work we aim to utilize the power of XLM-RoBERTa in Sudanese Arabic dialect. We collected over 6 million sentences in Sudanese dialect and ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d506fe02791a542e41a537538e4d5d1489c96e65\", \"img_url\": null, \"x\": -0.45454196634272565, \"y\": 0.814550812899334, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Inducing Document Representations from Graphs: A Blueprint\", \"authors\": \"Boshko Koloski, Marko Pranjic, Nada Lavrac, Bla\\u017e \\u0160krlj, Senja Pollak\", \"label\": \"Inducing Document Representations from Graphs: A Blueprint\", \"abstract\": \"Representing textual documents in continuous numerical spaces is a crucial task in NLP. Early practitioners of NLP built their approach around capturing statistical patterns within documents and utilizing them as features in rich feature spaces. In contrast, contemporary state-of-the-art techniques ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d50b8d236c86c155f99d4f95c8885b8b176e05cd\", \"img_url\": null, \"x\": -0.32281403863159236, \"y\": 0.731740642136762, \"cluster\": 1, \"weights\": {\"Influence\": 1.6666666666666665, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.11904761904761907, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7420266221981267, \"summary\": null}, {\"id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Text-Based Games as a Challenging Benchmark for Large Language Models\", \"authors\": \"Qinyue Tan, Ashkan Kazemi, Rada Mihalcea\", \"label\": \"Text-Based Games as a Challenging Benchmark for Large Language Models\", \"abstract\": \"Text-based games (TBG) are puzzle-solving, interactive dialogue, and generic language tasks that can play a substantial role as a challenging intelligence benchmark for large language models (LLMs.) TBGs are similar to interactive dialogue as they both require the capability for bidirectional commun...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d5c87578f6adfbadc7a945c6a171637ba37a943b\", \"img_url\": null, \"x\": 0.11467790797331325, \"y\": 0.9868168071623814, \"cluster\": 1, \"weights\": {\"Influence\": 13.999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 1.0, \"summary\": null}, {\"id\": \"d98e77771649b72cb8f3aedc3e437177e56f3b5c_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Heat Up The Sentiment Learning With Ice\", \"authors\": \"Yao Yao, Zuchao Li, hai zhao\", \"label\": \"Heat Up The Sentiment Learning With Ice\", \"abstract\": \"Recently, dramatic gains have been made on the task of aspect sentiment triplet extraction (ASTE). In this paper, we introduce a straightforward pipeline model to perform two-stage sequence labeling, including aspect and opinion terms identification and aspect-opinion pair classification. To exploit...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=d98e77771649b72cb8f3aedc3e437177e56f3b5c\", \"img_url\": null, \"x\": -1.0175281353871268, \"y\": 0.04612674993661139, \"cluster\": 1, \"weights\": {\"Influence\": 5.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3571428571428572, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8117491567391735, \"summary\": null}, {\"id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge\", \"authors\": \"Qianqian Qi, Qiming Bao, Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock\", \"label\": \"A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge\", \"abstract\": \"Transformer-based pretrained language models (PLMs) have shown to pre-learn rich prior knowledge. To assist data-to-text task, we propose a new dynamic prompt tuning method, DPTAK, to retrieve knowledge from a PLM that is associated with individual data-text pairs. Our method increases the diversity...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=da0958299f99644b57c73d2bf02751c91c512435\", \"img_url\": null, \"x\": -0.19525395312928248, \"y\": 0.8299581222480589, \"cluster\": 1, \"weights\": {\"Influence\": 2.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.16071428571428575, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7542280657428098, \"summary\": null}, {\"id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Seeing in Words: Learning to Classify through Language Bottleneck\", \"authors\": \"Khalid Saifullah, Yuxin Wen, Jonas Geiping, Micah Goldblum, Tom Goldstein\", \"label\": \"Seeing in Words: Learning to Classify through Language Bottleneck\", \"abstract\": \"Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks.  In contrast, humans can explain their predictions using succinct and intuitive descriptions.  To incorporate explainability into neural networks, we train a vision model whose feature...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=dac362da9a96399c3bc20245191e0f4a13f948cd\", \"img_url\": null, \"x\": -0.4005756295184844, \"y\": 0.6850115685500067, \"cluster\": 1, \"weights\": {\"Influence\": 3.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.21428571428571433, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7699156360145454, \"summary\": null}, {\"id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Attention-likelihood relationship in Transformers\", \"authors\": \"Valeria Ruscio, Valentino Maiorca, Fabrizio Silvestri\", \"label\": \"Attention-likelihood relationship in Transformers\", \"abstract\": \"We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models. ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8\", \"img_url\": null, \"x\": -0.20254613739205668, \"y\": 0.7575831074331022, \"cluster\": 1, \"weights\": {\"Influence\": 3.499999999999999, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7803740161957023, \"summary\": null}, {\"id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Concept Understanding in Large Language Models: An Empirical Study\", \"authors\": \"Jiayi Liao, Xu Chen, Lun Du\", \"label\": \"Concept Understanding in Large Language Models: An Empirical Study\", \"abstract\": \"Large-scale Language Models (LLMs) like GPT have demonstrated their superior comprehension and expressiveness across a wide range of tasks, and exhibited remarkable capabilities in real-world applications such as Copilot and New Bing. Hence, it is crucial to investigate LLM's potential and limitatio...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=dd6954f60cf1a50db825a641f9f491d1cea0745c\", \"img_url\": null, \"x\": 0.04317848045791635, \"y\": 0.9826410740532812, \"cluster\": 1, \"weights\": {\"Influence\": 4.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3214285714285715, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8012907765580164, \"summary\": null}, {\"id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"TEMPERA: Test-Time Prompt Editing via Reinforcement Learning\", \"authors\": \"Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, Joseph E. Gonzalez\", \"label\": \"TEMPERA: Test-Time Prompt Editing via Reinforcement Learning\", \"abstract\": \"Careful prompt design is critical to the use of large language models in zero-shot or few-shot learning.  As a consequence, there is a growing interest in automated methods to design optimal prompts. In this work, we propose Test-time Prompt Editing using Reinforcement learning (TEMPERA). In contras...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=dfef527565afabe77677ca6a9ab51a12ff0dfd9f\", \"img_url\": null, \"x\": -0.4333544527580105, \"y\": 1.0538220917337375, \"cluster\": 1, \"weights\": {\"Influence\": 4.7, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3357142857142858, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.86960540894846, \"summary\": null}, {\"id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"One Student Knows All Experts Know: From Sparse to Dense\", \"authors\": \"Fuzhao Xue, Xiaoxin He, Xiaozhe Ren, Yuxuan Lou, Yang You\", \"label\": \"One Student Knows All Experts Know: From Sparse to Dense\", \"abstract\": \"Human education system trains one student by multiple experts. Mixture-of-experts (MoE) is a powerful sparse architecture including multiple experts. However, sparse MoE model is easy to overfit, hard to deploy, and not hardware-friendly for practitioners. In this work, inspired by the human educati...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15\", \"img_url\": null, \"x\": -0.5226319732778855, \"y\": 0.6784945626214004, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?\", \"authors\": \"Mert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, James Zou\", \"label\": \"When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?\", \"abstract\": \"Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode the compositional relationships between objects and attributes. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the abili...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e3948c0ed73dea5112c96405fc413cdd1b55aafd\", \"img_url\": null, \"x\": -0.05503435980436798, \"y\": 0.7434541005818205, \"cluster\": 1, \"weights\": {\"Influence\": 4.6, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3285714285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8682033165715617, \"summary\": null}, {\"id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Improving Foundation Models for Few-Shot Learning via Multitask Finetuning\", \"authors\": \"Zhuoyan Xu, Zhenmei Shi, Junyi Wei, Yin Li, Yingyu Liang\", \"label\": \"Improving Foundation Models for Few-Shot Learning via Multitask Finetuning\", \"abstract\": \"Foundation models have become essential tools for AI. In this paper, we study the problem of adapting foundation models, pre-trained using contrastive learning, to downstream tasks with limited labels. We explore the paradigm of finetuning a foundation model before adapting to a target task, using a...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e3b6b2f4b010d549a82b36382e6fd4b7a3952012\", \"img_url\": null, \"x\": -0.6171958721274698, \"y\": 0.5834151956443174, \"cluster\": 1, \"weights\": {\"Influence\": 4.833333333333333, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3452380952380953, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8180695475208546, \"summary\": null}, {\"id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus\", \"authors\": \"Gang Li, Yang Li\", \"label\": \"Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus\", \"abstract\": \"Mobile UI understanding is important for enabling various interaction tasks such as UI automation and accessibility. Previous mobile UI modeling often depends on the view hierarchy information of a screen, which directly provides the structural data of the UI, with the hope to bypass challenging tas...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e5959dbd4a4308f02e63a5a46f13123d6b86b550\", \"img_url\": null, \"x\": 0.015692141831677234, \"y\": 0.8249352862948215, \"cluster\": 1, \"weights\": {\"Influence\": 5.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3750000000000001, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8773169170214005, \"summary\": null}, {\"id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Language Models are Visual Reasoning Coordinators\", \"authors\": \"Liangyu Chen, Bo Li, Sheng Shen, Jingkang Yang, Chunyuan Li, Kurt Keutzer, Trevor Darrell, Ziwei Liu\", \"label\": \"Language Models are Visual Reasoning Coordinators\", \"abstract\": \"Visual reasoning demands multimodal perception and commonsense cognition of the world. Recently, multiple vision-language models (VLMs) have been proposed with excellent commonsense reasoning ability in various domains. However, how to harness the collective power of these complementary VLMs is rare...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e747c96b77f105b1f5267b44d32d8b80b87988f9\", \"img_url\": null, \"x\": -0.03274764922675332, \"y\": 1.0943415454210532, \"cluster\": 1, \"weights\": {\"Influence\": 9.8125, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.7008928571428573, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9168908614811178, \"summary\": null}, {\"id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"heading\": \"ICLR, 16 Mar 2023\", \"title\": \"Tiny Attention: A Simple yet Effective Method for Learning Contextual Word Embeddings\", \"authors\": \"Renjith P Ravindran\", \"label\": \"Tiny Attention: A Simple yet Effective Method for Learning Contextual Word Embeddings\", \"abstract\": \"Contextual Word Embedding (CWE) obtained via the Attention Mechanism  in Transformer (AMT) models is one of the key drivers of the current revolution in Natural Language Processing. Previous techniques for learning CWEs are not only inferior to AMT  but also are largely subpar to the simple bag-of-w...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=e859b51d2b2320027737e41f46f812a6c58ae42a\", \"img_url\": null, \"x\": -0.446908857229551, \"y\": 0.958864548192007, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7176915898728794, \"summary\": null}, {\"id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion\", \"authors\": \"Aleksandar Pavlovi\\u0107, Emanuel Sallinger\", \"label\": \"ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion\", \"abstract\": \"Knowledge graphs are inherently incomplete. Therefore substantial research has been directed toward knowledge graph completion (KGC), i.e., predicting missing triples from the information represented in the knowledge graph (KG). KG embedding models (KGEs) have yielded promising results for KGC, yet ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ec3ffbe30adb404a1930acdb57d8147a5ed9bb76\", \"img_url\": null, \"x\": 0.3215872636802552, \"y\": 0.5494989118701978, \"cluster\": 1, \"weights\": {\"Influence\": 1.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.10714285714285714, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.824738452887715, \"summary\": null}, {\"id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning\", \"authors\": \"Olga Golovneva, Moya Peng Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz\", \"label\": \"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning\", \"abstract\": \"Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer)...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ec88d5b172eda48e48732f2dc404038efb08de78\", \"img_url\": null, \"x\": -0.06933965942628696, \"y\": 1.060991894458897, \"cluster\": 1, \"weights\": {\"Influence\": 6.25, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.44642857142857156, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8913378407903834, \"summary\": null}, {\"id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention\", \"authors\": \"Xiao Liu, Jian Zhang, Heng Zhang, Fuzhao Xue, Yang You\", \"label\": \"Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention\", \"abstract\": \"Compared with standard text, understanding dialogue is more challenging for machines as the dynamic and unexpected semantic changes in each turn. To model such inconsistent semantics, we propose a simple but effective Hierarchical Dialogue Understanding model, HiDialog. Specifically, we first insert...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=edc4ce7e3a05029da0822552360173e983ec2d15\", \"img_url\": null, \"x\": -0.3257845375773203, \"y\": 0.7900508637498896, \"cluster\": 1, \"weights\": {\"Influence\": 2.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1785714285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7594572558333883, \"summary\": null}, {\"id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"On Compositional Uncertainty Quantification for Seq2seq Graph Parsing\", \"authors\": \"Zi Lin, Du Phan, Panupong Pasupat, Jeremiah Zhe Liu, Jingbo Shang\", \"label\": \"On Compositional Uncertainty Quantification for Seq2seq Graph Parsing\", \"abstract\": \"Recent years have witnessed the success of applying seq2seq models to graph parsing tasks, where the outputs are compositionally structured (e.g., a graph or a tree). However, these seq2seq approaches pose a challenge in quantifying the model\\u2019s compositional uncertainty on graph structures due to th...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=edcc8581bdc4323bde3142870303f78734c689d1\", \"img_url\": null, \"x\": -0.08386769597165193, \"y\": 0.9369436568927467, \"cluster\": 1, \"weights\": {\"Influence\": 2.4, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.17142857142857146, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8373572842797995, \"summary\": null}, {\"id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"A Kernel-Based View of Language Model Fine-Tuning\", \"authors\": \"Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, Sanjeev Arora\", \"label\": \"A Kernel-Based View of Language Model Fine-Tuning\", \"abstract\": \"It has become standard to solve NLP tasks by  fine-tuning pre-trained language models (LMs), especially in low-data settings. There is minimal theoretical understanding of empirical success, e.g., why fine-tuning a model with $10^8$ or more parameters on a couple dozen training points does not resul...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ee1417ff85e32faeef31fc9e599a008b1c7fe7a8\", \"img_url\": null, \"x\": -0.575071309001082, \"y\": 0.7040820470435553, \"cluster\": 1, \"weights\": {\"Influence\": 6.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.47619047619047633, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8544556380166837, \"summary\": null}, {\"id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"The Obscure Limitation of Modular Multilingual Language Models\", \"authors\": \"Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Ayu Purwarianti\", \"label\": \"The Obscure Limitation of Modular Multilingual Language Models\", \"abstract\": \"We expose the limitation of modular multilingual language models (MLMs) in multilingual inference scenarios with unknown languages. Existing evaluations of modular MLMs exclude the involvement of language identification (LID) modules, which obscures the performance of real-case multilingual scenario...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ee9a49bba36009f18ec88780318e26bdb0fe67de\", \"img_url\": null, \"x\": -0.34114304266079354, \"y\": 0.9929678489798808, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Planning with Large Language Models for Code Generation\", \"authors\": \"Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, Chuang Gan\", \"label\": \"Planning with Large Language Models for Code Generation\", \"abstract\": \"Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ef753072577c9bf2ca217138d9dbc96c4c67844d\", \"img_url\": null, \"x\": -0.10147118490195546, \"y\": 0.990836997618731, \"cluster\": 1, \"weights\": {\"Influence\": 5.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4047619047619049, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.88315896859181, \"summary\": null}, {\"id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners\", \"authors\": \"Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, Minjoon Seo\", \"label\": \"Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners\", \"abstract\": \"Instruction-tuning, which fine-tunes the language model (LM) on various downstream tasks with task instruction, has improved the zero-shot task generalization performance. However, instruction-tuned LMs still struggle to generalize to challenging unseen tasks containing novel labels. In this paper, ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f07a68845de39a9a44c22cc9171cf8911a241425\", \"img_url\": null, \"x\": -0.26094424512677333, \"y\": 1.3026061313822992, \"cluster\": 1, \"weights\": {\"Influence\": 2.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1785714285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7717599777988904, \"summary\": null}, {\"id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"heading\": \"ICLR, 08 Feb 2023\", \"title\": \"Controlled assessment of CLIP-style language-aligned vision models in prediction of brain & behavioral data\", \"authors\": \"Colin Conwell, Jacob S. Prince, Christopher J Hamblin, George A. Alvarez\", \"label\": \"Controlled assessment of CLIP-style language-aligned vision models in prediction of brain & behavioral data\", \"abstract\": \"One of the core algorithmic forces driving the development of modern foundation models is the use of contrastive language alignment to facilitate more robust visual representation learning. The clear benefits conferred by CLIP-style multimodal objective functions in computer vision have generated a ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0\", \"img_url\": null, \"x\": -0.17348430071197823, \"y\": 0.6309382841844268, \"cluster\": 1, \"weights\": {\"Influence\": 1.4999999999999996, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.10714285714285714, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7519130193466199, \"summary\": null}, {\"id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study\", \"authors\": \"Mingxu Tao, Yansong Feng, Dongyan Zhao\", \"label\": \"Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study\", \"abstract\": \"Large pre-trained language models have helped to achieve state of the art on a variety of NLP tasks, nevertheless, they still suffer from forgetting when incrementally learning a series of sequential tasks. To alleviate this problem, recent works propose several models enhanced by sparse experience ...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f0e004db0e135c69347bd9b1703c2469526fc2cd\", \"img_url\": null, \"x\": -0.28989793758818416, \"y\": 0.7649890383846217, \"cluster\": 1, \"weights\": {\"Influence\": 6.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.4642857142857144, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.894843071732629, \"summary\": null}, {\"id\": \"f397b5eed0598c8f0c156205a8fc24d52b6035db_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Characters Are Like Faces\", \"authors\": \"Haoyu Deng, Zhaoteng Ye, Yule Duan\", \"label\": \"Characters Are Like Faces\", \"abstract\": \"There are over 100,000 characters in Chinese, though only four thousand of them are used in our daily life. However for cultural researchers, they interact with those Rarely Used Characters (RUCs) frequently. It would facilitate using these RUCs for them with Optical Character Recognition (OCR) tech...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f397b5eed0598c8f0c156205a8fc24d52b6035db\", \"img_url\": null, \"x\": -0.1305052768808199, \"y\": 0.5160353942459109, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning\", \"authors\": \"Antonia Creswell, Murray Shanahan, Irina Higgins\", \"label\": \"Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning\", \"abstract\": \"Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of logical...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f5fd381915e6e70cfeacb9d5702995fbd7475c6b\", \"img_url\": null, \"x\": 0.0004906868417996901, \"y\": 1.208313296061705, \"cluster\": 1, \"weights\": {\"Influence\": 4.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3214285714285715, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8668012241946634, \"summary\": null}, {\"id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models\", \"authors\": \"Navid Madani, Kenneth Joseph\", \"label\": \"Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models\", \"abstract\": \"Question Answering over Knowledge Graphs (KGQA) is the task of answering natural language questions over a knowledge graph (KG). This task requires a model to reason over multiple edges of the KG to reach the right answer. In this work,  we present a method to equip large language models (LLMs) with...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f6b9ad972b9eb3722721e33d00e71bc97a773a66\", \"img_url\": null, \"x\": 0.057057297690489575, \"y\": 1.0967312289892195, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"The Art of Embedding Fusion: Optimizing Hate Speech Detection\", \"authors\": \"Mohammad Aflah Khan, Neemesh Yadav, Mohit Jain, Sanyam Goyal\", \"label\": \"The Art of Embedding Fusion: Optimizing Hate Speech Detection\", \"abstract\": \"Hate speech detection is a challenging natural language processing task that requires capturing linguistic and contextual nuances. Pre-trained language models (PLMs) offer rich semantic representations of text that can improve this task. However there is still limited knowledge about ways to effecti...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8\", \"img_url\": null, \"x\": -0.35711844717950325, \"y\": 0.7598803408129915, \"cluster\": 1, \"weights\": {\"Influence\": 1.5, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.10714285714285716, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7385404954710743, \"summary\": null}, {\"id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Language models are multilingual chain-of-thought reasoners\", \"authors\": \"Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, Jason Wei\", \"label\": \"Language models are multilingual chain-of-thought reasoners\", \"abstract\": \"We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We fin...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=f76a317c21d03bcfba077169d330596d7f74fe24\", \"img_url\": null, \"x\": -0.14658096148511418, \"y\": 1.1905537081928597, \"cluster\": 1, \"weights\": {\"Influence\": 3.55, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.2535714285714286, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8534813466141297, \"summary\": null}, {\"id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Can Neural Networks Learn Implicit Logic from Physical Reasoning?\", \"authors\": \"Aaron Traylor, Roman Feiman, Ellie Pavlick\", \"label\": \"Can Neural Networks Learn Implicit Logic from Physical Reasoning?\", \"abstract\": \"Despite the success of neural network models in a range of domains, it remains an open question whether they can learn to represent abstract logical operators such as negation and disjunction. We test the hypothesis that neural networks without inherent inductive biases for logical reasoning can acq...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38\", \"img_url\": null, \"x\": 0.12855055175058647, \"y\": 0.8789794326343267, \"cluster\": 1, \"weights\": {\"Influence\": 2.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.1428571428571429, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8317489147722064, \"summary\": null}, {\"id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"heading\": \"ICLR, 01 Mar 2023\", \"title\": \"SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels\", \"authors\": \"Juhwan Choi, Kyohoon Jin, Junho Lee, Sangmin Song, YoungBin Kim\", \"label\": \"SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels\", \"abstract\": \"Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft l...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fc306c2c460c261cf6390cae4b41731ebac156bd\", \"img_url\": null, \"x\": -0.4957823561791293, \"y\": 0.7369754967148404, \"cluster\": 1, \"weights\": {\"Influence\": 1.0, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.07142857142857145, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.7280821152899172, \"summary\": null}, {\"id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing\", \"authors\": \"Pengcheng He, Jianfeng Gao, Weizhu Chen\", \"label\": \"DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing\", \"abstract\": \"This paper presents a new pre-trained language model, NewModel, which improves the original DeBERTa model by replacing mask language modeling (MLM) with replaced token detection (RTD), a more sample-efficient pre-training task. Our analysis shows that vanilla embedding sharing in ELECTRA hurts train...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=fdd06e793323ee4bd943a5422bb0db5a2236d165\", \"img_url\": null, \"x\": -0.4525658048343781, \"y\": 0.8790986800756521, \"cluster\": 1, \"weights\": {\"Influence\": 9.166666666666666, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.6547619047619049, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.9322322017832498, \"summary\": null}, {\"id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Promptagator: Few-shot Dense Retrieval From 8 Examples\", \"authors\": \"Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith Hall, Ming-Wei Chang\", \"label\": \"Promptagator: Few-shot Dense Retrieval From 8 Examples\", \"abstract\": \"Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other retrieval tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, t...\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ff3408860f327dc4c7b99fd13a4b9e49a667d4fa\", \"img_url\": null, \"x\": -0.1873271677678759, \"y\": 1.0918039900178174, \"cluster\": 1, \"weights\": {\"Influence\": 2.85, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.20357142857142863, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8436666999758418, \"summary\": null}, {\"id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"heading\": \"ICLR, 22 Sep 2022\", \"title\": \"Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization\", \"authors\": \"Jing Zhou, Zongyu Lin, Yanan Zheng, Jian Li, Zhilin Yang\", \"label\": \"Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization\", \"abstract\": \"Recent work has achieved remarkable zero-shot performance with multi-task prompted pretraining, but little has been understood. For the first time, we show that training on a small number of key tasks beats using all the training tasks, while removing these key tasks substantially hurts performance....\", \"uri\": \"https://search.zeta-alpha.com/?doc_ids=ff80ed545d90479256cbf06d908baca2b41237c2\", \"img_url\": null, \"x\": -0.33672684493492844, \"y\": 1.2582069603607702, \"cluster\": 1, \"weights\": {\"Influence\": 4.666666666666667, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"type\": null, \"normalized_w\": {\"Influence\": 0.3333333333333334, \"Relevance\": 1.0, \"Popularity\": 1.0, \"Citations\": 1.0}, \"impact_score\": 0.8691380448228272, \"summary\": null}], \"links\": [{\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"strength\": 0.2804131}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.2865818666666667}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.2956531333333333}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.3003872}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.3427101666666667}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"strength\": 0.22466250000000004}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.27413006666666667}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3089365666666667}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.27189473333333336}, {\"source_id\": \"00713671e1532afff26458bba10c815db540fc82_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.28046951333333336}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"strength\": 0.21061086}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.32255480000000003}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"strength\": 0.2144391}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.2993111}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.6453035}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.3753716533333334}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.71220435}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.8265285866666667}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.2834355333333333}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.6111914333333333}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.6290779000000001}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.29544736666666666}, {\"source_id\": \"00bdc1335e7fcaa04948b9fb95d5d8e837bf7144_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.3076409133333334}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"strength\": 0.21848720000000002}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"strength\": 0.2377629}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.23739288333333336}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"strength\": 0.3809749333333334}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"strength\": 0.27912010000000004}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"strength\": 0.26963373333333335}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.2495533}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.22304640000000003}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"strength\": 0.8707007333333334}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"strength\": 0.21934286666666666}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.25677014666666664}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"strength\": 0.19407923333333335}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"strength\": 0.21709132000000003}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.2319220666666667}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.27938708}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.2415802}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.24404103333333335}, {\"source_id\": \"066f9450f5c711985540d95de2dd685434906817_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.25132473333333333}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"strength\": 0.4089447}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"strength\": 0.705003}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"strength\": 0.7751749000000001}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.3754794}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"strength\": 0.7591358666666668}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"strength\": 0.30201333333333336}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"strength\": 0.32346986666666666}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.9049889333333334}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.4272216666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"strength\": 0.2714499}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"strength\": 0.29573170000000004}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"strength\": 0.37273670000000003}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.3739945666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.7813196666666666}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.8848036666666668}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.36463648333333337}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.28018160000000003}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 0.8266668800000001}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.7940855333333334}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.36471298333333335}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.78578982}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"strength\": 0.20099749333333333}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.3384066}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.950469}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.3363203}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.7769617666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.2863432666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.34444420000000003}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.3566900666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.8642221833333334}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3648116}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.4861486333333334}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.35927186666666666}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.28050463333333336}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.38065958666666666}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.4122328}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.86695988}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.27469413333333337}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.3109520666666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.3076691166666667}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.8334992000000001}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.354978}, {\"source_id\": \"08c23d7e9010a556e408032f2be868b4b137cde1_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7978767333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"strength\": 0.37583468000000003}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.4121169}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"strength\": 0.67454105}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"strength\": 0.5042347333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.4305369}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"strength\": 0.3686508333333333}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 1.2406606333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.8551030000000001}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 0.3823570333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.38850443333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3864345}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.2722200533333333}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.4908810333333333}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3437852466666667}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3692319333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.7749865866666668}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.8705398666666667}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.7589418666666667}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.64986292}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.4403152333333334}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 1.3914338000000002}, {\"source_id\": \"0bf6bde50c746c14dc05e96bcce53de82514ab58_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.6865635999999999}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"strength\": 0.23454316666666666}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"strength\": 0.24255541333333333}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"strength\": 0.2921940333333333}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.22967951333333333}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.31129898000000006}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"strength\": 0.6653992133333334}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.24466395000000002}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.3291056}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.30181600000000003}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.8614374333333334}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.28735926666666667}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.6740020466666667}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"strength\": 0.5108172866666667}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.6297800333333334}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.9290721133333335}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3354398333333334}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.26132126666666666}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.2523174}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2976877}, {\"source_id\": \"103acce1154b891ef581ef3e5210a8987e38f231_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.3334017333333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"strength\": 0.38727743333333337}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"strength\": 0.9718415}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"strength\": 0.4274851333333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.9231028666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"strength\": 0.2790834666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"strength\": 0.21040976666666666}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"strength\": 1.3645524}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 1.1614314000000001}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.3552956666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.42554800000000004}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.26287638333333335}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"strength\": 0.2840201833333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"strength\": 0.9301861666666666}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.2658104333333333}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 1.2624547000000002}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.43886506666666664}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.9434818666666668}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.4472627666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.9981945000000001}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 1.2013839333333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.2829329}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.1416836666666668}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.2802663166666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 1.1155838}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.24292539999999999}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.36107326666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8191095833333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.9467935666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2811035666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.3524221333333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2872452}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.8725668000000002}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.22154503333333334}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.1508411666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.28663676666666665}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2654608666666667}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.8016545666666668}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.9318248666666668}, {\"source_id\": \"11651173866b06c8bbd6be77978e7d140c8c5ac4_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.9512721000000001}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"strength\": 0.3658105666666667}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.4477069000000001}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"strength\": 0.3305599666666667}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.35617963333333336}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.7755589333333334}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.8897365466666667}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.8227820333333333}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.4365932333333334}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.7075443666666668}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.4768161}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.2591503333333333}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.8166749800000002}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.7629432666666667}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.25487498000000003}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.4432954333333334}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3722225}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.39721080000000003}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.26529658}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.43578426666666664}, {\"source_id\": \"1220ce96c6db4edf48899387a173730c6868e323_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.7943675866666666}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"strength\": 0.43821640000000006}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.38926903333333335}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"strength\": 0.2898754}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"strength\": 0.2817133333333333}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"strength\": 0.20182370000000002}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"strength\": 0.9756655333333333}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"strength\": 0.9529619333333333}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.4586150666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.79260965}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.9117459666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"strength\": 0.8441454666666668}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"strength\": 0.20316548666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.34385541333333336}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.9608466333333334}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.8638723333333334}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.5653660666666668}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.2898076}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.4395547}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.9768166666666668}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.37279073333333335}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.42723283333333334}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.25768414666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.37711074666666666}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.0656344666666668}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.3877922666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.33032618333333336}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.2709903666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.2933068833333333}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.8362925333333333}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.3000157666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.35245918333333337}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.28952370000000005}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.9817856666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.8807298000000001}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3135063}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.31211203333333337}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.4120236666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.25394933333333336}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.31737798}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2991298666666667}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.9805672000000001}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.9185260666666668}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.3363053}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.31556475333333334}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.8968510000000001}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.4013444}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.27180445333333336}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.32915863333333334}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.21682711333333335}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.77831185}, {\"source_id\": \"143cfb098bdebc195b95d87a19978ba4001d1fa8_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.2716014}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.47235000000000005}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"strength\": 0.3065586866666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"strength\": 0.31699768000000006}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.9637589000000001}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.7394550666666668}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.6452556500000001}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"strength\": 0.24383213333333337}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.67759828}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.8212646533333334}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.2759302533333334}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.3891302}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.27492925}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.27352166666666666}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.8321333166666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.9461148333333333}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.4029699}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.7341935866666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.28603300000000004}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.8924136666666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.9403793666666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.34277908333333335}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3231216}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.39124433333333336}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.35023203333333336}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.20896558}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3223821333333334}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.46599580000000007}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.9311999000000001}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.7710139666666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.3246983666666667}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.6366441}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.26415913333333335}, {\"source_id\": \"154b30e600a62c531fed410d51f41d34a5d13ef6_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.8249855133333333}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"strength\": 0.31511795000000004}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.3666876666666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.34434783333333335}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.26721130000000004}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"strength\": 0.2617645333333333}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"strength\": 0.22406545}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.279693}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.7180955800000001}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.33381088333333336}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"794d9d72a13ea406df0901e9d7459463efa086f3_0\", \"strength\": 0.22312263333333335}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 1.0672774333333335}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.6573394666666668}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.8422866666666666}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3647719833333334}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.4156125133333333}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.7279851333333334}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.35124468333333336}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"strength\": 0.22909210000000002}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.27833091666666665}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"strength\": 0.2895622666666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.375709}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"strength\": 0.9464204}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3904171666666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3304397666666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 1.0045487}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.3513076}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.28393963333333333}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.35917183333333336}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.287107}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.2894727666666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.3246046}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.8508391000000002}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.37200880000000003}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8143201166666667}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.34062612000000003}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.29133943333333334}, {\"source_id\": \"158c3e9b9937ad25aa9ef65b42d655cafe9754b5_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.24211815000000003}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"strength\": 0.3130811}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"strength\": 0.31195513333333336}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"strength\": 0.8207769666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.32859858333333336}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.3105878666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"strength\": 0.6934955}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.66564325}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 0.7907605666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3549917866666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.67735593}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.3557637533333333}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.7205406666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3369078833333334}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.23934496666666666}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.2696478666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.29402313333333335}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.3036728666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.311242}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.7189556333333333}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.7120178666666667}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.3873575}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.30350353333333335}, {\"source_id\": \"162d51317b72d69f5e99da4a6cc53cbd7f9b5e86_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.24996490000000002}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"strength\": 0.30500653333333333}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"strength\": 0.36957906666666673}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"strength\": 0.3775416833333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"strength\": 0.3107987666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.4477396666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.39834683333333337}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.7612481333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"strength\": 0.6730942}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.45589593333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.8431635333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.43069700000000005}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 1.1079673333333333}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.3370966}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.9324110333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"strength\": 0.2470908866666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.859612}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.2658283333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.38460345}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.0534965}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.8429727333333333}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.2353580666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.8434964}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.30370320000000006}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.7706626000000001}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 1.0000932}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.8361847}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3117337666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.37419773333333334}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.3063531}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"strength\": 0.25492373333333335}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.3145187666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8841971666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.9734439666666668}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.28938633333333336}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.3294107666666667}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.35649923333333333}, {\"source_id\": \"199a854fceaf26a4a1deae9b0c12c71276f5da00_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.8413083666666668}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.3815559333333334}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"strength\": 0.2576470666666667}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.30853440000000004}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3415510666666667}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.34037971333333333}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.6949756}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.26824913333333333}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.2465196}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3082066}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.32736671333333334}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.2662062333333333}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.26765916666666667}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.34447176666666673}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2854727}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.7425010000000001}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.6030236666666666}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2572224666666667}, {\"source_id\": \"1c4ca3277c2f4b3aab7b9c44937a91391cdf807b_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.5964367666666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.27004285333333333}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.305856}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.30570003333333334}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.2989422866666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.2667894333333333}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.5923782866666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.28284596666666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.27325866666666665}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.2651718133333334}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.26487003333333337}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.2732390666666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.26459773333333336}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.68736388}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2709215}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.2642042}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.2834064}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.5975225666666667}, {\"source_id\": \"1d26730c325a12eead65d64552a91658cce12baf_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2484182666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.39637653333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.71956198}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"strength\": 0.299479}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.36387640000000004}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.7867636333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3340599}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"strength\": 0.8494803333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.3646456666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.2813411666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"strength\": 0.27851163333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.6747110666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.3606769666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.35444596666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3366242466666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.7722736000000001}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.3202467866666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.2997831666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3000989666666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.27895373333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.30207090000000003}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.23140950000000002}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.29686203333333333}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.3056799333333334}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3490307}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.9637628500000002}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3267695866666667}, {\"source_id\": \"1e5cd6b33c003196129a1f247932ffbb7896feb5_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.36286700000000005}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"strength\": 0.7218474333333333}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"strength\": 0.6129864666666667}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.8207943}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.7690448000000001}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.2942306333333333}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"strength\": 0.18693199000000002}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.3416829333333334}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.33060221333333334}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.31202460000000004}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.2480662666666667}, {\"source_id\": \"1ed1617d66761681a93bdbe7b1f53aef7d21091f_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.36142331333333333}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"strength\": 0.6543009666666667}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.31164573333333334}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"strength\": 0.32433613333333333}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 1.1122676666666667}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.7604531533333334}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3075793333333333}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.6881352466666667}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"strength\": 0.32930950000000003}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.29161888}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.33482690000000004}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"d98e77771649b72cb8f3aedc3e437177e56f3b5c_0\", \"strength\": 0.18768727666666668}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.3603324133333333}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.7665179000000001}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.6342535333333335}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.6796294666666667}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.33919203333333336}, {\"source_id\": \"2391c4ff915a6cb6af2a9c779aa9fd050d4b0a2e_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7005844166666667}, {\"source_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.2033297666666667}, {\"source_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"target_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"strength\": 0.20489528666666668}, {\"source_id\": \"253ec8cde3e27fdba1c9ad3012d1fc3e9603b231_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.21488170000000004}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"strength\": 0.33424471666666666}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.9917603}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.8135551333333334}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.3965130666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"strength\": 0.9948995}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.5628316666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.8480080000000001}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.8305165666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.43525536666666664}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.3975671333333334}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 1.6473496}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.3325074666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.3281056333333334}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.3002611666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.34208703333333335}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 1.5420622666666668}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.35508738333333334}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.8092955666666668}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8450162333333334}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.31836263333333337}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.9338433666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.23068163333333336}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.20759043333333335}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2771716666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.8034655666666668}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7525579833333333}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.9700024666666667}, {\"source_id\": \"2a4e4028b8c23d3e71b07833c38d21059964d08a_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 1.5707874666666668}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"strength\": 0.30895750000000005}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.3049391166666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.2968907333333334}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3147209666666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.29837443333333336}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.3036023666666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3262672166666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.3124576}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.6890335166666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.36582593333333335}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.29812896666666666}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.2718689}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3136200666666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.3390914166666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3714347333333334}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.3025294666666667}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.31142770000000003}, {\"source_id\": \"2aa6ea5b1b5a3b3ac11ad23d76b403ef9644fac3_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.6914612}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"strength\": 0.3078115}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"strength\": 0.6556760500000001}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"strength\": 0.1888682}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.6509461833333334}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3447518666666667}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.3579585533333334}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.3217817333333334}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.30250546666666667}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3083372666666667}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.22048698333333336}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.3111205333333334}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.6368155}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.34752848333333336}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.30325358}, {\"source_id\": \"2d572c3562f66ea11f12de57a5ed1f961a6e4b68_0\", \"target_id\": \"f397b5eed0598c8f0c156205a8fc24d52b6035db_0\", \"strength\": 0.15180123333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"strength\": 0.5679934666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"strength\": 0.25096303333333336}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"strength\": 0.41038152000000006}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.42142913333333337}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"strength\": 0.2889758}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"strength\": 0.3164568833333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"strength\": 0.9662214666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.3852568}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.2933749}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.3224785333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.36610458333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 1.326726766666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.9576541000000001}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"strength\": 0.20017553333333335}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 1.0280855333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.3313851166666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.9590115666666668}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.27919225000000003}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.2712777333333333}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.35767288333333336}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 1.019276066666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 1.2566921}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"strength\": 0.41141146666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.3867179866666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.32569750000000003}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.29205993333333335}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 1.2751109666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.3230905}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.349403}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.0767657333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3915390666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.33496936666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"strength\": 0.18160909}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3712299866666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.3187108866666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"strength\": 0.2347901666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.3365338133333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.28149473333333336}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.27492475}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.3481677}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.9310313666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.8236667333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.40928955000000006}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.25009973333333335}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.33515485}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.36736660000000004}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.3623697166666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.4222268666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.24108536666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.2747183}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.9956817666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.29885903333333336}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.34922620000000004}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.33073873333333337}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.4213888666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.27258873333333333}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.41678790000000004}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.4506923000000001}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.29505272000000005}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.4860763}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.3155889333333334}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.32668796666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.34537735}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.9179945}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.34307312}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.3027143666666667}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.27530494666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.3303091}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.28140423333333336}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.1312027000000002}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.40830003333333337}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2737901}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.46823990000000004}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.8709301}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.42596951666666666}, {\"source_id\": \"2db7fac67c690d80d8b68567e6032edd31a04661_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.8826097666666668}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3960679666666667}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.3579981666666667}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.35537623333333335}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.3829129666666667}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.8934315000000002}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.9699599}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.2613329000000002}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.8496877333333334}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.41439590000000004}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.5005954}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.31151243333333334}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.26942336666666666}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.9563901000000001}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.8905202666666667}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7939580666666667}, {\"source_id\": \"30464dcfbcc9361f9567cb6180a024fde3f9f7c0_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.7522890666666667}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"strength\": 0.5888878500000001}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.28854815000000006}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.23830316666666668}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.23583616666666668}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.34953323333333336}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.2689492666666667}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.26392913333333334}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.2801947}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.6502773333333334}, {\"source_id\": \"312dd8836aeed42afc7cd56ba3f844401b4a7aac_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.23517936666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"strength\": 0.5887543666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"strength\": 0.6937359333333335}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.3811227666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.32732526666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.7984277166666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.29013086666666665}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.2692309333333333}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3500800333333334}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.32828013333333333}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.36042843333333335}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.35442580000000007}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.36650546666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3762815666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.2629205666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.3371119666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.33749923333333337}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3274768}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.6864984533333334}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.8207970466666668}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.7982328000000001}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.3155446666666667}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8141347833333334}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.31177378333333333}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.29262533333333335}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7077919166666666}, {\"source_id\": \"3339fc69d56af1c26a861cd289435c3b70a12b9a_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.36211761333333337}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.24542523333333338}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.22092750000000003}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.21907961666666667}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.2378972}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.22403453333333334}, {\"source_id\": \"347646a7f503e63e832fbd65317a9bb94b16a591_0\", \"target_id\": \"f397b5eed0598c8f0c156205a8fc24d52b6035db_0\", \"strength\": 0.14871671}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"strength\": 0.21797419999999998}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"strength\": 0.21944863333333336}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.29907263333333334}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"strength\": 0.18927177333333334}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.2858393}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.6042587166666666}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.2749860333333334}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.2913963333333333}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.7181376333333334}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.33578436666666667}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.32220070000000006}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3459623666666667}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.28317013333333335}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.21752126666666666}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.26919973333333336}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.25356876666666667}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.30090253333333333}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.5968668500000001}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.29388263333333337}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.30876390000000004}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.27225245000000003}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.5758925}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.5689069866666667}, {\"source_id\": \"34cc48cbd844dbafbe35faeb82129d13e66095bf_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.29767018666666667}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.23230802000000003}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.3795059666666667}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 0.23088463333333334}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.21326333333333333}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.21474866666666667}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.22247803333333332}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.219022}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.2875934866666667}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.39559510000000003}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.22187516666666668}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.21692036666666667}, {\"source_id\": \"3bac3a260f475e4af46396b434902c7a31a79d49_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.3457467}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"strength\": 0.2532184866666667}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.21348185333333336}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.21448136666666667}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.2944761666666667}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.22079983333333333}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.22997538333333334}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.23481553333333335}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.2435861666666667}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.2636172}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.21551676666666666}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.20935774333333335}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.6905808}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.25111086666666665}, {\"source_id\": \"40aa20d82f89b9d916bafcae6e7345462e2d8d35_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.22253606666666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.3012010666666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.26397255000000003}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.27279063333333337}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"strength\": 0.2795201666666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.9041046333333335}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.27250683333333336}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.6197309500000001}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.3022013333333333}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.5992344333333334}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.26393906666666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.7196217366666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.27368998333333333}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.23286811666666665}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.8521145333333333}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.6620555666666668}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.28904195000000005}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.26412813333333335}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.2626346666666667}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.7917387666666668}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.29622546666666666}, {\"source_id\": \"416279f655ea1098f0d9994426ae7fea3e89535c_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7176397333333334}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.26510882}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.2534520333333334}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.28170813333333333}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.3159452}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.24637043333333336}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.26817288666666667}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.26266306666666667}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.3241869866666667}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.2415513666666667}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.7051805533333334}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.30673312}, {\"source_id\": \"4383881f88fa683debadcf3027460fff1f2858a8_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.24495663333333337}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"strength\": 0.34051445}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"strength\": 0.7259171166666667}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.36728740000000004}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.38645460000000004}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.3652694333333334}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"strength\": 0.3193403}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.6349650666666666}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.6743755866666667}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.37562355000000003}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.663508}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.33988263333333335}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.7137176000000001}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.31912693333333336}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.7394818133333334}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20353208}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.34392578}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.24608833333333333}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.33289118333333334}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.27828600000000003}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.6966887333333334}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.23771176666666669}, {\"source_id\": \"4615365bba1bda4cd045b864a6cc186a6fe4e4fb_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3952427333333333}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"strength\": 0.7572236999999999}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.4115034666666667}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"strength\": 0.34592598}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"strength\": 0.21123371000000002}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.8925962133333334}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.9295353333333334}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 1.0530451}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.35000060000000005}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.44321260000000007}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.8392125666666668}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 1.1630474}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.2352641}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.67279825}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.9011048}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.8754599333333333}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.25873825}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7252557866666667}, {\"source_id\": \"49408caf6974b9f88c0ff22bdc7bb0f031b44012_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.8952720333333334}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"strength\": 0.23553795}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"794d9d72a13ea406df0901e9d7459463efa086f3_0\", \"strength\": 0.44717875333333335}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.2544731666666667}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.23431576666666667}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"strength\": 0.2686808666666667}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.33107938000000003}, {\"source_id\": \"4b064bf120f526e0a47df49f891a0e09958f8b40_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.2539243}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.32282126666666666}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"strength\": 0.3308305666666667}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.5629424000000001}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3348421666666667}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.3176420833333334}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.29921473333333337}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.22724380000000002}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.3334444333333334}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.2658974666666667}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.2121401}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"d98e77771649b72cb8f3aedc3e437177e56f3b5c_0\", \"strength\": 0.19274790000000003}, {\"source_id\": \"4f1eb4a8421681a49858b0590dafe1469e94ec7f_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3619348}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.2181028}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"strength\": 0.21398383333333335}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.2717917666666667}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.49075803333333334}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.21152471000000003}, {\"source_id\": \"56071e7fc5122991ecd78ce573ac00cf3e5067ef_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.2115487166666667}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.20772483333333336}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.31207565333333337}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.20749458333333334}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.6738501666666668}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.20756316000000002}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"strength\": 0.2047961666666667}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"strength\": 0.21554150000000002}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.4985394000000001}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.23442203333333336}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"strength\": 0.20098241333333336}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.7355651333333334}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.21635142000000004}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.25680850000000005}, {\"source_id\": \"569dbc3270ede6061aa6eec6c9b43bc2a646c43d_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.29394841666666666}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"strength\": 0.9332212000000001}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"strength\": 0.37607488}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.7309090133333334}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.7638365}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.31440434666666667}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.7497779166666667}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.7970210166666667}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.3019515466666667}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.37712500000000004}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.9758068666666666}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.7463515166666668}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.8305816666666668}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3662603666666667}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.28198113333333336}, {\"source_id\": \"56baf9e289f10825bce61e0cc10783b2abb58bde_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 1.2548086333333335}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"strength\": 0.6474681133333334}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.3058712}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.2769173166666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.27593950000000006}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.34925888000000005}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"strength\": 0.2898527}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3718227666666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.7192772333333334}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.34812970000000004}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.30587793333333335}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.34584010000000004}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.3040704}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.7038886200000001}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.30809105}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.2304074}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.31523803333333333}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.22977768000000004}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.29422623333333336}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.7043253666666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.34484193333333335}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.6560926300000001}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.30847830000000004}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.3006054166666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.7570114133333334}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3782124666666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2722716}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.6332564133333334}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.2648707666666667}, {\"source_id\": \"5973f5bc9a87c1e9f3e95e70f30b6497b95a673a_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.9481029333333335}, {\"source_id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.18486566666666668}, {\"source_id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.1912526}, {\"source_id\": \"5aa073b34e5455c3161e8e73b80b58eabae3a9ac_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.20944024333333336}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.2651301833333334}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.29800340000000003}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.2938853666666667}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.25902030000000004}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.25978703333333336}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.3023358}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.28243110000000005}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.31000473333333334}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.29498413333333334}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.28047916666666667}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.2612487666666667}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.2753509666666667}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.26814113333333334}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.73060895}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.8765862666666666}, {\"source_id\": \"5e6744097d023772f4e066a66f8496bcfc06e15d_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.75886125}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.46231276666666665}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"strength\": 0.3572315666666667}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.34034283333333337}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.37043800000000005}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.36385948333333334}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.2763145}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.3232311}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.41242121333333337}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.7199861666666667}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.7400694333333333}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.9241441333333333}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.74111712}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.7109965}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.29795783333333337}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.71740775}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.20063873333333335}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.2734934666666667}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.4069478666666667}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.25866573333333337}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.34488688}, {\"source_id\": \"6a9dd394987411ced6f4d53c6e4c71887d5c52ea_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 1.3377769000000002}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"strength\": 0.35138232}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.8176358666666668}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"strength\": 0.2885959666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.7768252666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.3070976666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.8463698833333334}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.9881056333333333}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"strength\": 0.7469642666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 1.0673682666666668}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.3958295333333333}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.5478765000000001}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.36369320000000005}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.36238108333333335}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3995617166666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.29619278}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.2377523}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.38751126666666674}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.42210250000000005}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.3390595}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.3526593533333333}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.3139734666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.3574466333333334}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.41007525000000006}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3203644666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.6911266166666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.3957842666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.29216583333333335}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.3469168}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.7461074333333333}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.41018610000000005}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.76289815}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.3251215333333334}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.27036886666666665}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.9470424533333334}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.35374750000000005}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.3785098333333333}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7893406666666667}, {\"source_id\": \"6ffbbe187cbcc22c7b7f1254a0396459a35e7d43_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.3641280333333334}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"strength\": 0.34606585333333334}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.7215879466666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"strength\": 0.2893008166666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.7660513666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.34352166666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"strength\": 0.7023105000000001}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.8459821666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.31848650000000006}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3504796666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.73717792}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.6484925500000001}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.6966407666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 1.497884}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.29993620000000004}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2613749666666667}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.3033641}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.7891022000000001}, {\"source_id\": \"738a5dc4ffd40969e1eebee88c95fb48e9013ccf_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.7987802166666667}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"strength\": 0.9685862666666667}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3230750666666667}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.9469264333333334}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.8208298533333334}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2777093666666667}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.7451713333333334}, {\"source_id\": \"76914ab5905f7896de9ea76722ee01e78f0f40ef_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.27271096666666667}, {\"source_id\": \"794d9d72a13ea406df0901e9d7459463efa086f3_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.2117892}, {\"source_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"target_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"strength\": 0.4260855333333334}, {\"source_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.22119173333333333}, {\"source_id\": \"7b874f6ed208bd4d96c8067585e1baada269ed99_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.3526845}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"strength\": 0.4494675333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.7973854500000002}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.8828346}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.3741068666666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.83623508}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.23884103333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.34756281666666666}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.9840610666666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3491875}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.36067953333333336}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.30501903333333336}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.3567747666666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.39354763333333337}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.9287508}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.38088735}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.6779850333333333}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.7910726666666668}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.2698016}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.43938893333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.9273946666666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.7794600666666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.37030573333333333}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.25662593333333333}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.2917483333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.26745963333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8417020166666667}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.38668223333333335}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.8883178333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.3473721333333334}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.31667283333333335}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.36964093333333337}, {\"source_id\": \"7b98935360946bb508faa85c8a3a1af1da8bb596_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 1.1108957333333334}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.26739825}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3002202666666667}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.28968723333333335}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.7024703333333334}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.27007653333333337}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.2749552333333333}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.6935224333333334}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.28536575333333336}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.6307593}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.2626236}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2814783466666667}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.3038804666666667}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.2645091666666667}, {\"source_id\": \"7ebd240a5100239de5f1143348bb6a02e57b4a3e_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.2998881666666667}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"strength\": 0.6265526}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"strength\": 0.294178}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"strength\": 0.8289299666666667}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.6715219800000001}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.30851672}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.3323158666666667}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.3137031666666667}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.2973611666666667}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"strength\": 0.9241656000000001}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.7807649833333334}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.37606800000000007}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.26046983333333334}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.33668668}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.9153055333333333}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.7134708333333334}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.401388}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.33104408333333335}, {\"source_id\": \"800604d777a5e522dd1b1fd27bfdba1457e06121_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.36846350000000005}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.8407150666666667}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.8414004}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.9382921333333334}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3249367666666667}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"strength\": 0.23142903333333334}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.7195051666666668}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 1.3222075333333334}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3871664166666667}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.9551041333333333}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8000318666666666}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.6696830166666667}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.7623313}, {\"source_id\": \"8040d9faa4476c89d1d8530fc3629609f670c413_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.9372573666666666}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.25756670000000004}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.2722086}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.2707278}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.2234474166666667}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.27718403333333336}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.25847692}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.25724993333333335}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2650402666666667}, {\"source_id\": \"814afdbddae5a09ae806fd668ee77e35184255f8_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.3260188666666667}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.3126155666666667}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"strength\": 0.3229346}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.28235020000000005}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.26747193333333336}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.26622983333333333}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.29320063333333335}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.26816442}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.29212}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.33028473333333336}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.2863042}, {\"source_id\": \"8172f5bcb615707ec5055beab47b4dd30e52d27b_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.2905998}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3285531666666667}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"strength\": 0.7818135133333334}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 1.0404643333333334}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.29283430000000005}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.35021743333333333}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.8729512133333335}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.35215060000000004}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.7925766000000001}, {\"source_id\": \"8415bcaf2b7284f0e357000e48ffb5fee6dd38b5_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.42405268333333335}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"strength\": 0.3142524466666667}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.73840778}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.33745840000000005}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.8468427333333334}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.5280501333333334}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.2760883666666667}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.2789038833333334}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3221394866666667}, {\"source_id\": \"842a83bd2d69d11016fcfe6c04050f8285afebcb_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3038610833333334}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"strength\": 0.81697138}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.37860050000000006}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.9426082333333334}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"strength\": 0.26284078}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.28226680000000004}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.6993934466666667}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.31991483333333337}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.2729559833333334}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.8312635666666668}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8905291666666667}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.2777053}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.31649508000000004}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.27412638333333333}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8846998666666668}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.28205253333333336}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.9084925333333334}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2824994333333334}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2461822}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7866711}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.2221001166666667}, {\"source_id\": \"8700f035892152b56dc9fc03c132cfa2deb7f85f_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.25595043333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"strength\": 0.3570818333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"strength\": 0.4108702666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"strength\": 0.36672016666666674}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.8855418533333335}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.7713574166666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.9083766000000001}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.47240886666666665}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"strength\": 0.22786308333333335}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3378179666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.24860776666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.2802552666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.2924043}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.36521690000000007}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.3027545166666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.35774465000000005}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8099555}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.30231585333333333}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.33123003333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.3501286666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.9910034333333333}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2775711}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.7367048333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.4436304333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.7154865866666666}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.43905669999999997}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.3012652}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.3044803}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.8287389533333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.35721403333333335}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.8575411333333334}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7871469466666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.8978447666666667}, {\"source_id\": \"89a27fe3e20a404707a6e722e7ac75e5a41c936d_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.2588013333333333}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.35161661666666666}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.3433879666666667}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"strength\": 0.3473929666666667}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.32279820000000004}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.3197349}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.6548889166666667}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3497577333333333}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.2781612133333333}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2681729}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.7486623633333334}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.4207542}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.6972986866666666}, {\"source_id\": \"8d60ddb46505a6c7cf1218d521823cb0c5c4cd66_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.33801445}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.4078881833333334}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.31133020000000006}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.8733507}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.4054973866666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.3025909166666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.24397756666666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.39569983333333336}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.36292440000000004}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.35762543333333335}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.3882802666666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.36087748333333336}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3549332666666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.25568103333333336}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2745843666666667}, {\"source_id\": \"8e3711b88bf51197682b0faf1dda62e1e6496eb6_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.3927934}, {\"source_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"target_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"strength\": 0.27942303333333335}, {\"source_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.6249250033333333}, {\"source_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.219493}, {\"source_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.31931376666666667}, {\"source_id\": \"8f1a724b5f7673c5cea51e10729a17139409b141_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.29747345000000003}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"strength\": 0.2943061666666667}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.31347973333333334}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"strength\": 0.7561868533333334}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20303062333333335}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.2554735666666667}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.26398188333333333}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.2882036333333333}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.38337350000000003}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.37675430000000004}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.28828308}, {\"source_id\": \"910ef8ca812f569efa081784e20837687fa5412f_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.7774857333333334}, {\"source_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.20277261000000002}, {\"source_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.22212560000000003}, {\"source_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.20243759}, {\"source_id\": \"9191ed837c5f5e96fce1b9ab1a856e54ad27cf48_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2340761}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"strength\": 0.28513683333333334}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.3226194666666667}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.33766976666666665}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.7050219333333334}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.2921321866666667}, {\"source_id\": \"937cb172bd8fb345dd500451e9090a1d1c742a9f_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.29706273333333333}, {\"source_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"target_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"strength\": 0.25586193333333335}, {\"source_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 1.0521373}, {\"source_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.7210553466666667}, {\"source_id\": \"957c50b0c0f2c3c1fb68d024cd21c56deb2cbe55_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.26112958333333336}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"strength\": 0.3353961333333334}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.2548400333333333}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.7656075}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.8165378133333334}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8151961833333334}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.32649263333333334}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.25128883333333335}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.2502813666666667}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.8130181133333334}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2667999}, {\"source_id\": \"95b15e6145029721347f9996f2773d1b77d6bb66_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3655002666666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 1.3907959333333335}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"strength\": 0.3597239166666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.3891941833333334}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.3028668666666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"strength\": 0.32406293333333336}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"strength\": 0.38666903333333336}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.3173306}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 1.1587083666666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.35310393333333334}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.3812028333333334}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.39066663333333335}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.32338723333333336}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.24149820000000002}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 1.0849330666666668}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.3012690333333333}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.32345273333333335}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.26229616666666666}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.35264122000000003}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.24391966666666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.2891480666666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2949161}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.49079906666666673}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.3450905866666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.39779210000000004}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.25494063333333333}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.20608690000000002}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.2607633466666667}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.27973882}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.5444787}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.36546628333333336}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2679878}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.8350286}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7257207133333334}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.39810790000000007}, {\"source_id\": \"96125b9cbf068a1f19afb3437a569c6718491419_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 1.5841274666666667}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.22469752}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"strength\": 0.4855944333333333}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.5854218833333333}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 1.0239715}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8062438999999999}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 1.0082626000000001}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.25026766666666667}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.5711445666666667}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2481715}, {\"source_id\": \"975b10e85ce2b8ad21d06c14449fe36492531eb6_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.6013866333333333}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"strength\": 0.3980617666666667}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.31999093333333334}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.33519605}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.34981308}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.29736895333333335}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.3372988333333334}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.3131973333333333}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.28906233333333337}, {\"source_id\": \"978b9bb55b55d26ab62267a885cb369761805000_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.3364507}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 1.0972775666666665}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.26894433333333334}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.24080566666666667}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.9340668666666667}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8806099533333334}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.3064752666666667}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.32265368}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2887373866666667}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.8641588}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.49216109999999996}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2569123833333334}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.1461755333333334}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.28028816666666667}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2642324833333334}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.87931402}, {\"source_id\": \"9a6e1b270d07b878a00eb571c87ce87cd859c93c_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.9548144333333334}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"strength\": 0.7415688}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"strength\": 0.33648552000000004}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.22974612}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.7055142966666668}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.2855603666666667}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.3469904833333333}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.7138518333333335}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.33639993333333335}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.24176443333333336}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.8331431}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.8652186666666667}, {\"source_id\": \"9c29e03740cac092695afb43a5a70cf895bbb43a_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7128400133333335}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.4069100666666667}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 1.4072143333333336}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.36936282000000004}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.2906621}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.37634696666666667}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.8158838666666668}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.8648593666666666}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.3894173166666667}, {\"source_id\": \"9c48d6dea10e415f0f9ba5e11d8e77bca1a6f5b1_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.32669533333333334}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"strength\": 0.32583433333333334}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"strength\": 0.2116099166666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.2800351466666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.31980043333333336}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.3468841666666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.30803278666666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.3032291}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.6922752366666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.2665996666666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.40109782000000005}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.41064673333333335}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.7438780666666667}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.25356836666666666}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.33721453333333334}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.6057112800000001}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.27073168333333336}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.32662768000000003}, {\"source_id\": \"9ecc9f31cf39e80f5a7bcf267fd954fd13cb64f1_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.2646076666666667}, {\"source_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"target_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"strength\": 0.20687464333333336}, {\"source_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.21897940000000002}, {\"source_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.22316766666666668}, {\"source_id\": \"9f025823831bf6a7883f12641ae4ab3fbe3120d7_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.20032643333333333}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"strength\": 0.23354693333333337}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"strength\": 0.25261036666666664}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.2902287666666667}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.20531175000000002}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.22869952}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20736034333333336}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.2764840666666667}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.48025465}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.30487470000000005}, {\"source_id\": \"9fae64a3d5c141fc9d5af324fa7fd4ae17c1930d_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.6227257133333334}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"strength\": 0.21633876666666668}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.21131721333333336}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.22710373333333334}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.20927423333333334}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.20233406666666667}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.21535893333333336}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.20093223333333335}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.23027706666666667}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.22356840000000003}, {\"source_id\": \"a15aa7f865c5a7ff51361bf3e04812165432fab5_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.22081553333333334}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.26276326666666666}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.29879293333333334}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.46708786666666674}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.22835626666666667}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.3734177666666667}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.28316730000000007}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"d98e77771649b72cb8f3aedc3e437177e56f3b5c_0\", \"strength\": 0.19934233333333334}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.38486145}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.3366378666666667}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3561687666666667}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2822775}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.2442117666666667}, {\"source_id\": \"a78d1be317d81da5a4020349ba536e9181e1037a_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.38468943333333333}, {\"source_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.30682413333333336}, {\"source_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.3628925666666667}, {\"source_id\": \"a81bdd7b9216e082bde00e72490394930ab652a8_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.3137955}, {\"source_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.5583466866666666}, {\"source_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.2655212}, {\"source_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.20044161333333335}, {\"source_id\": \"a8b93e4304e78f871888067da2b86627e6d9d79d_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.20120674000000002}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"strength\": 0.5770569833333334}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"strength\": 0.23780573333333332}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"strength\": 0.25186943333333334}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.42404816666666667}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.23522094666666668}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20209263333333333}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.2765340166666667}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.21568610000000005}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.21846264999999998}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.22389803333333336}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.21392911333333336}, {\"source_id\": \"a9c04f1bd391a18bc1a275e91a0d4a73e570aec0_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.25300283333333334}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.26860930000000005}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.2772813}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.22816193333333337}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.27436140000000003}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.26655700000000004}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.28721878}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.2627184666666667}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.2936824333333334}, {\"source_id\": \"aa7c8e8d0e77d06be04cecb954275a993bfc0616_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.29849431333333337}, {\"source_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.21676081333333336}, {\"source_id\": \"ac9245791ee906fa4171932daaf6597a52c0fa98_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.20388243333333333}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.24832662}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.2514134466666667}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"strength\": 0.5301016466666667}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2553057}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.24393033333333336}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.26355723333333336}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.23238660000000003}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.2628114}, {\"source_id\": \"ace20966de455608877702bdba6ddfcf3d4c5248_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.2760547666666667}, {\"source_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.29536653333333335}, {\"source_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.34508633333333333}, {\"source_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.36144625333333336}, {\"source_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.27945446666666673}, {\"source_id\": \"ae051745891477c4d524fadadded72dc67e244e4_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.8120848333333334}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"strength\": 0.29650630000000006}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.5759790333333333}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.5638703}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20622472}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.24205485000000002}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.2821188866666667}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.29140126666666666}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.3096203}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.2801368666666667}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2989582333333334}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.8735554333333334}, {\"source_id\": \"b1093942944eb13269b1e4b7dbd71b931206ac32_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.52594255}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"strength\": 0.30458188333333336}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.23881739999999999}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.6585254}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.29020103333333336}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.3585696166666667}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.3652888333333334}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.24725288333333337}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.6701888033333334}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.33351633333333336}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.3129851666666667}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.2684152}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.25863996666666667}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2660015866666667}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2644263333333334}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.67550255}, {\"source_id\": \"b18d2118bbae2664f100d7f2764db171c3e7ddbe_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.9899592666666668}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"strength\": 0.2826678}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.31507480000000004}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"strength\": 0.23855393333333336}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.23953213333333334}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.25360493333333334}, {\"source_id\": \"b381e35373a8a5f711b8c30561f0955434490182_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.2792947666666667}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"strength\": 0.7463073500000001}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"strength\": 0.27901675000000004}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.42989013333333337}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.31854355}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"strength\": 0.2838856}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.26768553333333334}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.2531621333333333}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.30899353333333335}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.9003942333333333}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.24882379999999998}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.29649030000000004}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2662155666666667}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 1.2966882000000002}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3424272666666667}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.24205183333333335}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2741677333333334}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.3601556666666667}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.7096113666666668}, {\"source_id\": \"b79aa79713c798b31118df4df4e474e744adf3b9_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 1.2961205}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.31208440000000004}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.2729398666666667}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"strength\": 0.37817470000000003}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.25870753333333335}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.8376398833333334}, {\"source_id\": \"b82544e7b6f3d7f929005770613bc1d429ba6b26_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.3218123666666667}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"strength\": 0.7715837000000001}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.3372529333333334}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.3418237333333334}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.3373528}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.67283578}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.7843401333333334}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3808210666666667}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"f397b5eed0598c8f0c156205a8fc24d52b6035db_0\", \"strength\": 0.15472934666666668}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.22454286666666667}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7587227333333334}, {\"source_id\": \"b89d1b51f29771b7df36c5aa06d788ef19142453_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.6836816333333333}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.23510936666666668}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"strength\": 0.26825350000000003}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"strength\": 0.24013600000000004}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.23531041333333336}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.7083637833333334}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.24398673333333337}, {\"source_id\": \"b9adac8b86a46ce53d30f935c93d94efe8240723_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.26191203333333335}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"strength\": 0.2635557333333334}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.7653658666666667}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.8980024666666666}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.3982822166666667}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3950383333333333}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.6212870500000001}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.6613889166666667}, {\"source_id\": \"bc3f48deb9335657a0435bf09275fe89d55b5beb_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.4147598533333333}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"strength\": 0.32028798333333336}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.3550452}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.3397234}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.3820657333333334}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.2520961}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.27481863333333334}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.3029617}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.8473191333333334}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.3789532666666667}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.7287270333333333}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.26605446666666666}, {\"source_id\": \"bcc767207b1287eb294e9a467c460545751f87f6_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 1.0605803666666669}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"strength\": 0.2731690666666667}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.5822705}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.6801839866666667}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.6131451666666667}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"strength\": 0.29603693333333336}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.26179453333333336}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.5904747800000001}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.7238964666666667}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2801633}, {\"source_id\": \"bd92f5a11981955438485317e8838ce905ae9fb4_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3016394666666667}, {\"source_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"target_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"strength\": 0.23060276666666668}, {\"source_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.23073556666666667}, {\"source_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.27308106666666665}, {\"source_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.23351740000000004}, {\"source_id\": \"c3233f783e071d58d17669ed4b17040c83622fbc_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.24115125000000004}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"strength\": 0.8357357666666667}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.8024436500000001}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"strength\": 0.295061}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.2965167}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.36467310000000003}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.8178237166666666}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.26116656666666666}, {\"source_id\": \"c35345142c29c10dd877b90f067671ad2dc9081c_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.7986163333333334}, {\"source_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"target_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"strength\": 0.7665612666666667}, {\"source_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.3114701833333334}, {\"source_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.9285478666666667}, {\"source_id\": \"c4dbef493cd078a0f00a04077ba6d9f3ae9b47e2_0\", \"target_id\": \"f099d4bb4de0bbdf54549c6f706a5b38a0e19dd0_0\", \"strength\": 0.8864596333333334}, {\"source_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.2129373566666667}, {\"source_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.20346255000000002}, {\"source_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.22479206666666668}, {\"source_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.5147823466666668}, {\"source_id\": \"c5c408ff21f5280879d55665f2fc11a13b53fa95_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.26986713333333334}, {\"source_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.2221663666666667}, {\"source_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.23861583333333336}, {\"source_id\": \"c81c3af55037853a58cb4d1020c7e1ed37e702e0_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.31156233333333333}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"strength\": 0.29850863333333333}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3949882}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.34079063333333337}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.2588076}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.9769011000000001}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.21875086666666668}, {\"source_id\": \"c9bcbab395245c32bcfb60369320486a3d89ef98_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.38531952}, {\"source_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"target_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"strength\": 0.31093543333333334}, {\"source_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.27221043333333333}, {\"source_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.7020582533333334}, {\"source_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2557667}, {\"source_id\": \"cafcd1ec66445ef30a74de00ab878462088c0e5b_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.7106189333333334}, {\"source_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.24969873333333337}, {\"source_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"target_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"strength\": 0.7811781}, {\"source_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.23831353333333335}, {\"source_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.25251648}, {\"source_id\": \"cb874b3ac26b4b643bd11d102ad4a64f13b494dd_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.21276066666666668}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.31325573333333334}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.34159858666666665}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.2993615333333333}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.6165010466666667}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.33278646666666667}, {\"source_id\": \"cba38b30b10b856818a1b2c96e147c90b526500e_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.2744803}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"strength\": 0.20982559333333337}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"strength\": 0.27702588333333333}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.85872645}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.28803486666666667}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.5369685000000001}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.30832791666666665}, {\"source_id\": \"cd07e6460b349dbaae2d346eea1f5c1ce90e9347_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.6396388833333333}, {\"source_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"target_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"strength\": 0.31653850000000006}, {\"source_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.8527886}, {\"source_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.7386637666666667}, {\"source_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.4961626333333334}, {\"source_id\": \"cde088dabad3c7da68d013f4869713cd792ba962_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2600232666666667}, {\"source_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"target_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"strength\": 0.39965330000000004}, {\"source_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.2930362666666667}, {\"source_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.23049321333333336}, {\"source_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.20158255333333336}, {\"source_id\": \"d01647148dc09c77c31fbf9c08f181710ef2e94a_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.28377653333333336}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"strength\": 0.26724568666666665}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"strength\": 0.34548760000000006}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"strength\": 0.4214429333333333}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.7626877000000001}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.2548108666666667}, {\"source_id\": \"d05cd121f1b7d8dbc66d65141de6284818425b34_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.33119516666666665}, {\"source_id\": \"d0e39e56013f39042797c59aa4fabe8ddfc44c14_0\", \"target_id\": \"ef753072577c9bf2ca217138d9dbc96c4c67844d_0\", \"strength\": 0.7518707333333334}, {\"source_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"target_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"strength\": 0.33648673333333334}, {\"source_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.35190745000000007}, {\"source_id\": \"d37954de196d2a847c8c987dc562f58649e88c9f_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.26939586666666665}, {\"source_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"target_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"strength\": 0.31224378}, {\"source_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2625838466666667}, {\"source_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.2589600333333334}, {\"source_id\": \"d4fdae33a9ad8746cdcfb319930e0e73f4bdab99_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.37038340000000003}, {\"source_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"target_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"strength\": 0.2243540333333333}, {\"source_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"target_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"strength\": 0.2286367}, {\"source_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.2276604666666667}, {\"source_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.23425520000000002}, {\"source_id\": \"d506fe02791a542e41a537538e4d5d1489c96e65_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.31422773333333337}, {\"source_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.27133863333333336}, {\"source_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.2473682666666667}, {\"source_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2627371}, {\"source_id\": \"d50b8d236c86c155f99d4f95c8885b8b176e05cd_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2814618166666667}, {\"source_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2623629}, {\"source_id\": \"d5c87578f6adfbadc7a945c6a171637ba37a943b_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.3405651333333333}, {\"source_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.26379020000000003}, {\"source_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2967459866666667}, {\"source_id\": \"da0958299f99644b57c73d2bf02751c91c512435_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2937250533333333}, {\"source_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"target_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"strength\": 0.28103873333333335}, {\"source_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"target_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"strength\": 0.6777816666666667}, {\"source_id\": \"dac362da9a96399c3bc20245191e0f4a13f948cd_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 0.2900186666666667}, {\"source_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"target_id\": \"dd6954f60cf1a50db825a641f9f491d1cea0745c_0\", \"strength\": 0.2639749}, {\"source_id\": \"dbd8e6d8fad229d95e8ba0117bf4eaecfe22dec8_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.6319523666666668}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"strength\": 0.78385086}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.9900188333333334}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"strength\": 0.2576140333333334}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.3843764666666667}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7329214133333334}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.378634}, {\"source_id\": \"dfef527565afabe77677ca6a9ab51a12ff0dfd9f_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.7360753866666667}, {\"source_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.2775317333333333}, {\"source_id\": \"e0fcd7acf5f4aaf4987cc4f9d15db4126d65fa15_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.34724563333333336}, {\"source_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"target_id\": \"e5959dbd4a4308f02e63a5a46f13123d6b86b550_0\", \"strength\": 0.31194763333333336}, {\"source_id\": \"e3948c0ed73dea5112c96405fc413cdd1b55aafd_0\", \"target_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"strength\": 1.0204345000000001}, {\"source_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"target_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"strength\": 0.9163721333333334}, {\"source_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"target_id\": \"fc306c2c460c261cf6390cae4b41731ebac156bd_0\", \"strength\": 0.2599145666666667}, {\"source_id\": \"e3b6b2f4b010d549a82b36382e6fd4b7a3952012_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3468413333333334}, {\"source_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"target_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"strength\": 0.29154711333333333}, {\"source_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.8510951333333334}, {\"source_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.27160202}, {\"source_id\": \"e747c96b77f105b1f5267b44d32d8b80b87988f9_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.34309343333333336}, {\"source_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"target_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"strength\": 0.20767419333333334}, {\"source_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"target_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"strength\": 0.21746116666666668}, {\"source_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.24524433333333337}, {\"source_id\": \"e859b51d2b2320027737e41f46f812a6c58ae42a_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.22873380000000004}, {\"source_id\": \"ec3ffbe30adb404a1930acdb57d8147a5ed9bb76_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.20670322333333335}, {\"source_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.4571848}, {\"source_id\": \"ec88d5b172eda48e48732f2dc404038efb08de78_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.29842920000000006}, {\"source_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"target_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"strength\": 0.28495143333333334}, {\"source_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.2601233}, {\"source_id\": \"edc4ce7e3a05029da0822552360173e983ec2d15_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.3115513666666667}, {\"source_id\": \"edcc8581bdc4323bde3142870303f78734c689d1_0\", \"target_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"strength\": 0.2731983}, {\"source_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"target_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"strength\": 0.3380354666666667}, {\"source_id\": \"ee1417ff85e32faeef31fc9e599a008b1c7fe7a8_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.7706124333333334}, {\"source_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.40401640000000005}, {\"source_id\": \"ee9a49bba36009f18ec88780318e26bdb0fe67de_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.27517043333333335}, {\"source_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.3372958666666667}, {\"source_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.3922188666666667}, {\"source_id\": \"f07a68845de39a9a44c22cc9171cf8911a241425_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 1.4498234666666667}, {\"source_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"target_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"strength\": 0.31866863333333334}, {\"source_id\": \"f0e004db0e135c69347bd9b1703c2469526fc2cd_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.8484052333333334}, {\"source_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"target_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"strength\": 0.24049461333333333}, {\"source_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"target_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"strength\": 0.3082287866666667}, {\"source_id\": \"f5fd381915e6e70cfeacb9d5702995fbd7475c6b_0\", \"target_id\": \"fba8fec30df1c374b8b7a5d2b2f77e7861f6ae38_0\", \"strength\": 0.2555148}, {\"source_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"target_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"strength\": 0.26832190000000006}, {\"source_id\": \"f6b9ad972b9eb3722721e33d00e71bc97a773a66_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.2453408}, {\"source_id\": \"f6bfbcc020950fa3d5eb457246f86bc8e8ea63e8_0\", \"target_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"strength\": 0.2655180866666667}, {\"source_id\": \"f76a317c21d03bcfba077169d330596d7f74fe24_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.26905813333333334}, {\"source_id\": \"fdd06e793323ee4bd943a5422bb0db5a2236d165_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.26842506666666666}, {\"source_id\": \"ff3408860f327dc4c7b99fd13a4b9e49a667d4fa_0\", \"target_id\": \"ff80ed545d90479256cbf06d908baca2b41237c2_0\", \"strength\": 0.2922802666666667}], \"clusters\": [{\"cluster\": 1, \"label\": \"Natural Language Processing Innovations\", \"summary\": null}, {\"cluster\": 2, \"label\": \"Representative documents of cluster\", \"summary\": null}], \"blog_title\": null, \"blog_intro\": null, \"blog_conclusion\": null}}"